diff --git a/src/na/na_ofi.c b/src/na/na_ofi.c
index 64d042b..ffc5db5 100644
--- a/src/na/na_ofi.c
+++ b/src/na/na_ofi.c
@@ -75,6 +75,13 @@
  * The purpose of this is to aggregate settings for all providers into a
  * single location so that it is easier to alter them.
  */
+#ifndef FI_ADDR_CXI
+#define FI_ADDR_CXI 0xe
+#endif
+
+#ifndef FI_PROTO_CXI
+#define FI_PROTO_CXI (FI_PROTO_PSMX3 + 1)
+#endif
 #define NA_OFI_PROV_TYPES                                                      \
     X(NA_OFI_PROV_NULL, "", "", 0, 0, 0, 0)                                    \
     X(NA_OFI_PROV_SOCKETS, "sockets", "", FI_SOCKADDR_IN, FI_PROGRESS_AUTO,    \
@@ -83,6 +90,8 @@
             NA_OFI_SEP)                                                        \
     X(NA_OFI_PROV_TCP, "tcp;ofi_rxm", "tcp", FI_SOCKADDR_IN, FI_PROGRESS_AUTO, \
         FI_SOURCE | FI_DIRECTED_RECV, NA_OFI_WAIT_FD | NA_OFI_SOURCE_MSG)      \
+    X(NA_OFI_PROV_CXI, "cxi", "cxi", FI_ADDR_CXI, FI_PROGRESS_MANUAL, 		\
+        0, NA_OFI_SOURCE_MSG | NA_OFI_VERIFY_PROV_DOM)      \
     X(NA_OFI_PROV_PSM, "psm", "", FI_ADDR_PSMX, FI_PROGRESS_MANUAL, 0,         \
         NA_OFI_WAIT_SET | NA_OFI_SOURCE_MSG)                                   \
     X(NA_OFI_PROV_PSM2, "psm2", "", FI_ADDR_PSMX2, FI_PROGRESS_MANUAL,         \
@@ -168,6 +177,9 @@ static unsigned long const na_ofi_prov_flags[] = {NA_OFI_PROV_TYPES};
 #define NA_OFI_OP_QUEUED    (1 << 3)
 #define NA_OFI_OP_ERRORED   (1 << 4)
 
+/* The timeout (second) when give up for FI_EAGAIN's retry */
+#define NA_OFI_OP_RETRY_TIMEOUT ((double)90.0)
+
 /* Private data access */
 #define NA_OFI_CLASS(na_class)                                                 \
     ((struct na_ofi_class *) ((na_class)->plugin_class))
@@ -277,6 +289,22 @@ struct na_ofi_psm2_addr {
     na_uint64_t addr1;
 };
 
+#define C_DFA_PID_BITS_MAX 9
+#define C_DFA_NIC_BITS 20
+
+struct na_ofi_cxi_addr {
+	union {
+		struct {
+			uint32_t pid	: C_DFA_PID_BITS_MAX;
+			uint32_t nic	: C_DFA_NIC_BITS;
+			uint32_t valid	: 1;
+			uint32_t unused : 2;
+		} detail;
+
+		na_uint32_t raw;
+	}
+};
+
 /* GNI address */
 struct na_ofi_gni_addr {
     struct {
@@ -358,6 +386,7 @@ struct na_ofi_rma_info {
 
 /* Operation ID */
 struct na_ofi_op_id {
+    hg_time_t op_ts; /* timestamp to check when retry for EAGAIN */
     struct na_cb_completion_data completion_data; /* Completion data    */
     union {
         struct na_ofi_msg_info msg;
@@ -508,6 +537,9 @@ na_ofi_str_to_psm2(const char *str, void **addr, na_size_t *len);
 static na_return_t
 na_ofi_str_to_gni(const char *str, void **addr, na_size_t *len);
 
+static na_return_t
+na_ofi_str_to_cxi(const char *str, void **addr, na_size_t *len);
+
 /**
  * Convert the address to a 64-bit key to search corresponding FI addr.
  */
@@ -523,6 +555,8 @@ static NA_INLINE na_uint64_t
 na_ofi_psm2_to_key(const struct na_ofi_psm2_addr *addr);
 static NA_INLINE na_uint64_t
 na_ofi_gni_to_key(const struct na_ofi_gni_addr *addr);
+static NA_INLINE na_uint64_t
+na_ofi_cxi_to_key(const struct na_ofi_cxi_addr *addr);
 
 /**
  * Key hash for hash table.
@@ -830,6 +864,13 @@ na_ofi_op_retry(
     struct na_ofi_context *na_ofi_context, struct na_ofi_op_id *na_ofi_op_id);
 
 /**
+ * Abort all ops targeted at fi_addr.
+ */
+static NA_INLINE void
+na_ofi_op_queue_abort(
+    struct na_ofi_context *na_ofi_context, fi_addr_t fi_addr, int ret);
+
+/**
  * Complete operation ID.
  */
 static NA_INLINE void
@@ -1218,6 +1259,8 @@ na_ofi_prov_addr_size(na_uint32_t addr_format)
             return sizeof(struct na_ofi_psm_addr);
         case FI_ADDR_PSMX2:
             return sizeof(struct na_ofi_psm2_addr);
+        case FI_ADDR_CXI:
+		return sizeof(struct na_ofi_cxi_addr);
         case FI_ADDR_GNI:
             return sizeof(struct na_ofi_gni_addr);
         default:
@@ -1288,6 +1331,8 @@ na_ofi_str_to_addr(
             return na_ofi_str_to_psm(str, addr, len);
         case FI_ADDR_PSMX2:
             return na_ofi_str_to_psm2(str, addr, len);
+        case FI_ADDR_CXI:
+		return na_ofi_str_to_cxi(str, addr, len);
         case FI_ADDR_GNI:
             return na_ofi_str_to_gni(str, addr, len);
         default:
@@ -1400,6 +1445,31 @@ error:
     return ret;
 }
 
+static na_return_t
+na_ofi_str_to_cxi(const char *str, void **addr, na_size_t *len)
+{
+    struct na_ofi_cxi_addr *cxi_addr;
+    na_return_t ret = NA_SUCCESS;
+    int rc;
+
+    *len = sizeof(*cxi_addr);
+    cxi_addr = calloc(1, *len);
+    NA_CHECK_SUBSYS_ERROR(addr, cxi_addr == NULL, error, ret, NA_NOMEM,
+        "Could not allocate cxi address");
+
+    rc = sscanf(str, "%*[^:]://%" SCNx64,  (uint64_t *) &cxi_addr->raw);
+
+    NA_CHECK_SUBSYS_ERROR(addr, rc != 1, error, ret, NA_PROTONOSUPPORT,
+        "Could not convert addr string to CXI addr format");
+
+    *addr = cxi_addr;
+
+    return ret;
+
+error:
+    free(cxi_addr);
+    return ret;
+}
 /*---------------------------------------------------------------------------*/
 static na_return_t
 na_ofi_str_to_psm2(const char *str, void **addr, na_size_t *len)
@@ -1504,6 +1574,10 @@ na_ofi_addr_to_key(na_uint32_t addr_format, const void *addr, na_size_t len)
                 "Addr len (%" PRIu64 ") does not match for FI_ADDR_PSMX2 (%zu)",
                 len, sizeof(struct na_ofi_psm2_addr));
             return na_ofi_psm2_to_key((const struct na_ofi_psm2_addr *) addr);
+
+	case FI_ADDR_CXI:
+		return na_ofi_cxi_to_key((const struct na_ofi_cxi_addr *) addr);
+
         case FI_ADDR_GNI:
             NA_CHECK_SUBSYS_ERROR_NORET(addr,
                 len != sizeof(struct na_ofi_gni_addr), out,
@@ -1550,6 +1624,12 @@ na_ofi_psm2_to_key(const struct na_ofi_psm2_addr *addr)
     return addr->addr0;
 }
 
+static NA_INLINE na_uint64_t
+na_ofi_cxi_to_key(const struct na_ofi_cxi_addr *addr)
+{
+	return (((na_uint64_t)addr->raw));
+}
+
 /*---------------------------------------------------------------------------*/
 static NA_INLINE na_uint64_t
 na_ofi_gni_to_key(const struct na_ofi_gni_addr *addr)
@@ -1874,11 +1954,17 @@ na_ofi_getinfo(enum na_ofi_prov_type prov_type, struct fi_info **providers,
      * appropriate time.
      */
     hints->domain_attr->mr_mode = (NA_OFI_MR_BASIC_REQ | FI_MR_LOCAL);
+    if (prov_type == NA_OFI_PROV_CXI)
+        hints->domain_attr->mr_mode = (NA_OFI_MR_BASIC_REQ | FI_MR_LOCAL) | FI_MR_ENDPOINT;
 
     /* set default progress mode */
     hints->domain_attr->control_progress = na_ofi_prov_progress[prov_type];
     hints->domain_attr->data_progress = na_ofi_prov_progress[prov_type];
 
+
+    if (prov_type == NA_OFI_PROV_CXI)
+	hints->ep_attr->protocol = FI_PROTO_CXI;
+
     /* only use sockets provider with tcp for now */
     if (prov_type == NA_OFI_PROV_SOCKETS)
         hints->ep_attr->protocol = FI_PROTO_SOCK_TCP;
@@ -3282,6 +3368,31 @@ na_ofi_cq_read(na_context_t *context, size_t max_count,
             *actual_count = 1;
             break;
 
+        case FI_ENOTCONN:
+        case FI_ECONNRESET:
+        case FI_ECONNABORTED:
+        case FI_ECONNREFUSED:
+        {
+            struct na_ofi_op_id *na_ofi_op_id = NULL;
+
+            NA_CHECK_SUBSYS_ERROR(op, cq_err.op_context == NULL, out, ret,
+                NA_INVALID_ARG, "Invalid operation context");
+            na_ofi_op_id =
+                container_of(cq_err.op_context, struct na_ofi_op_id, fi_ctx);
+            NA_LOG_ERROR("got cq_err.err %s, event on operation ID %p\n",
+                         fi_strerror(cq_err.err), na_ofi_op_id);
+            NA_CHECK_SUBSYS_ERROR(op, na_ofi_op_id == NULL, out, ret,
+                NA_INVALID_ARG, "Invalid operation ID");
+
+            NA_CHECK_SUBSYS_ERROR(op,
+                hg_atomic_get32(&na_ofi_op_id->status) & NA_OFI_OP_COMPLETED,
+                out, ret, NA_FAULT, "Operation ID was completed");
+
+            na_ofi_op_queue_abort(NA_OFI_CONTEXT(context), na_ofi_op_id->addr->fi_addr,
+                                  NA_HOSTUNREACH);
+            na_ofi_complete(na_ofi_op_id, NA_HOSTUNREACH);
+        } break;
+
         default:
             NA_LOG_SUBSYS_WARNING(poll,
                 "fi_cq_readerr() got err: %d (%s), "
@@ -3484,7 +3595,10 @@ na_ofi_cq_process_retries(struct na_ofi_context *na_ofi_context)
     na_return_t ret;
 
     do {
+        hg_time_t now, *op_ts;
         na_bool_t canceled = NA_FALSE;
+        na_cb_type_t cb_type;
+        double time_diff;
         ssize_t rc = 0;
 
         hg_thread_spin_lock(&op_queue->lock);
@@ -3514,8 +3628,13 @@ na_ofi_cq_process_retries(struct na_ofi_context *na_ofi_context)
         NA_LOG_SUBSYS_DEBUG(
             op, "Attempting to retry %p", (void *) na_ofi_op_id);
 
-        /* Retry operation */
-        switch (na_ofi_op_id->completion_data.callback_info.type) {
+        /* Retry operation, set the timestamp for first time retry */
+
+        cb_type = na_ofi_op_id->completion_data.callback_info.type;
+        op_ts = &na_ofi_op_id->op_ts;
+        if (hg_time_to_ms(*op_ts) == 0)
+            hg_time_get_current(op_ts);
+        switch (cb_type) {
             case NA_CB_SEND_UNEXPECTED:
             case NA_CB_SEND_EXPECTED:
                 rc = fi_tsend(na_ofi_context->fi_tx,
@@ -3562,6 +3681,18 @@ na_ofi_cq_process_retries(struct na_ofi_context *na_ofi_context)
             }
             continue;
         } else if (rc == -FI_EAGAIN) {
+            /* if RMA keep getting FI_EAGAIN within NA_OFI_OP_RETRY_TIMEOUT, cancel the OP */
+            hg_time_get_current(&now);
+            time_diff = hg_time_diff(now, *op_ts);
+            if ((cb_type == NA_CB_PUT || cb_type == NA_CB_GET) &&
+                time_diff > NA_OFI_OP_RETRY_TIMEOUT) {
+                NA_LOG_ERROR("Aborting op_id %p (%s) as keep getting FI_EAGAIN in %f seconds.\n",
+                             na_ofi_op_id, na_cb_type_to_string(cb_type), time_diff);
+                hg_atomic_or32(&na_ofi_op_id->status, NA_OFI_OP_ERRORED);
+                na_ofi_complete(na_ofi_op_id, NA_CANCELED);
+                continue;
+            }
+
             hg_thread_spin_lock(&op_queue->lock);
             /* Do not repush OP ID if it was canceled in the meantime */
             if (hg_atomic_get32(&na_ofi_op_id->status) & NA_OFI_OP_CANCELING) {
@@ -3621,11 +3752,39 @@ na_ofi_op_retry(
 
 /*---------------------------------------------------------------------------*/
 static NA_INLINE void
+na_ofi_op_queue_abort(
+    struct na_ofi_context *na_ofi_context, fi_addr_t fi_addr, int ret)
+{
+    struct na_ofi_op_id *na_ofi_op_id;
+    struct na_ofi_op_queue *op_queue = na_ofi_context->retry_op_queue;
+
+    NA_LOG_ERROR("Aborting all OPs in queue to fi_addr %d", (int)fi_addr);
+
+    hg_thread_spin_lock(&op_queue->lock);
+    HG_QUEUE_FOREACH(na_ofi_op_id, &op_queue->queue, entry) {
+        if (na_ofi_op_id->addr->fi_addr != fi_addr)
+            continue;
+        HG_QUEUE_REMOVE(&op_queue->queue, na_ofi_op_id, na_ofi_op_id, entry);
+        NA_LOG_ERROR("Aborting op_id %p (%s) in queue to fi_addr %d, ret %d.", na_ofi_op_id,
+                     na_cb_type_to_string(na_ofi_op_id->completion_data.callback_info.type),
+                     (int)fi_addr, ret);
+        hg_atomic_and32(&na_ofi_op_id->status, ~NA_OFI_OP_QUEUED);
+        hg_atomic_or32(&na_ofi_op_id->status, NA_OFI_OP_ERRORED);
+        na_ofi_complete(na_ofi_op_id, ret);
+    }
+    hg_thread_spin_unlock(&op_queue->lock);
+}
+
+/*---------------------------------------------------------------------------*/
+static NA_INLINE void
 na_ofi_complete(struct na_ofi_op_id *na_ofi_op_id, na_return_t cb_ret)
 {
     /* Mark op id as completed (independent of cb_ret) */
     hg_atomic_or32(&na_ofi_op_id->status, NA_OFI_OP_COMPLETED);
 
+    /* zero the timestamp */
+    memset(&na_ofi_op_id->op_ts, 0, sizeof(na_ofi_op_id->op_ts));
+
     /* Set callback ret */
     na_ofi_op_id->completion_data.callback_info.ret = cb_ret;
 
@@ -3971,6 +4130,36 @@ na_ofi_initialize(na_class_t *na_class, const struct na_info *na_info,
     priv->iov_max = priv->domain->fi_prov->domain_attr->mr_iov_limit;
 
     /* Create endpoint */
+
+    /* For CXI we need to create fake endpoint first to parse out base address */
+    if (prov_type == NA_OFI_PROV_CXI && port != 0) {
+	static uint32_t base_addr = 0x0;
+	uint32_t tmp_pid = port % 512;
+	uint32_t tmp_addr;
+
+
+	if (base_addr == 0x0) {
+	    uint32_t addrlen  =4;
+	    ret = na_ofi_endpoint_open(priv->domain, node_ptr, NULL, 0,
+			priv->no_wait, priv->context_max, &priv->endpoint);
+            NA_CHECK_SUBSYS_NA_ERROR(cls, out, ret, "Could not create base endpoint");
+
+	    ret = fi_getname(&priv->endpoint->fi_ep->fid, &base_addr, &addrlen);
+            NA_CHECK_SUBSYS_NA_ERROR(cls, out, ret, "fi_getname() failed");
+
+            ret = na_ofi_endpoint_close(priv->endpoint);
+            NA_CHECK_SUBSYS_NA_ERROR(cls, out, ret, "na_ofi_endpoint_close() failed");
+	}
+
+	//tmp_pid++;
+	tmp_addr = base_addr & ~0x1ff; /* 9 bits for pid */
+	tmp_addr |= (tmp_pid & 0x1ff);
+	src_addr = malloc(sizeof(uint32_t));
+
+	memcpy(src_addr, &tmp_addr, sizeof(uint32_t));
+	src_addrlen = 4;
+    }
+
     ret = na_ofi_endpoint_open(priv->domain, node_ptr, src_addr, src_addrlen,
         priv->no_wait, priv->context_max, &priv->endpoint);
     NA_CHECK_SUBSYS_NA_ERROR(
@@ -4943,6 +5132,19 @@ na_ofi_mem_register(na_class_t *na_class, na_mem_handle_t mem_handle)
     na_ofi_mem_handle->desc.info.fi_mr_key =
         fi_mr_key(na_ofi_mem_handle->fi_mr);
 
+	if ((domain->fi_prov->domain_attr->mr_mode & FI_MR_ENDPOINT)) {
+		struct na_ofi_class *priv;
+		priv = NA_OFI_CLASS(na_class);
+
+		rc = fi_mr_bind(na_ofi_mem_handle->fi_mr, priv->endpoint->fi_ep, 0x0);
+		NA_CHECK_SUBSYS_ERROR(cls, rc != 0, out, ret, na_ofi_errno_to_na(-rc),
+				"fi_mr_bind() failed, rc: %d (%s)\n", rc, fi_strerror(-rc));
+
+		rc = fi_mr_enable(na_ofi_mem_handle->fi_mr);
+		NA_CHECK_SUBSYS_ERROR(cls, rc != 0, out, ret, na_ofi_errno_to_na(-rc),
+				"fi_mr_enable() failed, rc: %d (%s)\n", rc, fi_strerror(-rc));
+	}
+
 out:
     return ret;
 }
