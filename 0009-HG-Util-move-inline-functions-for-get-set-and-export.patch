--- b/src/CMakeLists.txt
+++ a/src/CMakeLists.txt
@@ -179,11 +179,11 @@
 # Set sources
 #------------------------------------------------------------------------------
 set(MERCURY_SRCS
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury.c
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_bulk.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_core.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_core_header.c
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_header.c
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_bulk.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_proc.c
   ${CMAKE_CURRENT_SOURCE_DIR}/proc_extra/mercury_string_object.c
 )
@@ -237,20 +237,18 @@
 # Specify project header files to be installed
 #-----------------------------------------------------------------------------
 set(MERCURY_HEADERS
-  ${CMAKE_CURRENT_BINARY_DIR}/mercury_config.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_bulk.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_core.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_core_header.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_core_types.h
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_proc.h
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_bulk.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_error.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_header.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_macros.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_proc_bulk.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_proc.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_types.h
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_macros.h
+  ${CMAKE_CURRENT_BINARY_DIR}/mercury_config.h
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_error.h
+  ${CMAKE_CURRENT_SOURCE_DIR}/proc_extra/mercury_string_object.h
   ${CMAKE_CURRENT_SOURCE_DIR}/proc_extra/mercury_proc_string.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/proc_extra/mercury_string_object.h
 )
 set(MERCURY_HL_HEADERS
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_hl.h
--- b/src/mercury.c
+++ a/src/mercury.c
@@ -9,9 +9,12 @@
  */
 
 #include "mercury.h"
+#include "mercury_core.h"
+#include "mercury_header.h"
 #include "mercury_bulk.h"
 #include "mercury_proc.h"
 #include "mercury_proc_bulk.h"
+#include "mercury_error.h"
 
 #include "mercury_hash_string.h"
 #include "mercury_mem.h"
@@ -30,16 +33,15 @@
 #define HG_ERROR_STRING_MACRO(def, value, string) \
   if (value == def) string = #def
 
-#define HG_CONTEXT_CLASS(context) \
-    ((struct hg_private_class *)(context->hg_class))
-
 /************************************/
 /* Local Type and Struct Definition */
 /************************************/
 
 /* HG class */
+struct hg_class {
+    hg_core_class_t *core_class;    /* Core class */
+    hg_size_t in_offset;            /* Input offset */
+    hg_size_t out_offset;           /* Output offset */
-struct hg_private_class {
-    struct hg_class hg_class;       /* Must remain as first field */
     hg_thread_spin_t register_lock; /* Register lock */
 
     /* Callbacks */
@@ -47,6 +49,12 @@
     void *handle_create_arg;                            /* handle_create arg */
 };
 
+/* HG context */
+struct hg_context {
+    hg_core_context_t *core_context;/* Core context */
+    hg_class_t *hg_class;           /* HG class */
+};
+
 /* Info for function map */
 struct hg_proc_info {
     hg_rpc_cb_t rpc_cb;             /* RPC callback */
@@ -58,8 +66,9 @@
 };
 
 /* HG handle */
+struct hg_handle {
+    hg_core_handle_t core_handle;   /* Core handle */
+    struct hg_info hg_info;         /* HG info */
-struct hg_private_handle {
-    struct hg_handle handle;        /* Must remain as first field */
     hg_cb_t forward_cb;             /* Forward callback */
     void *forward_arg;              /* Forward callback args */
     hg_cb_t respond_cb;             /* Respond callback */
@@ -74,6 +83,8 @@
     hg_size_t out_extra_buf_size;   /* Extra output buffer size */
     hg_bulk_t out_extra_bulk;       /* Extra output bulk handle */
     hg_return_t (*extra_bulk_transfer_cb)(hg_core_handle_t); /* Bulk transfer callback */
+    void *data;                         /* User data */
+    void (*data_free_callback)(void *); /* User data free callback */
 };
 
 /* HG op id */
@@ -92,6 +103,19 @@
     } info;
 };
 
+/***********************/
+/* External Prototypes */
+/***********************/
+
+/**
+ * Get RPC registered data.
+ * TODO can be improved / same as calling HG_Registered_data()?
+ */
+extern void *
+hg_core_get_rpc_data(
+        struct hg_core_handle *hg_core_handle
+        );
+
 /********************/
 /* Local Prototypes */
 /********************/
@@ -107,9 +131,9 @@
 /**
  * Alloc function for private data.
  */
+static struct hg_handle *
-static struct hg_private_handle *
 hg_handle_create(
+        hg_class_t *hg_class
-        struct hg_private_class *hg_class
         );
 
 /**
@@ -168,8 +192,8 @@
  */
 static hg_return_t
 hg_get_struct(
+        struct hg_handle *hg_handle,
+        struct hg_proc_info *hg_proc_info,
-        struct hg_private_handle *hg_handle,
-        const struct hg_proc_info *hg_proc_info,
         hg_op_t op,
         void *struct_ptr
         );
@@ -179,8 +203,8 @@
  */
 static hg_return_t
 hg_set_struct(
+        struct hg_handle *hg_handle,
+        struct hg_proc_info *hg_proc_info,
-        struct hg_private_handle *hg_handle,
-        const struct hg_proc_info *hg_proc_info,
         hg_op_t op,
         void *struct_ptr,
         hg_size_t *payload_size,
@@ -192,8 +216,8 @@
  */
 static hg_return_t
 hg_free_struct(
+        struct hg_handle *hg_handle,
+        struct hg_proc_info *hg_proc_info,
-        struct hg_private_handle *hg_handle,
-        const struct hg_proc_info *hg_proc_info,
         hg_op_t op,
         void *struct_ptr
         );
@@ -203,7 +227,7 @@
  */
 static hg_return_t
 hg_get_extra_payload(
+        struct hg_handle *hg_handle,
-        struct hg_private_handle *hg_handle,
         hg_op_t op,
         hg_return_t (*done_cb)(hg_core_handle_t)
         );
@@ -221,7 +245,7 @@
  */
 static void
 hg_free_extra_payload(
+        struct hg_handle *hg_handle
-        struct hg_private_handle *hg_handle
         );
 
 /**
@@ -259,30 +283,30 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static struct hg_handle *
+hg_handle_create(hg_class_t *hg_class)
-static struct hg_private_handle *
-hg_handle_create(struct hg_private_class *hg_class)
 {
+    struct hg_handle *hg_handle = NULL;
-    struct hg_private_handle *hg_handle = NULL;
     hg_return_t ret;
 
     /* Create private data to wrap callbacks etc */
+    hg_handle = (struct hg_handle *) malloc(
+        sizeof(struct hg_handle));
-    hg_handle = (struct hg_private_handle *) malloc(
-        sizeof(struct hg_private_handle));
     if (!hg_handle) {
         HG_LOG_ERROR("Could not allocate private data");
         goto done;
     }
+    memset(hg_handle, 0, sizeof(struct hg_handle));
+    hg_handle->hg_info.hg_class = hg_class;
-    memset(hg_handle, 0, sizeof(struct hg_private_handle));
-    hg_handle->handle.info.hg_class = (hg_class_t *) hg_class;
     hg_header_init(&hg_handle->hg_header, HG_UNDEF);
 
     /* CRC32 is enough for small size buffers */
+    ret = hg_proc_create(hg_class, HG_CRC32, &hg_handle->in_proc);
-    ret = hg_proc_create((hg_class_t *) hg_class, HG_CRC32, &hg_handle->in_proc);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Cannot create HG proc");
         goto done;
     }
+    ret = hg_proc_create(hg_class, HG_CRC32, &hg_handle->out_proc);
-    ret = hg_proc_create((hg_class_t *) hg_class, HG_CRC32, &hg_handle->out_proc);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Cannot create HG proc");
         goto done;
@@ -296,10 +320,10 @@
 static void
 hg_handle_free(void *arg)
 {
+    struct hg_handle *hg_handle = (struct hg_handle *) arg;
-    struct hg_private_handle *hg_handle = (struct hg_private_handle *) arg;
 
+    if (hg_handle->data_free_callback)
+        hg_handle->data_free_callback(hg_handle->data);
-    if (hg_handle->handle.data_free_callback)
-        hg_handle->handle.data_free_callback(hg_handle->handle.data);
     if (hg_handle->in_proc != HG_PROC_NULL)
         hg_proc_free(hg_handle->in_proc);
     if (hg_handle->out_proc != HG_PROC_NULL)
@@ -313,25 +337,24 @@
 hg_handle_create_cb(hg_core_handle_t core_handle, void *arg)
 {
     struct hg_context *hg_context = (struct hg_context *) arg;
+    struct hg_handle *hg_handle;
-    struct hg_private_handle *hg_handle;
     hg_return_t ret = HG_SUCCESS;
 
+    hg_handle = hg_handle_create(hg_context->hg_class);
-    hg_handle = hg_handle_create(HG_CONTEXT_CLASS(hg_context));
     if (!hg_handle) {
         HG_LOG_ERROR("Could not create HG handle");
         ret = HG_NOMEM_ERROR;
         goto done;
     }
+    hg_handle->core_handle = core_handle;
+    hg_handle->hg_info.context = hg_context;
-    hg_handle->handle.core_handle = core_handle;
-    hg_handle->handle.info.context = hg_context;
 
     HG_Core_set_data(core_handle, hg_handle, hg_handle_free);
 
     /* Call handle create if defined */
+    if (hg_context->hg_class->handle_create) {
+        ret = hg_context->hg_class->handle_create(hg_handle,
+            hg_context->hg_class->handle_create_arg);
-    if (HG_CONTEXT_CLASS(hg_context)->handle_create) {
-        ret = HG_CONTEXT_CLASS(hg_context)->handle_create(
-            (hg_handle_t) hg_handle,
-            HG_CONTEXT_CLASS(hg_context)->handle_create_arg);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Error in handle create callback");
             goto done;
@@ -347,12 +370,12 @@
 hg_more_data_cb(hg_core_handle_t core_handle, hg_op_t op,
     hg_return_t (*done_cb)(hg_core_handle_t))
 {
+    struct hg_handle *hg_handle;
-    struct hg_private_handle *hg_handle;
     void *extra_buf;
     hg_return_t ret = HG_SUCCESS;
 
     /* Retrieve private data */
+    hg_handle = (struct hg_handle *) HG_Core_get_data(core_handle);
-    hg_handle = (struct hg_private_handle *) HG_Core_get_data(core_handle);
     if (!hg_handle) {
         HG_LOG_ERROR("Could not get private data");
         ret = HG_PROTOCOL_ERROR;
@@ -396,10 +419,10 @@
 static void
 hg_more_data_free_cb(hg_core_handle_t core_handle)
 {
+    struct hg_handle *hg_handle;
-    struct hg_private_handle *hg_handle;
 
     /* Retrieve private data */
+    hg_handle = (struct hg_handle *) HG_Core_get_data(core_handle);
-    hg_handle = (struct hg_private_handle *) HG_Core_get_data(core_handle);
     if (!hg_handle) {
         goto done;
     }
@@ -415,15 +438,15 @@
 hg_core_rpc_cb(hg_core_handle_t core_handle)
 {
     const struct hg_core_info *hg_core_info = HG_Core_get_info(core_handle);
+    struct hg_proc_info *hg_proc_info =
+        (struct hg_proc_info *) hg_core_get_rpc_data(core_handle);
+    struct hg_handle *hg_handle =
+        (struct hg_handle *) HG_Core_get_data(core_handle);
-    const struct hg_proc_info *hg_proc_info =
-        (const struct hg_proc_info *) HG_Core_get_rpc_data(core_handle);
-    struct hg_private_handle *hg_handle =
-        (struct hg_private_handle *) HG_Core_get_data(core_handle);
     hg_return_t ret = HG_SUCCESS;
 
+    hg_handle->hg_info.addr = (hg_addr_t) hg_core_info->addr;
+    hg_handle->hg_info.context_id = hg_core_info->context_id;
+    hg_handle->hg_info.id = hg_core_info->id;
-    hg_handle->handle.info.addr = (hg_addr_t) hg_core_info->addr;
-    hg_handle->handle.info.context_id = hg_core_info->context_id;
-    hg_handle->handle.info.id = hg_core_info->id;
 
     if (!hg_proc_info->rpc_cb) {
         HG_LOG_ERROR("No RPC callback registered");
@@ -432,7 +455,7 @@
         ret = HG_INVALID_PARAM;
         goto done;
     }
+    ret = hg_proc_info->rpc_cb(hg_handle);
-    ret = hg_proc_info->rpc_cb((hg_handle_t) hg_handle);
 
 done:
     return ret;
@@ -459,8 +482,8 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_get_struct(struct hg_handle *hg_handle, struct hg_proc_info *hg_proc_info,
+    hg_op_t op, void *struct_ptr)
-hg_get_struct(struct hg_private_handle *hg_handle,
-    const struct hg_proc_info *hg_proc_info, hg_op_t op, void *struct_ptr)
 {
     hg_proc_t proc = HG_PROC_NULL;
     hg_proc_cb_t proc_cb = NULL;
@@ -476,7 +499,7 @@
     switch (op) {
         case HG_INPUT:
             /* Use custom header offset */
+            header_offset += hg_handle->hg_info.hg_class->in_offset;
-            header_offset += hg_handle->handle.info.hg_class->in_offset;
             /* Set input proc */
             proc = hg_handle->in_proc;
             proc_cb = hg_proc_info->in_proc_cb;
@@ -484,7 +507,7 @@
             hg_header_hash = &hg_header->msg.input.hash;
 #endif
             /* Get core input buffer */
+            ret = HG_Core_get_input(hg_handle->core_handle, &buf, &buf_size);
-            ret = HG_Core_get_input(hg_handle->handle.core_handle, &buf, &buf_size);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Could not get input buffer");
                 goto done;
@@ -500,7 +523,7 @@
                 goto done;
             }
             /* Use custom header offset */
+            header_offset += hg_handle->hg_info.hg_class->out_offset;
-            header_offset += hg_handle->handle.info.hg_class->out_offset;
             /* Set output proc */
             proc = hg_handle->out_proc;
             proc_cb = hg_proc_info->out_proc_cb;
@@ -508,7 +531,7 @@
             hg_header_hash = &hg_header->msg.output.hash;
 #endif
             /* Get core output buffer */
+            ret = HG_Core_get_output(hg_handle->core_handle, &buf, &buf_size);
-            ret = HG_Core_get_output(hg_handle->handle.core_handle, &buf, &buf_size);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Could not get output buffer");
                 goto done;
@@ -581,7 +604,7 @@
 
     /* Increment ref count on handle so that it remains valid until free_struct
      * is called */
+    HG_Core_ref_incr(hg_handle->core_handle);
-    HG_Core_ref_incr(hg_handle->handle.core_handle);
 
 done:
     return ret;
@@ -589,9 +612,8 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_set_struct(struct hg_handle *hg_handle, struct hg_proc_info *hg_proc_info,
+    hg_op_t op, void *struct_ptr, hg_size_t *payload_size, hg_bool_t *more_data)
-hg_set_struct(struct hg_private_handle *hg_handle,
-    const struct hg_proc_info *hg_proc_info, hg_op_t op, void *struct_ptr,
-    hg_size_t *payload_size, hg_bool_t *more_data)
 {
     hg_proc_t proc = HG_PROC_NULL;
     hg_proc_cb_t proc_cb = NULL;
@@ -608,7 +630,7 @@
     switch (op) {
         case HG_INPUT:
             /* Use custom header offset */
+            header_offset += hg_handle->hg_info.hg_class->in_offset;
-            header_offset += hg_handle->handle.info.hg_class->in_offset;
             /* Set input proc */
             proc = hg_handle->in_proc;
             proc_cb = hg_proc_info->in_proc_cb;
@@ -616,7 +638,7 @@
             hg_header_hash = &hg_header->msg.input.hash;
 #endif
             /* Get core input buffer */
+            ret = HG_Core_get_input(hg_handle->core_handle, &buf, &buf_size);
-            ret = HG_Core_get_input(hg_handle->handle.core_handle, &buf, &buf_size);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Could not get input buffer");
                 goto done;
@@ -633,7 +655,7 @@
                 goto done;
             }
             /* Use custom header offset */
+            header_offset += hg_handle->hg_info.hg_class->out_offset;
-            header_offset += hg_handle->handle.info.hg_class->out_offset;
             /* Set output proc */
             proc = hg_handle->out_proc;
             proc_cb = hg_proc_info->out_proc_cb;
@@ -641,7 +663,7 @@
             hg_header_hash = &hg_header->msg.output.hash;
 #endif
             /* Get core output buffer */
+            ret = HG_Core_get_output(hg_handle->core_handle, &buf, &buf_size);
-            ret = HG_Core_get_output(hg_handle->handle.core_handle, &buf, &buf_size);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Could not get output buffer");
                 goto done;
@@ -721,7 +743,7 @@
         hg_proc_set_extra_buf_is_mine(proc, HG_TRUE);
 
         /* Create bulk descriptor */
+        ret = HG_Bulk_create(hg_handle->hg_info.hg_class, 1, extra_buf,
-        ret = HG_Bulk_create(hg_handle->handle.info.hg_class, 1, extra_buf,
             extra_buf_size, HG_BULK_READ_ONLY, extra_bulk);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Could not create bulk data handle");
@@ -777,8 +799,8 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_free_struct(struct hg_handle *hg_handle, struct hg_proc_info *hg_proc_info,
+    hg_op_t op, void *struct_ptr)
-hg_free_struct(struct hg_private_handle *hg_handle,
-    const struct hg_proc_info *hg_proc_info, hg_op_t op, void *struct_ptr)
 {
     hg_proc_t proc = HG_PROC_NULL;
     hg_proc_cb_t proc_cb = NULL;
@@ -821,7 +843,7 @@
     }
 
     /* Decrement ref count or free */
+    ret = HG_Core_destroy(hg_handle->core_handle);
-    ret = HG_Core_destroy(hg_handle->handle.core_handle);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not decrement handle ref count");
         goto done;
@@ -833,11 +855,11 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_get_extra_payload(struct hg_handle *hg_handle, hg_op_t op,
-hg_get_extra_payload(struct hg_private_handle *hg_handle, hg_op_t op,
     hg_return_t (*done_cb)(hg_core_handle_t core_handle))
 {
     const struct hg_core_info *hg_core_info = HG_Core_get_info(
+        hg_handle->core_handle);
-        hg_handle->handle.core_handle);
     hg_proc_t proc = HG_PROC_NULL;
     void *buf, **extra_buf;
     hg_size_t buf_size, *extra_buf_size;
@@ -850,11 +872,11 @@
     switch (op) {
         case HG_INPUT:
             /* Use custom header offset */
+            header_offset += hg_handle->hg_info.hg_class->in_offset;
-            header_offset += hg_handle->handle.info.hg_class->in_offset;
             /* Set input proc */
             proc = hg_handle->in_proc;
             /* Get core input buffer */
+            ret = HG_Core_get_input(hg_handle->core_handle, &buf, &buf_size);
-            ret = HG_Core_get_input(hg_handle->handle.core_handle, &buf, &buf_size);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Could not get input buffer");
                 goto done;
@@ -865,11 +887,11 @@
             break;
         case HG_OUTPUT:
             /* Use custom header offset */
+            header_offset += hg_handle->hg_info.hg_class->out_offset;
-            header_offset += hg_handle->handle.info.hg_class->out_offset;
             /* Set output proc */
             proc = hg_handle->out_proc;
             /* Get core output buffer */
+            ret = HG_Core_get_output(hg_handle->core_handle, &buf, &buf_size);
-            ret = HG_Core_get_output(hg_handle->handle.core_handle, &buf, &buf_size);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Could not get output buffer");
                 goto done;
@@ -916,7 +938,7 @@
         goto done;
     }
 
+    ret = HG_Bulk_create(hg_handle->hg_info.hg_class, 1, extra_buf,
-    ret = HG_Bulk_create(hg_handle->handle.info.hg_class, 1, extra_buf,
         extra_buf_size, HG_BULK_READWRITE, &local_handle);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not create HG bulk handle");
@@ -925,7 +947,7 @@
 
     /* Read bulk data here and wait for the data to be here  */
     hg_handle->extra_bulk_transfer_cb = done_cb;
+    ret = HG_Bulk_transfer_id(hg_handle->hg_info.context,
-    ret = HG_Bulk_transfer_id(hg_handle->handle.info.context,
         hg_get_extra_payload_cb, hg_handle, HG_BULK_PULL,
         (hg_addr_t) hg_core_info->addr, hg_core_info->context_id,
         *extra_bulk, 0, local_handle, 0, *extra_buf_size,
@@ -948,11 +970,10 @@
 static HG_INLINE hg_return_t
 hg_get_extra_payload_cb(const struct hg_cb_info *callback_info)
 {
+    struct hg_handle *hg_handle = (struct hg_handle *) callback_info->arg;
-    struct hg_private_handle *hg_handle =
-        (struct hg_private_handle *) callback_info->arg;
     hg_return_t ret = HG_SUCCESS;
 
+    ret = hg_handle->extra_bulk_transfer_cb(hg_handle->core_handle);
-    ret = hg_handle->extra_bulk_transfer_cb(hg_handle->handle.core_handle);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not execute bulk transfer callback");
         goto done;
@@ -964,7 +985,7 @@
 
 /*---------------------------------------------------------------------------*/
 static void
+hg_free_extra_payload(struct hg_handle *hg_handle)
-hg_free_extra_payload(struct hg_private_handle *hg_handle)
 {
     /* Free extra bulk buf if there was any */
     if (hg_handle->in_extra_buf) {
@@ -988,8 +1009,8 @@
 static HG_INLINE hg_return_t
 hg_core_forward_cb(const struct hg_core_cb_info *callback_info)
 {
+    struct hg_handle *hg_handle =
+            (struct hg_handle *) callback_info->arg;
-    struct hg_private_handle *hg_handle =
-            (struct hg_private_handle *) callback_info->arg;
     hg_return_t ret = HG_SUCCESS;
 
     /* Execute callback */
@@ -999,7 +1020,7 @@
         hg_cb_info.arg = hg_handle->forward_arg;
         hg_cb_info.ret = callback_info->ret;
         hg_cb_info.type = callback_info->type;
+        hg_cb_info.info.forward.handle = hg_handle;
-        hg_cb_info.info.forward.handle = (hg_handle_t) hg_handle;
 
         hg_handle->forward_cb(&hg_cb_info);
     }
@@ -1011,8 +1032,8 @@
 static HG_INLINE hg_return_t
 hg_core_respond_cb(const struct hg_core_cb_info *callback_info)
 {
+    struct hg_handle *hg_handle =
+            (struct hg_handle *) callback_info->arg;
-    struct hg_private_handle *hg_handle =
-            (struct hg_private_handle *) callback_info->arg;
     hg_return_t ret = HG_SUCCESS;
 
     /* Execute callback */
@@ -1022,7 +1043,7 @@
         hg_cb_info.arg = hg_handle->respond_arg;
         hg_cb_info.ret = callback_info->ret;
         hg_cb_info.type = callback_info->type;
+        hg_cb_info.info.respond.handle = hg_handle;
-        hg_cb_info.info.respond.handle = (hg_handle_t) hg_handle;
 
         hg_handle->respond_cb(&hg_cb_info);
     }
@@ -1076,46 +1097,44 @@
 HG_Init_opt(const char *na_info_string, hg_bool_t na_listen,
     const struct hg_init_info *hg_init_info)
 {
+    struct hg_class *hg_class = NULL;
-    struct hg_private_class *hg_class = NULL;
 
+    hg_class = malloc(sizeof(struct hg_class));
-    hg_class = malloc(sizeof(struct hg_private_class));
     if (!hg_class) {
         HG_LOG_ERROR("Could not allocate HG class");
         goto done;
     }
+    memset(hg_class, 0, sizeof(struct hg_class));
-    memset(hg_class, 0, sizeof(struct hg_private_class));
     hg_thread_spin_init(&hg_class->register_lock);
 
+    hg_class->core_class = HG_Core_init_opt(na_info_string, na_listen,
-    hg_class->hg_class.core_class = HG_Core_init_opt(na_info_string, na_listen,
         hg_init_info);
+    if (!hg_class->core_class) {
-    if (!hg_class->hg_class.core_class) {
         HG_LOG_ERROR("Could not create HG core class");
         goto done;
     }
 
     /* Set more data callback */
+    HG_Core_set_more_data_callback(hg_class->core_class, hg_more_data_cb,
+        hg_more_data_free_cb);
-    HG_Core_set_more_data_callback(hg_class->hg_class.core_class,
-        hg_more_data_cb, hg_more_data_free_cb);
 
 done:
+    return hg_class;
-    return (hg_class_t *) hg_class;
 }
 
 /*---------------------------------------------------------------------------*/
 hg_return_t
 HG_Finalize(hg_class_t *hg_class)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     hg_return_t ret = HG_SUCCESS;
 
+    ret = HG_Core_finalize(hg_class->core_class);
-    ret = HG_Core_finalize(private_class->hg_class.core_class);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not finalize HG core class");
         goto done;
     }
+    hg_thread_spin_destroy(&hg_class->register_lock);
+    free(hg_class);
-    hg_thread_spin_destroy(&private_class->register_lock);
-    free(private_class);
 
 done:
     return ret;
@@ -1129,12 +1148,177 @@
 }
 
 /*---------------------------------------------------------------------------*/
+const char *
+HG_Class_get_name(const hg_class_t *hg_class)
+{
+    const char *ret = NULL;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        goto done;
+    }
+
+    ret = HG_Core_class_get_name(hg_class->core_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+const char *
+HG_Class_get_protocol(const hg_class_t *hg_class)
+{
+    const char *ret = NULL;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        goto done;
+    }
+
+    ret = HG_Core_class_get_protocol(hg_class->core_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_bool_t
+HG_Class_is_listening(const hg_class_t *hg_class)
+{
+    hg_bool_t ret = HG_FALSE;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        goto done;
+    }
+
+    ret = HG_Core_class_is_listening(hg_class->core_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_size_t
+HG_Class_get_input_eager_size(const hg_class_t *hg_class)
+{
+    hg_size_t header = hg_header_get_size(HG_INPUT);
+    hg_size_t ret = 0;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        goto done;
+    }
+
+    ret = HG_Core_class_get_input_eager_size(hg_class->core_class);
+    if (ret > header)
+        ret -= header;
+    else
+        ret = 0;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_size_t
+HG_Class_get_output_eager_size(const hg_class_t *hg_class)
+{
+    hg_size_t ret = 0;
+    hg_size_t header = hg_header_get_size(HG_OUTPUT);
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        goto done;
+    }
+
+    ret = HG_Core_class_get_output_eager_size(hg_class->core_class);
+    if (ret > header)
+        ret -= header;
+    else
+        ret = 0;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Class_set_input_offset(hg_class_t *hg_class, hg_size_t offset)
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    hg_class->in_offset = offset;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Class_set_output_offset(hg_class_t *hg_class, hg_size_t offset)
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    hg_class->out_offset = offset;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Class_set_data(hg_class_t *hg_class, void *data,
+    void (*free_callback)(void *))
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    ret = HG_Core_class_set_data(hg_class->core_class, data, free_callback);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+void *
+HG_Class_get_data(const hg_class_t *hg_class)
+{
+    void *ret = NULL;
+
+    if (!hg_class) {
+        HG_LOG_ERROR("NULL HG class");
+        goto done;
+    }
+
+    ret = HG_Core_class_get_data(hg_class->core_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
 hg_return_t
 HG_Class_set_handle_create_callback(hg_class_t *hg_class,
     hg_return_t (*callback)(hg_handle_t, void *), void *arg)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     hg_return_t ret = HG_SUCCESS;
 
     if (!hg_class) {
@@ -1143,8 +1327,8 @@
         goto done;
     }
 
+    hg_class->handle_create = callback;
+    hg_class->handle_create_arg = arg;
-    private_class->handle_create = callback;
-    private_class->handle_create_arg = arg;
 
 done:
     return ret;
@@ -1231,6 +1415,76 @@
 }
 
 /*---------------------------------------------------------------------------*/
+hg_class_t *
+HG_Context_get_class(const hg_context_t *context)
+{
+    hg_class_t *ret = NULL;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG context");
+        goto done;
+    }
+
+    ret = context->hg_class;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_uint8_t
+HG_Context_get_id(const hg_context_t *context)
+{
+    hg_uint8_t ret = 0;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG context");
+        goto done;
+    }
+
+    ret = HG_Core_context_get_id(context->core_context);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Context_set_data(hg_context_t *context, void *data,
+    void (*free_callback)(void *))
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG context");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    ret = HG_Core_context_set_data(context->core_context, data, free_callback);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+void *
+HG_Context_get_data(const hg_context_t *context)
+{
+    void *ret = NULL;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG context");
+        goto done;
+    }
+
+    ret = HG_Core_context_get_data(context->core_context);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
 hg_id_t
 HG_Register_name(hg_class_t *hg_class, const char *func_name,
     hg_proc_cb_t in_proc_cb, hg_proc_cb_t out_proc_cb, hg_rpc_cb_t rpc_cb)
@@ -1266,8 +1520,6 @@
 HG_Registered_name(hg_class_t *hg_class, const char *func_name, hg_id_t *id,
     hg_bool_t *flag)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     hg_id_t rpc_id = 0;
     hg_return_t ret = HG_SUCCESS;
 
@@ -1282,21 +1534,21 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
 
     /* Generate an ID from the function name */
     rpc_id = hg_hash_string(func_name);
 
+    ret = HG_Core_registered(hg_class->core_class, rpc_id, flag);
-    ret = HG_Core_registered(private_class->hg_class.core_class, rpc_id, flag);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not check for registered RPC id");
+        hg_thread_spin_unlock(&hg_class->register_lock);
-        hg_thread_spin_unlock(&private_class->register_lock);
         goto done;
     }
 
     if (id) *id = rpc_id;
 
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return ret;
@@ -1307,8 +1559,6 @@
 HG_Register(hg_class_t *hg_class, hg_id_t id, hg_proc_cb_t in_proc_cb,
     hg_proc_cb_t out_proc_cb, hg_rpc_cb_t rpc_cb)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     struct hg_proc_info *hg_proc_info = NULL;
     hg_bool_t registered;
     hg_return_t ret = HG_SUCCESS;
@@ -1319,7 +1569,7 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
 
     /* Check if already registered */
     ret = HG_Core_registered(hg_class->core_class, id, &registered);
@@ -1370,7 +1620,7 @@
         free(hg_proc_info);
     }
     if (hg_class)
+        hg_thread_spin_unlock(&hg_class->register_lock);
-        hg_thread_spin_unlock(&private_class->register_lock);
     return ret;
 }
 
@@ -1378,8 +1628,6 @@
 hg_return_t
 HG_Deregister(hg_class_t *hg_class, hg_id_t id)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     hg_return_t ret = HG_SUCCESS;
 
     if (!hg_class) {
@@ -1388,9 +1636,9 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
     ret = HG_Core_deregister(hg_class->core_class, id);
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return ret;
@@ -1400,8 +1648,6 @@
 hg_return_t
 HG_Registered(hg_class_t *hg_class, hg_id_t id, hg_bool_t *flag)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     hg_return_t ret = HG_SUCCESS;
 
     if (!hg_class) {
@@ -1410,9 +1656,9 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
     ret = HG_Core_registered(hg_class->core_class, id, flag);
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return ret;
@@ -1423,8 +1669,6 @@
 HG_Registered_proc_cb(hg_class_t *hg_class, hg_id_t id, hg_bool_t *flag,
     hg_proc_cb_t *in_proc_cb, hg_proc_cb_t *out_proc_cb)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     struct hg_proc_info *hg_proc_info = NULL;
     hg_return_t ret = HG_SUCCESS;
 
@@ -1434,7 +1678,7 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
 
     ret = HG_Core_registered(hg_class->core_class, id, flag);
     if(ret == HG_SUCCESS && *flag) {
@@ -1444,7 +1688,7 @@
         if (!hg_proc_info) {
             HG_LOG_ERROR("Could not get registered data");
             ret = HG_NO_MATCH;
+            hg_thread_spin_unlock(&hg_class->register_lock);
-            hg_thread_spin_unlock(&private_class->register_lock);
             goto done;
         }
         if (in_proc_cb)
@@ -1453,7 +1697,7 @@
             *out_proc_cb = hg_proc_info->out_proc_cb;
     }
 
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return ret;
@@ -1464,8 +1708,6 @@
 HG_Register_data(hg_class_t *hg_class, hg_id_t id, void *data,
     void (*free_callback)(void *))
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     struct hg_proc_info *hg_proc_info = NULL;
     hg_return_t ret = HG_SUCCESS;
 
@@ -1475,7 +1717,7 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
 
     /* Retrieve proc function from function map */
     hg_proc_info = (struct hg_proc_info *) HG_Core_registered_data(
@@ -1483,14 +1725,14 @@
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get registered data");
         ret = HG_NO_MATCH;
+        hg_thread_spin_unlock(&hg_class->register_lock);
-        hg_thread_spin_unlock(&private_class->register_lock);
         goto done;
     }
 
     hg_proc_info->data = data;
     hg_proc_info->free_callback = free_callback;
 
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return ret;
@@ -1500,8 +1742,6 @@
 void *
 HG_Registered_data(hg_class_t *hg_class, hg_id_t id)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     struct hg_proc_info *hg_proc_info = NULL;
     void *data = NULL;
 
@@ -1510,20 +1750,20 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
 
     /* Retrieve proc function from function map */
     hg_proc_info = (struct hg_proc_info *) HG_Core_registered_data(
         hg_class->core_class, id);
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get registered data");
+        hg_thread_spin_unlock(&hg_class->register_lock);
-        hg_thread_spin_unlock(&private_class->register_lock);
         goto done;
     }
 
     data = hg_proc_info->data;
 
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return data;
@@ -1534,8 +1774,6 @@
 HG_Registered_disable_response(hg_class_t *hg_class, hg_id_t id,
     hg_bool_t disable)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     struct hg_proc_info *hg_proc_info = NULL;
     hg_return_t ret = HG_SUCCESS;
 
@@ -1545,7 +1783,7 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
 
     /* Retrieve proc function from function map */
     hg_proc_info = (struct hg_proc_info *) HG_Core_registered_data(
@@ -1553,13 +1791,13 @@
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get registered data");
         ret = HG_NO_MATCH;
+        hg_thread_spin_unlock(&hg_class->register_lock);
-        hg_thread_spin_unlock(&private_class->register_lock);
         goto done;
     }
 
     hg_proc_info->no_response = disable;
 
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return ret;
@@ -1570,8 +1808,6 @@
 HG_Registered_disabled_response(hg_class_t *hg_class, hg_id_t id,
     hg_bool_t *disabled)
 {
-    struct hg_private_class *private_class =
-        (struct hg_private_class *) hg_class;
     struct hg_proc_info *hg_proc_info = NULL;
     hg_return_t ret = HG_SUCCESS;
 
@@ -1586,7 +1822,7 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_class->register_lock);
-    hg_thread_spin_lock(&private_class->register_lock);
 
     /* Retrieve proc function from function map */
     hg_proc_info = (struct hg_proc_info *) HG_Core_registered_data(
@@ -1594,13 +1830,13 @@
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get registered data");
         ret = HG_NO_MATCH;
+        hg_thread_spin_unlock(&hg_class->register_lock);
-        hg_thread_spin_unlock(&private_class->register_lock);
         goto done;
     }
 
     *disabled = hg_proc_info->no_response;
 
+    hg_thread_spin_unlock(&hg_class->register_lock);
-    hg_thread_spin_unlock(&private_class->register_lock);
 
 done:
     return ret;
@@ -1724,7 +1960,7 @@
 HG_Create(hg_context_t *context, hg_addr_t addr, hg_id_t id,
     hg_handle_t *handle)
 {
+    struct hg_handle *hg_handle = NULL;
-    struct hg_private_handle *hg_handle = NULL;
     hg_core_handle_t core_handle;
     hg_return_t ret = HG_SUCCESS;
 
@@ -1744,9 +1980,9 @@
     }
 
     /* Get data and HG info */
+    hg_handle = (struct hg_handle *) HG_Core_get_data(core_handle);
+    hg_handle->hg_info.addr = addr;
+    hg_handle->hg_info.id = id;
-    hg_handle = (struct hg_private_handle *) HG_Core_get_data(core_handle);
-    hg_handle->handle.info.addr = addr;
-    hg_handle->handle.info.id = id;
 
     *handle = (hg_handle_t) hg_handle;
 
@@ -1776,8 +2012,6 @@
 hg_return_t
 HG_Reset(hg_handle_t handle, hg_addr_t addr, hg_id_t id)
 {
-    struct hg_private_handle *private_handle =
-        (struct hg_private_handle *) handle;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -1794,9 +2028,97 @@
     }
 
     /* Set info */
+    handle->hg_info.addr = addr;
+    handle->hg_info.id = id;
+    handle->hg_info.context_id = 0;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Ref_incr(hg_handle_t handle)
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!handle) {
+        HG_LOG_ERROR("NULL HG handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    ret = HG_Core_ref_incr(handle->core_handle);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_int32_t
+HG_Ref_get(hg_handle_t handle)
+{
+    hg_int32_t ret = -1;
+
+    if (!handle) {
+        HG_LOG_ERROR("NULL HG handle");
+        goto done;
+    }
+
+    ret = HG_Core_ref_get(handle->core_handle);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+const struct hg_info *
+HG_Get_info(hg_handle_t handle)
+{
+    const struct hg_info *ret = NULL;
+
+    if (!handle) {
+        HG_LOG_ERROR("NULL HG handle");
+        goto done;
+    }
+
+    ret = &handle->hg_info;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Set_data(hg_handle_t handle, void *data, void (*free_callback)(void *))
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!handle) {
+        HG_LOG_ERROR("NULL HG handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    handle->data = data;
+    handle->data_free_callback = free_callback;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+void *
+HG_Get_data(hg_handle_t handle)
+{
+    void *ret = NULL;
+
+    if (!handle) {
+        HG_LOG_ERROR("NULL HG handle");
+        goto done;
+    }
+
+    ret = handle->data;
-    private_handle->handle.info.addr = addr;
-    private_handle->handle.info.id = id;
-    private_handle->handle.info.context_id = 0;
 
 done:
     return ret;
@@ -1806,7 +2128,7 @@
 hg_return_t
 HG_Get_input(hg_handle_t handle, void *in_struct)
 {
+    struct hg_proc_info *hg_proc_info;
-    const struct hg_proc_info *hg_proc_info;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -1821,7 +2143,7 @@
     }
 
     /* Retrieve RPC data */
+    hg_proc_info = (struct hg_proc_info *) hg_core_get_rpc_data(
-    hg_proc_info = (const struct hg_proc_info *) HG_Core_get_rpc_data(
         handle->core_handle);
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get proc info");
@@ -1830,8 +2152,7 @@
     }
 
     /* Get input struct */
+    ret = hg_get_struct(handle, hg_proc_info, HG_INPUT, in_struct);
-    ret = hg_get_struct((struct hg_private_handle *) handle, hg_proc_info,
-        HG_INPUT, in_struct);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not get input");
         goto done;
@@ -1845,7 +2166,7 @@
 hg_return_t
 HG_Free_input(hg_handle_t handle, void *in_struct)
 {
+    struct hg_proc_info *hg_proc_info;
-    const struct hg_proc_info *hg_proc_info;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -1860,7 +2181,7 @@
     }
 
     /* Retrieve RPC data */
+    hg_proc_info = (struct hg_proc_info *) hg_core_get_rpc_data(
-    hg_proc_info = (const struct hg_proc_info *) HG_Core_get_rpc_data(
         handle->core_handle);
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get proc info");
@@ -1869,8 +2190,7 @@
     }
 
     /* Free input struct */
+    ret = hg_free_struct(handle, hg_proc_info, HG_INPUT, in_struct);
-    ret = hg_free_struct((struct hg_private_handle *) handle, hg_proc_info,
-        HG_INPUT, in_struct);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not free input");
         goto done;
@@ -1884,7 +2204,7 @@
 hg_return_t
 HG_Get_output(hg_handle_t handle, void *out_struct)
 {
+    struct hg_proc_info *hg_proc_info;
-    const struct hg_proc_info *hg_proc_info;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -1899,7 +2219,7 @@
     }
 
     /* Retrieve RPC data */
+    hg_proc_info = (struct hg_proc_info *) hg_core_get_rpc_data(
-    hg_proc_info = (const struct hg_proc_info *) HG_Core_get_rpc_data(
         handle->core_handle);
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get proc info");
@@ -1908,8 +2228,7 @@
     }
 
     /* Get output struct */
+    ret = hg_get_struct(handle, hg_proc_info, HG_OUTPUT, out_struct);
-    ret = hg_get_struct((struct hg_private_handle *) handle, hg_proc_info,
-        HG_OUTPUT, out_struct);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not get output");
         goto done;
@@ -1923,7 +2242,7 @@
 hg_return_t
 HG_Free_output(hg_handle_t handle, void *out_struct)
 {
+    struct hg_proc_info *hg_proc_info;
-    const struct hg_proc_info *hg_proc_info;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -1938,7 +2257,7 @@
     }
 
     /* Retrieve RPC data */
+    hg_proc_info = (struct hg_proc_info *) hg_core_get_rpc_data(
-    hg_proc_info = (const struct hg_proc_info *) HG_Core_get_rpc_data(
         handle->core_handle);
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get proc info");
@@ -1947,8 +2266,7 @@
     }
 
     /* Free output struct */
+    ret = hg_free_struct(handle, hg_proc_info, HG_OUTPUT, out_struct);
-    ret = hg_free_struct((struct hg_private_handle *) handle, hg_proc_info,
-        HG_OUTPUT, out_struct);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not free output");
         goto done;
@@ -1962,8 +2280,6 @@
 hg_return_t
 HG_Get_input_buf(hg_handle_t handle, void **in_buf, hg_size_t *in_buf_size)
 {
-    struct hg_private_handle *private_handle =
-        (struct hg_private_handle *) handle;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -1979,9 +2295,9 @@
 
     /* Space must be left for input header, no offset if extra buffer since
      * only the user payload is copied */
+    if (handle->in_extra_buf) {
+        *in_buf = handle->in_extra_buf;
+        *in_buf_size = handle->in_extra_buf_size;
-    if (private_handle->in_extra_buf) {
-        *in_buf = private_handle->in_extra_buf;
-        *in_buf_size = private_handle->in_extra_buf_size;
     } else {
         void *buf;
         hg_size_t buf_size, header_offset = hg_header_get_size(HG_INPUT);
@@ -2005,8 +2321,6 @@
 hg_return_t
 HG_Get_output_buf(hg_handle_t handle, void **out_buf, hg_size_t *out_buf_size)
 {
-    struct hg_private_handle *private_handle =
-        (struct hg_private_handle *) handle;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -2022,9 +2336,9 @@
 
     /* Space must be left for output header, no offset if extra buffer since
      * only the user payload is copied */
+    if (handle->out_extra_buf) {
+        *out_buf = handle->out_extra_buf;
+        *out_buf_size = handle->out_extra_buf_size;
-    if (private_handle->out_extra_buf) {
-        *out_buf = private_handle->out_extra_buf;
-        *out_buf_size = private_handle->out_extra_buf_size;
     } else {
         void *buf;
         hg_size_t buf_size, header_offset = hg_header_get_size(HG_OUTPUT);
@@ -2046,11 +2360,32 @@
 
 /*---------------------------------------------------------------------------*/
 hg_return_t
+HG_Set_target_id(hg_handle_t handle, hg_uint8_t id)
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!handle) {
+        HG_LOG_ERROR("NULL HG handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    ret = HG_Core_set_target_id(handle->core_handle, id);
+    if (ret != HG_SUCCESS) {
+        HG_LOG_ERROR("Could not set target id");
+        goto done;
+    }
+    handle->hg_info.context_id = id;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
 HG_Forward(hg_handle_t handle, hg_cb_t callback, void *arg, void *in_struct)
 {
+    struct hg_proc_info *hg_proc_info;
-    struct hg_private_handle *private_handle =
-        (struct hg_private_handle *) handle;
-    const struct hg_proc_info *hg_proc_info;
     hg_size_t payload_size;
     hg_bool_t more_data = HG_FALSE;
     hg_uint8_t flags = 0;
@@ -2063,11 +2398,11 @@
     }
 
     /* Set callback data */
+    handle->forward_cb = callback;
+    handle->forward_arg = arg;
-    private_handle->forward_cb = callback;
-    private_handle->forward_arg = arg;
 
     /* Retrieve RPC data */
+    hg_proc_info = (struct hg_proc_info *) hg_core_get_rpc_data(
-    hg_proc_info = (const struct hg_proc_info *) HG_Core_get_rpc_data(
         handle->core_handle);
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get proc info");
@@ -2076,7 +2411,7 @@
     }
 
     /* Set input struct */
+    ret = hg_set_struct(handle, hg_proc_info, HG_INPUT, in_struct,
-    ret = hg_set_struct(private_handle, hg_proc_info, HG_INPUT, in_struct,
         &payload_size, &more_data);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not set input");
@@ -2107,9 +2442,7 @@
 hg_return_t
 HG_Respond(hg_handle_t handle, hg_cb_t callback, void *arg, void *out_struct)
 {
+    struct hg_proc_info *hg_proc_info;
-    struct hg_private_handle *private_handle =
-        (struct hg_private_handle *) handle;
-    const struct hg_proc_info *hg_proc_info;
     hg_size_t payload_size;
     hg_bool_t more_data = HG_FALSE;
     hg_uint8_t flags = 0;
@@ -2122,11 +2455,11 @@
     }
 
     /* Set callback data */
+    handle->respond_cb = callback;
+    handle->respond_arg = arg;
-    private_handle->respond_cb = callback;
-    private_handle->respond_arg = arg;
 
     /* Retrieve RPC data */
+    hg_proc_info = (struct hg_proc_info *) hg_core_get_rpc_data(
-    hg_proc_info = (const struct hg_proc_info *) HG_Core_get_rpc_data(
         handle->core_handle);
     if (!hg_proc_info) {
         HG_LOG_ERROR("Could not get proc info");
@@ -2135,7 +2468,7 @@
     }
 
     /* Set output struct */
+    ret = hg_set_struct(handle, hg_proc_info, HG_OUTPUT, out_struct,
-    ret = hg_set_struct(private_handle, hg_proc_info, HG_OUTPUT, out_struct,
         &payload_size, &more_data);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not set output");
--- b/src/mercury.h
+++ a/src/mercury.h
@@ -12,10 +12,6 @@
 #define MERCURY_H
 
 #include "mercury_types.h"
-#include "mercury_header.h"
-#include "mercury_error.h"
-
-#include "mercury_core.h"
 
 /*************************************/
 /* Public Type and Struct Definition */
@@ -132,7 +128,7 @@
  *
  * \return the name of the class, or NULL if not a valid class
  */
+HG_EXPORT const char *
-static HG_INLINE const char *
 HG_Class_get_name(
         const hg_class_t *hg_class
         );
@@ -144,7 +140,7 @@
  *
  * \return the name of the class's transport, or NULL if not a valid class
  */
+HG_EXPORT const char *
-static HG_INLINE const char *
 HG_Class_get_protocol(
         const hg_class_t *hg_class
         );
@@ -156,7 +152,7 @@
  *
  * \return HG_TRUE if listening or HG_FALSE if not, or not a valid class
  */
+HG_EXPORT hg_bool_t
-static HG_INLINE hg_bool_t
 HG_Class_is_listening(
         const hg_class_t *hg_class
         );
@@ -170,7 +166,7 @@
  * \return the maximum size, or 0 if hg_class is not a valid class or XDR is
  * being used
  */
+HG_EXPORT hg_size_t
-static HG_INLINE hg_size_t
 HG_Class_get_input_eager_size(
         const hg_class_t *hg_class
         );
@@ -184,7 +180,7 @@
  * \return the maximum size, or 0 if hg_class is not a valid class or XDR is
  * being used
  */
+HG_EXPORT hg_size_t
-static HG_INLINE hg_size_t
 HG_Class_get_output_eager_size(
         const hg_class_t *hg_class
         );
@@ -200,7 +196,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Class_set_input_offset(
         hg_class_t *hg_class,
         hg_size_t offset
@@ -217,7 +213,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Class_set_output_offset(
         hg_class_t *hg_class,
         hg_size_t offset
@@ -233,7 +229,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Class_set_data(
         hg_class_t *hg_class,
         void *data,
@@ -247,7 +243,7 @@
  *
  * \return Pointer to user data or NULL if not set or any error has occurred
  */
+HG_EXPORT void *
-static HG_INLINE void *
 HG_Class_get_data(
         const hg_class_t *hg_class
         );
@@ -329,7 +325,7 @@
  *
  * \return Pointer to associated HG class or NULL if not a valid context
  */
+HG_EXPORT hg_class_t *
-static HG_INLINE hg_class_t *
 HG_Context_get_class(
         const hg_context_t *context
         );
@@ -341,7 +337,7 @@
  *
  * \return Non-negative integer (max value of 255) or 0 if no ID has been set
  */
+HG_EXPORT hg_uint8_t
-static HG_INLINE hg_uint8_t
 HG_Context_get_id(
         const hg_context_t *context
         );
@@ -356,7 +352,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Context_set_data(
         hg_context_t *context,
         void *data,
@@ -370,7 +366,7 @@
  *
  * \return Pointer to user data or NULL if not set or any error has occurred
  */
+HG_EXPORT void *
-static HG_INLINE void *
 HG_Context_get_data(
         const hg_context_t *context
         );
@@ -656,6 +652,7 @@
         hg_addr_t   addr
         );
 
+
 /**
  * Initiate a new HG RPC using the specified function ID and the local/remote
  * target defined by addr. The HG handle created can be used to query input
@@ -716,7 +713,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Ref_incr(
         hg_handle_t hg_handle
         );
@@ -728,7 +725,7 @@
  *
  * \return Non-negative value or negative if the handle is not valid
  */
+HG_EXPORT hg_int32_t
-static HG_INLINE hg_int32_t
 HG_Ref_get(
         hg_handle_t handle
         );
@@ -742,7 +739,7 @@
  *
  * \return Pointer to info or NULL in case of failure
  */
+HG_EXPORT const struct hg_info *
-static HG_INLINE const struct hg_info *
 HG_Get_info(
         hg_handle_t handle
         );
@@ -757,7 +754,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Set_data(
         hg_handle_t handle,
         void *data,
@@ -771,7 +768,7 @@
  *
  * \return Pointer to user data or NULL if not set or any error has occurred
  */
+HG_EXPORT void *
-static HG_INLINE void *
 HG_Get_data(
         hg_handle_t handle
         );
@@ -904,7 +901,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Set_target_id(
         hg_handle_t handle,
         hg_uint8_t id
@@ -1013,297 +1010,6 @@
         hg_handle_t handle
         );
 
-/************************************/
-/* Local Type and Struct Definition */
-/************************************/
-
-/* HG class */
-struct hg_class {
-    hg_core_class_t *core_class;        /* Core class */
-    hg_size_t in_offset;                /* Input offset */
-    hg_size_t out_offset;               /* Output offset */
-};
-
-/* HG context */
-struct hg_context {
-    hg_core_context_t *core_context;    /* Core context */
-    hg_class_t *hg_class;               /* HG class */
-};
-
-/* HG handle */
-struct hg_handle {
-    hg_core_handle_t core_handle;       /* Core handle */
-    struct hg_info info;                /* HG info */
-    void *data;                         /* User data */
-    void (*data_free_callback)(void *); /* User data free callback */
-};
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE const char *
-HG_Class_get_name(const hg_class_t *hg_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return NULL;
-    }
-#endif
-    return HG_Core_class_get_name(hg_class->core_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE const char *
-HG_Class_get_protocol(const hg_class_t *hg_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return NULL;
-    }
-#endif
-    return HG_Core_class_get_protocol(hg_class->core_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_bool_t
-HG_Class_is_listening(const hg_class_t *hg_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return HG_FALSE;
-    }
-#endif
-    return HG_Core_class_is_listening(hg_class->core_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_size_t
-HG_Class_get_input_eager_size(const hg_class_t *hg_class)
-{
-    hg_size_t core, header;
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return 0;
-    }
-#endif
-    core = HG_Core_class_get_input_eager_size(hg_class->core_class);
-    header = hg_header_get_size(HG_INPUT);
-
-    return (core > header) ? core - header : 0;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_size_t
-HG_Class_get_output_eager_size(const hg_class_t *hg_class)
-{
-    hg_size_t core, header;
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return 0;
-    }
-#endif
-    core = HG_Core_class_get_output_eager_size(hg_class->core_class);
-    header = hg_header_get_size(HG_OUTPUT);
-
-    return (core > header) ? core - header : 0;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Class_set_input_offset(hg_class_t *hg_class, hg_size_t offset)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    hg_class->in_offset = offset;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Class_set_output_offset(hg_class_t *hg_class, hg_size_t offset)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    hg_class->out_offset = offset;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Class_set_data(hg_class_t *hg_class, void *data,
-    void (*free_callback)(void *))
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    return HG_Core_class_set_data(hg_class->core_class, data, free_callback);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE void *
-HG_Class_get_data(const hg_class_t *hg_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_class) {
-        HG_LOG_ERROR("NULL HG class");
-        return NULL;
-    }
-#endif
-    return HG_Core_class_get_data(hg_class->core_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_class_t *
-HG_Context_get_class(const hg_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG context");
-        return NULL;
-    }
-#endif
-    return context->hg_class;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_uint8_t
-HG_Context_get_id(const hg_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG context");
-        return 0;
-    }
-#endif
-    return HG_Core_context_get_id(context->core_context);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Context_set_data(hg_context_t *context, void *data,
-    void (*free_callback)(void *))
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG context");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    return HG_Core_context_set_data(context->core_context, data, free_callback);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE void *
-HG_Context_get_data(const hg_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG context");
-        return NULL;
-    }
-#endif
-    return HG_Core_context_get_data(context->core_context);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Ref_incr(hg_handle_t handle)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL HG handle");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    return HG_Core_ref_incr(handle->core_handle);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_int32_t
-HG_Ref_get(hg_handle_t handle)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL HG handle");
-        return -1;
-    }
-#endif
-    return HG_Core_ref_get(handle->core_handle);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE const struct hg_info *
-HG_Get_info(hg_handle_t handle)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL HG handle");
-        return NULL;
-    }
-#endif
-    return &handle->info;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Set_data(hg_handle_t handle, void *data, void (*free_callback)(void *))
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL HG handle");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    handle->data = data;
-    handle->data_free_callback = free_callback;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE void *
-HG_Get_data(hg_handle_t handle)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL HG handle");
-        return NULL;
-    }
-#endif
-    return handle->data;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Set_target_id(hg_handle_t handle, hg_uint8_t id)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL HG handle");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    handle->info.context_id = id;
-
-    return HG_Core_set_target_id(handle->core_handle, id);
-}
-
 #ifdef __cplusplus
 }
 #endif
--- b/src/mercury_bulk.c
+++ a/src/mercury_bulk.c
@@ -13,7 +13,7 @@
 #include "mercury_private.h"
 #include "mercury_error.h"
 
+#include "na_private.h"
-#include "na.h"
 
 #include "mercury_atomic.h"
 
@@ -379,7 +379,7 @@
     na_class_t *na_sm_class = HG_Core_class_get_na_sm(hg_class->core_class);
 #endif
     hg_bool_t use_register_segments = (hg_bool_t)
+        (na_class->mem_handle_create_segments && count > 1);
-        (na_class->ops->mem_handle_create_segments && count > 1);
     unsigned int i;
 
     hg_bulk = (struct hg_bulk *) malloc(sizeof(struct hg_bulk));
@@ -867,8 +867,7 @@
         (hg_core_addr_t) origin_addr);
     hg_bool_t is_self = NA_Addr_is_self(na_origin_addr_class, na_origin_addr);
     hg_bool_t scatter_gather =
+        (na_class->mem_handle_create_segments && !is_self) ? HG_TRUE : HG_FALSE;
-        (na_class->ops->mem_handle_create_segments && !is_self) ? HG_TRUE :
-            HG_FALSE;
     hg_return_t ret = HG_SUCCESS;
     unsigned int i;
 
@@ -1644,8 +1643,8 @@
         buf_ptr += serialize_size;
         buf_size_left -= (ssize_t) serialize_size;
 
+        hg_bulk->addr = HG_Core_addr_create(hg_bulk->hg_class->core_class);
+        if (hg_bulk->addr == HG_CORE_ADDR_NULL) {
-        ret = HG_Core_addr_create(hg_bulk->hg_class->core_class, &hg_bulk->addr);
-        if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Could not create core addr");
             ret = HG_NOMEM_ERROR;
             goto done;
--- b/src/mercury_core.c
+++ a/src/mercury_core.c
@@ -9,22 +9,26 @@
  */
 
 #include "mercury_core.h"
+#include "mercury_core_header.h"
 #include "mercury_private.h"
+#include "mercury_error.h"
 
-#include "mercury_atomic_queue.h"
-#ifdef HG_HAS_SELF_FORWARD
-#include "mercury_event.h"
-#endif
 #include "mercury_hash_table.h"
+#include "mercury_atomic.h"
+#include "mercury_queue.h"
 #include "mercury_list.h"
-#include "mercury_mem.h"
-#include "mercury_poll.h"
-#include "mercury_queue.h"
-#include "mercury_thread_condition.h"
 #include "mercury_thread_mutex.h"
-#include "mercury_thread_pool.h"
 #include "mercury_thread_spin.h"
+#include "mercury_thread_condition.h"
 #include "mercury_time.h"
+#include "mercury_atomic.h"
+#include "mercury_poll.h"
+#include "mercury_thread_pool.h"
+#ifdef HG_HAS_SELF_FORWARD
+#include "mercury_event.h"
+#endif
+#include "mercury_atomic_queue.h"
+#include "mercury_mem.h"
 
 #ifdef HG_HAS_SM_ROUTING
 #include <uuid/uuid.h>
@@ -42,7 +46,6 @@
 #define HG_CORE_ATOMIC_QUEUE_SIZE   1024
 #define HG_CORE_PENDING_INCR        256
 #define HG_CORE_PROCESSING_TIMEOUT  1000
-#define HG_CORE_MAX_TRIGGER_COUNT   1
 #ifdef HG_HAS_SM_ROUTING
 # define HG_CORE_UUID_MAX_LEN       36
 # define HG_CORE_ADDR_MAX_SIZE      256
@@ -74,22 +77,15 @@
 #define HG_CORE_STAT_INIT HG_ATOMIC_VAR_INIT
 #endif
 
-#define HG_CORE_CONTEXT_CLASS(context) \
-    ((struct hg_core_private_class *)(context->core_context.core_class))
-
-#define HG_CORE_HANDLE_CLASS(handle) \
-    ((struct hg_core_private_class *)(handle->core_handle.info.core_class))
-#define HG_CORE_HANDLE_CONTEXT(handle) \
-    ((struct hg_core_private_context *)(handle->core_handle.info.context))
-
 /************************************/
 /* Local Type and Struct Definition */
 /************************************/
 
 /* HG class */
+struct hg_core_class {
+    na_class_t *na_class;               /* NA class */
-struct hg_core_private_class {
-    struct hg_core_class core_class;    /* Must remain as first field */
 #ifdef HG_HAS_SM_ROUTING
+    na_class_t *na_sm_class;            /* NA SM class */
     uuid_t na_sm_uuid;                  /* UUID for local identification */
 #endif
     hg_hash_table_t *func_map;          /* Function map */
@@ -101,6 +97,8 @@
 #ifdef HG_HAS_COLLECT_STATS
     hg_bool_t stats;                    /* (Debug) Print stats at exit */
 #endif
+    void *data;                         /* User data */
+    void (*data_free_callback)(void *); /* User data free callback */
     hg_atomic_int32_t n_contexts;       /* Atomic used for number of contexts */
     hg_atomic_int32_t n_addrs;          /* Atomic used for number of addrs */
 
@@ -111,34 +109,47 @@
 };
 
 /* HG context */
+struct hg_core_context {
+    struct hg_core_class *hg_core_class;          /* HG core class */
+    na_context_t *na_context;                     /* NA context */
+#ifdef HG_HAS_SM_ROUTING
+    na_context_t *na_sm_context;                  /* NA SM context */
+#endif
+    hg_uint8_t id;                                /* Context ID */
+    struct hg_poll_set *poll_set;                 /* Context poll set */
-struct hg_core_private_context {
-    struct hg_core_context core_context;        /* Must remain as first field */
-    struct hg_poll_set *poll_set;               /* Context poll set */
     /* Pointer to function used for making progress */
+    hg_return_t (*progress)(struct hg_core_context *context, unsigned int timeout);
+    struct hg_atomic_queue *completion_queue;     /* Default completion queue */
-    hg_return_t (*progress)(struct hg_core_private_context *context,
-        unsigned int timeout);
-    struct hg_atomic_queue *completion_queue;   /* Default completion queue */
     HG_QUEUE_HEAD(hg_completion_entry) backfill_queue; /* Backfill completion queue */
+    hg_atomic_int32_t backfill_queue_count;       /* Backfill queue count */
+    hg_thread_mutex_t completion_queue_mutex;     /* Completion queue mutex */
+    hg_thread_cond_t  completion_queue_cond;      /* Completion queue cond */
+    hg_atomic_int32_t trigger_waiting;            /* Waiting in trigger */
+    HG_LIST_HEAD(hg_core_handle) pending_list;    /* List of pending handles */
+    hg_thread_spin_t pending_list_lock;           /* Pending list lock */
-    hg_atomic_int32_t backfill_queue_count;     /* Backfill queue count */
-    hg_thread_mutex_t completion_queue_mutex;   /* Completion queue mutex */
-    hg_thread_cond_t  completion_queue_cond;    /* Completion queue cond */
-    hg_atomic_int32_t trigger_waiting;          /* Waiting in trigger */
-    HG_LIST_HEAD(hg_core_private_handle) pending_list;  /* List of pending handles */
-    hg_thread_spin_t pending_list_lock;         /* Pending list lock */
 #ifdef HG_HAS_SM_ROUTING
+    HG_LIST_HEAD(hg_core_handle) sm_pending_list; /* List of SM pending handles */
+    hg_thread_spin_t sm_pending_list_lock;        /* SM pending list lock */
-    HG_LIST_HEAD(hg_core_private_handle) sm_pending_list; /* List of SM pending handles */
-    hg_thread_spin_t sm_pending_list_lock;      /* SM pending list lock */
 #endif
+    HG_LIST_HEAD(hg_core_handle) created_list;    /* List of handles for that context */
+    hg_thread_spin_t created_list_lock;           /* Handle list lock */
-    HG_LIST_HEAD(hg_core_private_handle) created_list;  /* List of handles for that context */
-    hg_thread_spin_t created_list_lock;         /* Handle list lock */
 #ifdef HG_HAS_SELF_FORWARD
+    int completion_queue_notify;                  /* Self notification */
+    hg_thread_pool_t *self_processing_pool;       /* Thread pool for self processing */
-    int completion_queue_notify;                /* Self notification */
-    hg_thread_pool_t *self_processing_pool;     /* Thread pool for self processing */
 #endif
     hg_return_t (*handle_create)(hg_core_handle_t, void *); /* handle_create */
+    void *handle_create_arg;                      /* handle_create arg */
+    void *data;                                   /* User data */
+    void (*data_free_callback)(void *);           /* User data free callback */
+    hg_bool_t finalizing;                         /* Prevent reposts */
+    hg_atomic_int32_t n_handles;                  /* Atomic used for number of handles */
+};
+
+/* Info for function map */
+struct hg_core_rpc_info {
+    hg_core_rpc_cb_t rpc_cb;        /* RPC callback */
+    void *data;                     /* User data */
+    void (*free_callback)(void *);  /* User data free callback */
-    void *handle_create_arg;                    /* handle_create arg */
-    hg_bool_t finalizing;                       /* Prevent reposts */
-    hg_atomic_int32_t n_handles;                /* Atomic used for number of handles */
 };
 
 #ifdef HG_HAS_SELF_FORWARD
@@ -152,9 +163,11 @@
 #endif
 
 /* HG addr */
+struct hg_core_addr {
+    na_class_t *na_class;               /* NA class from NA address */
+    na_addr_t na_addr;                  /* NA address */
-struct hg_core_private_addr {
-    struct hg_core_addr core_addr;      /* Must remain as first field */
 #ifdef HG_HAS_SM_ROUTING
+    na_addr_t na_sm_addr;               /* NA SM address */
     uuid_t na_sm_uuid;                  /* NA SM UUID */
 #endif
     hg_bool_t is_mine;                  /* Created internally or not */
@@ -174,8 +187,8 @@
 } hg_core_op_type_t;
 
 /* HG core handle */
+struct hg_core_handle {
+    struct hg_core_info hg_info;        /* HG info */
-struct hg_core_private_handle {
-    struct hg_core_handle core_handle;  /* Must remain as first field */
     na_class_t *na_class;               /* NA class */
     na_context_t *na_context;           /* NA context */
     hg_core_cb_t request_callback;      /* Request callback */
@@ -186,17 +199,23 @@
     na_tag_t tag;                       /* Tag used for request and response */
     hg_uint8_t cookie;                  /* Cookie */
     hg_return_t ret;                    /* Return code associated to handle */
+    HG_LIST_ENTRY(hg_core_handle) created;  /* Created list entry */
+    HG_LIST_ENTRY(hg_core_handle) pending;  /* Pending list entry */
-    HG_LIST_ENTRY(hg_core_private_handle) created;  /* Created list entry */
-    HG_LIST_ENTRY(hg_core_private_handle) pending;  /* Pending list entry */
     struct hg_completion_entry hg_completion_entry; /* Entry in completion queue */
     hg_bool_t repost;                   /* Repost handle on completion (listen) */
     hg_bool_t is_self;                  /* Self processed */
     hg_atomic_int32_t in_use;           /* Is in use */
     hg_bool_t no_response;              /* Require response or not */
 
+    void *in_buf;                       /* Input buffer */
     void *in_buf_plugin_data;           /* Input buffer NA plugin data */
+    na_size_t in_buf_size;              /* Input buffer size */
+    na_size_t na_in_header_offset;      /* Input NA header offset */
     na_size_t in_buf_used;              /* Amount of input buffer used */
+    void *out_buf;                      /* Output buffer */
     void *out_buf_plugin_data;          /* Output buffer NA plugin data */
+    na_size_t out_buf_size;             /* Output buffer size */
+    na_size_t na_out_header_offset;     /* Output NA header offset */
     na_size_t out_buf_used;             /* Amount of output buffer used */
     void *ack_buf;                      /* Ack buf for more data */
     void *ack_buf_plugin_data;          /* Ack plugin data */
@@ -208,32 +227,37 @@
     hg_atomic_int32_t na_op_completed_count;    /* Number of NA operations completed */
     hg_bool_t na_op_id_mine;            /* Operation ID created by HG */
 
+    hg_atomic_int32_t ref_count;        /* Reference count */
+
     struct hg_core_header in_header;    /* Input header */
     struct hg_core_header out_header;   /* Output header */
 
+    struct hg_core_rpc_info *hg_core_rpc_info;  /* Associated RPC info */
+    void *data;                         /* User data */
+    void (*data_free_callback)(void *); /* User data free callback */
+
-    hg_atomic_int32_t ref_count;        /* Reference count */
     struct hg_thread_work thread_work;  /* Used for self processing and testing */
 
     /* Callbacks */
     hg_return_t (*forward)(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         ); /* forward */
     hg_return_t (*respond)(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         ); /* respond */
     hg_return_t (*no_respond)(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         ); /* no_respond */
 };
 
 /* HG op id */
 struct hg_core_op_info_lookup {
+    struct hg_core_addr *hg_core_addr;  /* Address */
-    struct hg_core_private_addr *hg_core_addr; /* Address */
     na_op_id_t na_lookup_op_id;         /* Operation ID for lookup */
 };
 
 struct hg_core_op_id {
+    struct hg_core_context *context;    /* Context */
-    struct hg_core_private_context *context; /* Context */
     hg_cb_type_t type;                  /* Callback type */
     hg_core_cb_t callback;              /* Callback */
     void *arg;                          /* Callback arguments */
@@ -288,10 +312,24 @@
  */
 static HG_INLINE na_tag_t
 hg_core_gen_request_tag(
+        struct hg_core_class *hg_core_class
-        struct hg_core_private_class *hg_core_class
         );
 
 /**
+ * Retrieve usable buffer to store input payload.
+ */
+static HG_INLINE void
+hg_core_get_input(struct hg_core_handle *hg_core_handle, void **in_buf,
+    hg_size_t *in_buf_size);
+
+/**
+ * Retrieve usable buffer to store output payload.
+ */
+static HG_INLINE void
+hg_core_get_output(struct hg_core_handle *hg_core_handle, void **out_buf,
+    hg_size_t *out_buf_size);
+
+/**
  * Proc request header and verify it if decoded.
  */
 static HG_INLINE hg_return_t
@@ -316,7 +354,7 @@
  */
 static hg_return_t
 hg_core_pending_list_cancel(
+        struct hg_core_context *context
-        struct hg_core_private_context *context
         );
 
 #ifdef HG_HAS_SM_ROUTING
@@ -325,7 +363,7 @@
  */
 static hg_return_t
 hg_core_sm_pending_list_cancel(
+        struct hg_core_context *context
-        struct hg_core_private_context *context
         );
 #endif
 
@@ -334,13 +372,13 @@
  */
 static hg_return_t
 hg_core_created_list_wait(
+        struct hg_core_context *context
-        struct hg_core_private_context *context
         );
 
 /**
  * Initialize class.
  */
+static struct hg_core_class *
-static struct hg_core_private_class *
 hg_core_init(
         const char *na_info_string,
         hg_bool_t na_listen,
@@ -352,15 +390,15 @@
  */
 static hg_return_t
 hg_core_finalize(
+        struct hg_core_class *hg_core_class
-        struct hg_core_private_class *hg_core_class
         );
 
 /**
  * Create addr.
  */
+static struct hg_core_addr *
-static struct hg_core_private_addr *
 hg_core_addr_create(
+        struct hg_core_class *hg_core_class,
-        struct hg_core_private_class *hg_core_class,
         na_class_t *na_class
         );
 
@@ -369,7 +407,7 @@
  */
 static hg_return_t
 hg_core_addr_lookup(
+        struct hg_core_context *context,
-        struct hg_core_private_context *context,
         hg_core_cb_t callback,
         void *arg,
         const char *name,
@@ -397,8 +435,8 @@
  */
 static hg_return_t
 hg_core_addr_free(
+        struct hg_core_class *hg_core_class,
+        struct hg_core_addr *hg_core_addr
-        struct hg_core_private_class *hg_core_class,
-        struct hg_core_private_addr *hg_core_addr
         );
 
 /**
@@ -406,8 +444,8 @@
  */
 static hg_return_t
 hg_core_addr_self(
+        struct hg_core_class *hg_core_class,
+        struct hg_core_addr **self_addr
-        struct hg_core_private_class *hg_core_class,
-        struct hg_core_private_addr **self_addr
         );
 
 /**
@@ -415,9 +453,9 @@
  */
 static hg_return_t
 hg_core_addr_dup(
+        struct hg_core_class *hg_core_class,
+        struct hg_core_addr *hg_core_addr,
+        struct hg_core_addr **hg_new_addr
-        struct hg_core_private_class *hg_core_class,
-        struct hg_core_private_addr *hg_core_addr,
-        struct hg_core_private_addr **hg_new_addr
         );
 
 /**
@@ -425,18 +463,18 @@
  */
 static hg_return_t
 hg_core_addr_to_string(
+        struct hg_core_class *hg_core_class,
-        struct hg_core_private_class *hg_core_class,
         char *buf,
         hg_size_t *buf_size,
+        struct hg_core_addr *hg_core_addr
-        struct hg_core_private_addr *hg_core_addr
         );
 
 /**
  * Create handle.
  */
+static struct hg_core_handle *
-static struct hg_core_private_handle *
 hg_core_create(
+        struct hg_core_context *context,
-        struct hg_core_private_context *context,
         hg_bool_t use_sm
         );
 
@@ -445,7 +483,7 @@
  */
 static void
 hg_core_destroy(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -453,7 +491,7 @@
  */
 static void
 hg_core_reset(
+        struct hg_core_handle *hg_core_handle,
-        struct hg_core_private_handle *hg_core_handle,
         hg_bool_t reset_info
         );
 
@@ -462,18 +500,26 @@
  */
 static hg_return_t
 hg_core_set_rpc(
+        struct hg_core_handle *hg_core_handle,
+        hg_core_addr_t addr,
-        struct hg_core_private_handle *hg_core_handle,
-        struct hg_core_private_addr *addr,
         hg_id_t id
         );
 
+/**
+ * Get RPC registered data.
+ */
+void *
+hg_core_get_rpc_data(
+        struct hg_core_handle *hg_core_handle
+        );
+
 #ifdef HG_HAS_SELF_FORWARD
 /**
  * Forward handle locally.
  */
 static hg_return_t
 hg_core_forward_self(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 #endif
 
@@ -482,7 +528,7 @@
  */
 static hg_return_t
 hg_core_forward_na(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 #ifdef HG_HAS_SELF_FORWARD
@@ -491,7 +537,7 @@
  */
 static HG_INLINE hg_return_t
 hg_core_respond_self(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -499,7 +545,7 @@
  */
 static HG_INLINE hg_return_t
 hg_core_no_respond_self(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 #endif
 
@@ -508,7 +554,7 @@
  */
 static hg_return_t
 hg_core_respond_na(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -516,7 +562,7 @@
  */
 static HG_INLINE hg_return_t
 hg_core_no_respond_na(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -540,7 +586,7 @@
  */
 static hg_return_t
 hg_core_process_input(
+        struct hg_core_handle *hg_core_handle,
-        struct hg_core_private_handle *hg_core_handle,
         hg_bool_t *completed
         );
 
@@ -565,7 +611,7 @@
  */
 static hg_return_t
 hg_core_process_output(
+        struct hg_core_handle *hg_core_handle,
-        struct hg_core_private_handle *hg_core_handle,
         hg_bool_t *completed,
         hg_return_t (*done_callback)(hg_core_handle_t)
         );
@@ -575,7 +621,7 @@
  */
 static hg_return_t
 hg_core_send_ack(
+        struct hg_core_handle *hg_core_handle
-        hg_core_handle_t handle
         );
 
 /**
@@ -617,7 +663,7 @@
  */
 static hg_return_t
 hg_core_process(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -625,7 +671,7 @@
  */
 static HG_INLINE hg_return_t
 hg_core_complete_na(
+        struct hg_core_handle *hg_core_handle,
-        struct hg_core_private_handle *hg_core_handle,
         na_op_id_t *op_id,
         hg_bool_t *completed
         );
@@ -635,7 +681,7 @@
  */
 static HG_INLINE hg_return_t
 hg_core_complete(
+        struct hg_core_handle *hg_core_handle
-        hg_core_handle_t handle
         );
 
 /**
@@ -653,7 +699,7 @@
  */
 static hg_return_t
 hg_core_context_post(
+        struct hg_core_context *context,
-        struct hg_core_private_context *context,
         unsigned int request_count,
         hg_bool_t repost,
         hg_bool_t use_sm
@@ -664,7 +710,7 @@
  */
 static hg_return_t
 hg_core_post(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -672,7 +718,7 @@
  */
 static hg_return_t
 hg_core_reset_post(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -680,7 +726,7 @@
  */
 static hg_return_t
 hg_core_progress_na(
+        struct hg_core_context *context,
-        struct hg_core_private_context *context,
         unsigned int timeout
         );
 
@@ -688,7 +734,7 @@
 /**
  * Completion queue notification callback.
  */
+static int
-static HG_INLINE int
 hg_core_completion_queue_notify_cb(
         void *arg,
         unsigned int timeout,
@@ -734,7 +780,7 @@
  */
 static hg_return_t
 hg_core_progress_poll(
+        struct hg_core_context *context,
-        struct hg_core_private_context *context,
         unsigned int timeout
         );
 
@@ -743,7 +789,7 @@
  */
 static hg_return_t
 hg_core_trigger(
+        struct hg_core_context *context,
-        struct hg_core_private_context *context,
         unsigned int timeout,
         unsigned int max_count,
         unsigned int *actual_count
@@ -762,7 +808,7 @@
  */
 static hg_return_t
 hg_core_trigger_entry(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 /**
@@ -778,7 +824,7 @@
  */
 static hg_return_t
 hg_core_cancel(
+        struct hg_core_handle *hg_core_handle
-        struct hg_core_private_handle *hg_core_handle
         );
 
 #ifdef HG_HAS_COLLECT_STATS
@@ -881,7 +927,7 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_INLINE na_tag_t
+hg_core_gen_request_tag(struct hg_core_class *hg_core_class)
-hg_core_gen_request_tag(struct hg_core_private_class *hg_core_class)
 {
     na_tag_t request_tag = 0;
 
@@ -896,6 +942,32 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static HG_INLINE void
+hg_core_get_input(struct hg_core_handle *hg_core_handle, void **in_buf,
+    hg_size_t *in_buf_size)
+{
+    hg_size_t header_offset = hg_core_header_request_get_size() +
+        hg_core_handle->na_in_header_offset;
+
+    /* Space must be left for request header */
+    *in_buf = (char *) hg_core_handle->in_buf + header_offset;
+    *in_buf_size = hg_core_handle->in_buf_size - header_offset;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_INLINE void
+hg_core_get_output(struct hg_core_handle *hg_core_handle, void **out_buf,
+    hg_size_t *out_buf_size)
+{
+    hg_size_t header_offset = hg_core_header_response_get_size() +
+        hg_core_handle->na_out_header_offset;
+
+    /* Space must be left for response header */
+    *out_buf = (char *) hg_core_handle->out_buf + header_offset;
+    *out_buf_size = hg_core_handle->out_buf_size - header_offset;
+}
+
+/*---------------------------------------------------------------------------*/
 static HG_INLINE hg_return_t
 hg_core_proc_header_request(struct hg_core_handle *hg_core_handle,
     struct hg_core_header *hg_core_header, hg_proc_op_t op)
@@ -959,15 +1031,14 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_pending_list_cancel(struct hg_core_context *context)
-hg_core_pending_list_cancel(struct hg_core_private_context *context)
 {
     hg_return_t ret = HG_SUCCESS;
 
     hg_thread_spin_lock(&context->pending_list_lock);
 
     while (!HG_LIST_IS_EMPTY(&context->pending_list)) {
+        struct hg_core_handle *hg_core_handle = HG_LIST_FIRST(&context->pending_list);
-        struct hg_core_private_handle *hg_core_handle =
-            HG_LIST_FIRST(&context->pending_list);
         HG_LIST_REMOVE(hg_core_handle, pending);
 
         /* Prevent reposts */
@@ -989,15 +1060,14 @@
 /*---------------------------------------------------------------------------*/
 #ifdef HG_HAS_SM_ROUTING
 static hg_return_t
+hg_core_sm_pending_list_cancel(struct hg_core_context *context)
-hg_core_sm_pending_list_cancel(struct hg_core_private_context *context)
 {
     hg_return_t ret = HG_SUCCESS;
 
     hg_thread_spin_lock(&context->sm_pending_list_lock);
 
     while (!HG_LIST_IS_EMPTY(&context->sm_pending_list)) {
+        struct hg_core_handle *hg_core_handle = HG_LIST_FIRST(&context->sm_pending_list);
-        struct hg_core_private_handle *hg_core_handle =
-            HG_LIST_FIRST(&context->sm_pending_list);
         HG_LIST_REMOVE(hg_core_handle, pending);
 
         /* Prevent reposts */
@@ -1019,7 +1089,7 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_created_list_wait(struct hg_core_context *context)
-hg_core_created_list_wait(struct hg_core_private_context *context)
 {
     hg_util_bool_t created_list_empty = HG_UTIL_FALSE;
     /* Convert timeout in ms into seconds */
@@ -1059,11 +1129,11 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static struct hg_core_class *
-static struct hg_core_private_class *
 hg_core_init(const char *na_info_string, hg_bool_t na_listen,
     const struct hg_init_info *hg_init_info)
 {
+    struct hg_core_class *hg_core_class = NULL;
-    struct hg_core_private_class *hg_core_class = NULL;
     na_tag_t na_max_tag;
 #ifdef HG_HAS_SM_ROUTING
     na_tag_t na_sm_max_tag;
@@ -1072,20 +1142,19 @@
     hg_return_t ret = HG_SUCCESS;
 
     /* Create new HG class */
+    hg_core_class = (struct hg_core_class *) malloc(sizeof(struct hg_core_class));
-    hg_core_class = (struct hg_core_private_class *) malloc(
-        sizeof(struct hg_core_private_class));
     if (!hg_core_class) {
         HG_LOG_ERROR("Could not allocate HG class");
         ret = HG_NOMEM_ERROR;
         goto done;
     }
+    memset(hg_core_class, 0, sizeof(struct hg_core_class));
-    memset(hg_core_class, 0, sizeof(struct hg_core_private_class));
 
     /* Parse options */
     if (hg_init_info) {
         /* External NA class */
         if (hg_init_info->na_class) {
+            hg_core_class->na_class = hg_init_info->na_class;
-            hg_core_class->core_class.na_class = hg_init_info->na_class;
             hg_core_class->na_ext_init = HG_TRUE;
         }
         hg_core_class->progress_mode = hg_init_info->na_init_info.progress_mode;
@@ -1112,9 +1181,9 @@
 
     /* Initialize NA if not provided externally */
     if (!hg_core_class->na_ext_init) {
+        hg_core_class->na_class = NA_Initialize_opt(na_info_string, na_listen,
+            &hg_init_info->na_init_info);
+        if (!hg_core_class->na_class) {
-        hg_core_class->core_class.na_class = NA_Initialize_opt(
-            na_info_string, na_listen, &hg_init_info->na_init_info);
-        if (!hg_core_class->core_class.na_class) {
             HG_LOG_ERROR("Could not initialize NA class");
             ret = HG_NA_ERROR;
             goto done;
@@ -1124,8 +1193,7 @@
 #ifdef HG_HAS_SM_ROUTING
     /* Initialize SM plugin */
     if (auto_sm) {
+        if (strcmp(NA_Get_class_name(hg_core_class->na_class), "na") == 0) {
-        if (strcmp(NA_Get_class_name(hg_core_class->core_class.na_class),
-            "na") == 0) {
             HG_LOG_ERROR("Cannot use auto SM mode if initialized NA class is "
                 "already using SM");
             ret = HG_PROTOCOL_ERROR;
@@ -1133,9 +1201,9 @@
         }
 
         /* Initialize NA SM first so that tmp directories are created */
+        hg_core_class->na_sm_class = NA_Initialize_opt("na+sm", na_listen,
+            &hg_init_info->na_init_info);
+        if (!hg_core_class->na_sm_class) {
-        hg_core_class->core_class.na_sm_class = NA_Initialize_opt("na+sm",
-            na_listen, &hg_init_info->na_init_info);
-        if (!hg_core_class->core_class.na_sm_class) {
             HG_LOG_ERROR("Could not initialize NA SM class");
             ret = HG_NA_ERROR;
             goto done;
@@ -1151,7 +1219,7 @@
 #endif
 
     /* Compute max request tag */
+    na_max_tag = NA_Msg_get_max_tag(hg_core_class->na_class);
-    na_max_tag = NA_Msg_get_max_tag(hg_core_class->core_class.na_class);
     if (!na_max_tag) {
         HG_LOG_ERROR("NA Max tag is not defined");
         ret = HG_NA_ERROR;
@@ -1161,8 +1229,7 @@
 
 #ifdef HG_HAS_SM_ROUTING
     if (auto_sm) {
+        na_sm_max_tag = NA_Msg_get_max_tag(hg_core_class->na_sm_class);
-        na_sm_max_tag = NA_Msg_get_max_tag(
-            hg_core_class->core_class.na_sm_class);
         if (!na_max_tag) {
             HG_LOG_ERROR("NA Max tag is not defined");
             ret = HG_NA_ERROR;
@@ -1206,7 +1273,7 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_finalize(struct hg_core_class *hg_core_class)
-hg_core_finalize(struct hg_core_private_class *hg_core_class)
 {
     hg_util_int32_t n_addrs, n_contexts;
     hg_return_t ret = HG_SUCCESS;
@@ -1235,26 +1302,25 @@
     hg_core_class->func_map = NULL;
 
     /* Free user data */
+    if (hg_core_class->data_free_callback)
+        hg_core_class->data_free_callback(hg_core_class->data);
-    if (hg_core_class->core_class.data_free_callback)
-        hg_core_class->core_class.data_free_callback(
-            hg_core_class->core_class.data);
 
     /* Destroy mutex */
     hg_thread_spin_destroy(&hg_core_class->func_map_lock);
 
     if (!hg_core_class->na_ext_init) {
         /* Finalize interface */
+        if (NA_Finalize(hg_core_class->na_class) != NA_SUCCESS) {
-        if (NA_Finalize(hg_core_class->core_class.na_class) != NA_SUCCESS) {
             HG_LOG_ERROR("Could not finalize NA interface");
             ret = HG_NA_ERROR;
             goto done;
         }
+        hg_core_class->na_class = NULL;
-        hg_core_class->core_class.na_class = NULL;
     }
 
 #ifdef HG_HAS_SM_ROUTING
     /* Finalize SM interface */
+    if (NA_Finalize(hg_core_class->na_sm_class) != NA_SUCCESS) {
-    if (NA_Finalize(hg_core_class->core_class.na_sm_class) != NA_SUCCESS) {
         HG_LOG_ERROR("Could not finalize NA SM interface");
         ret = HG_NA_ERROR;
         goto done;
@@ -1269,23 +1335,21 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static struct hg_core_addr *
+hg_core_addr_create(struct hg_core_class *hg_core_class, na_class_t *na_class)
-static struct hg_core_private_addr *
-hg_core_addr_create(struct hg_core_private_class *hg_core_class,
-    na_class_t *na_class)
 {
+    struct hg_core_addr *hg_core_addr = NULL;
-    struct hg_core_private_addr *hg_core_addr = NULL;
 
+    hg_core_addr = (struct hg_core_addr *) malloc(sizeof(struct hg_core_addr));
-    hg_core_addr = (struct hg_core_private_addr *) malloc(
-        sizeof(struct hg_core_private_addr));
     if (!hg_core_addr) {
         HG_LOG_ERROR("Could not allocate HG addr");
         goto done;
     }
+    memset(hg_core_addr, 0, sizeof(struct hg_core_addr));
+    hg_core_addr->na_class = na_class;
+    hg_core_addr->na_addr = NA_ADDR_NULL;
-    memset(hg_core_addr, 0, sizeof(struct hg_core_private_addr));
-    hg_core_addr->core_addr.na_class = na_class;
-    hg_core_addr->core_addr.na_addr = NA_ADDR_NULL;
 #ifdef HG_HAS_SM_ROUTING
+    hg_core_addr->na_sm_addr = NA_ADDR_NULL;
-    hg_core_addr->core_addr.na_sm_addr = NA_ADDR_NULL;
 #endif
     hg_atomic_init32(&hg_core_addr->ref_count, 1);
 
@@ -1298,13 +1362,13 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_addr_lookup(struct hg_core_context *context, hg_core_cb_t callback, void *arg,
+    const char *name, hg_core_op_id_t *op_id)
-hg_core_addr_lookup(struct hg_core_private_context *context,
-    hg_core_cb_t callback, void *arg, const char *name, hg_core_op_id_t *op_id)
 {
+    na_class_t *na_class = context->hg_core_class->na_class;
+    na_context_t *na_context = context->na_context;
-    na_class_t *na_class = context->core_context.core_class->na_class;
-    na_context_t *na_context = context->core_context.na_context;
     struct hg_core_op_id *hg_core_op_id = NULL;
+    struct hg_core_addr *hg_core_addr = NULL;
-    struct hg_core_private_addr *hg_core_addr = NULL;
     na_return_t na_ret;
 #ifdef HG_HAS_SM_ROUTING
     char lookup_name[HG_CORE_ADDR_MAX_SIZE] = {'\0'};
@@ -1328,7 +1392,7 @@
     hg_core_op_id->info.lookup.na_lookup_op_id = NA_OP_ID_NULL;
 
     /* Allocate addr */
+    hg_core_addr = hg_core_addr_create(context->hg_core_class, NULL);
-    hg_core_addr = hg_core_addr_create(HG_CORE_CONTEXT_CLASS(context), NULL);
     if (!hg_core_addr) {
         HG_LOG_ERROR("Could not create HG addr");
         ret = HG_NOMEM_ERROR;
@@ -1361,12 +1425,11 @@
         local_name = lookup_names;
 
         /* Compare UUIDs, if they match it's local address */
+        if (context->na_sm_context && uuid_compare(hg_core_addr->na_sm_uuid,
+            context->hg_core_class->na_sm_uuid) == 0) {
-        if (context->core_context.na_sm_context
-            && uuid_compare(hg_core_addr->na_sm_uuid,
-            HG_CORE_CONTEXT_CLASS(context)->na_sm_uuid) == 0) {
             name_str = local_name;
+            na_class = context->hg_core_class->na_sm_class;
+            na_context = context->na_sm_context;
-            na_class = context->core_context.core_class->na_sm_class;
-            na_context = context->core_context.na_sm_context;
         } else {
             /* Remote lookup */
             name_str = remote_name;
@@ -1374,7 +1437,7 @@
     }
 #endif
     /* Assign corresponding NA class */
+    hg_core_addr->na_class = na_class;
-    hg_core_addr->core_addr.na_class = na_class;
 
     /* Assign op_id */
     if (op_id && op_id != HG_CORE_OP_ID_IGNORE)
@@ -1401,7 +1464,7 @@
     if (ret != HG_SUCCESS) {
         free(hg_core_op_id);
         if (hg_core_addr != NULL)
+            hg_core_addr_free(context->hg_core_class, hg_core_addr);
-            hg_core_addr_free(HG_CORE_CONTEXT_CLASS(context), hg_core_addr);
     }
 
     return ret;
@@ -1411,8 +1474,7 @@
 static int
 hg_core_addr_lookup_cb(const struct na_cb_info *callback_info)
 {
+    struct hg_core_op_id *hg_core_op_id = (struct hg_core_op_id *) callback_info->arg;
-    struct hg_core_op_id *hg_core_op_id =
-        (struct hg_core_op_id *) callback_info->arg;
     na_return_t na_ret = NA_SUCCESS;
     int ret = 0;
 
@@ -1421,8 +1483,7 @@
     }
 
     /* Assign addr */
+    hg_core_op_id->info.lookup.hg_core_addr->na_addr = callback_info->info.lookup.addr;
-    hg_core_op_id->info.lookup.hg_core_addr->core_addr.na_addr =
-        callback_info->info.lookup.addr;
 
     /* Mark as completed */
     if (hg_core_addr_lookup_complete(hg_core_op_id) != HG_SUCCESS) {
@@ -1440,7 +1501,7 @@
 static hg_return_t
 hg_core_addr_lookup_complete(struct hg_core_op_id *hg_core_op_id)
 {
+    hg_core_context_t *context = hg_core_op_id->context;
-    hg_core_context_t *context = &hg_core_op_id->context->core_context;
     struct hg_completion_entry *hg_completion_entry =
         &hg_core_op_id->hg_completion_entry;
     hg_return_t ret = HG_SUCCESS;
@@ -1463,8 +1524,7 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_addr_free(struct hg_core_class *hg_core_class, struct hg_core_addr *hg_core_addr)
-hg_core_addr_free(struct hg_core_private_class *hg_core_class,
-    struct hg_core_private_addr *hg_core_addr)
 {
     hg_return_t ret = HG_SUCCESS;
     na_return_t na_ret;
@@ -1480,10 +1540,8 @@
     hg_atomic_decr32(&hg_core_class->n_addrs);
 
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_addr->na_sm_addr != NA_ADDR_NULL) { /* Self address case with SM */
+        na_ret = NA_Addr_free(hg_core_class->na_sm_class, hg_core_addr->na_sm_addr);
-    /* Self address case with SM */
-    if (hg_core_addr->core_addr.na_sm_addr != NA_ADDR_NULL) {
-        na_ret = NA_Addr_free(hg_core_class->core_class.na_sm_class,
-            hg_core_addr->core_addr.na_sm_addr);
         if (na_ret != NA_SUCCESS) {
             HG_LOG_ERROR("Could not free NA SM address");
             ret = HG_NA_ERROR;
@@ -1493,8 +1551,7 @@
 #endif
 
     /* Free NA address */
+    na_ret = NA_Addr_free(hg_core_addr->na_class, hg_core_addr->na_addr);
-    na_ret = NA_Addr_free(hg_core_addr->core_addr.na_class,
-        hg_core_addr->core_addr.na_addr);
     if (na_ret != NA_SUCCESS) {
         HG_LOG_ERROR("Could not free address");
         ret = HG_NA_ERROR;
@@ -1508,23 +1565,21 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_addr_self(struct hg_core_class *hg_core_class,
+    struct hg_core_addr **self_addr)
-hg_core_addr_self(struct hg_core_private_class *hg_core_class,
-    struct hg_core_private_addr **self_addr)
 {
+    struct hg_core_addr *hg_core_addr = NULL;
-    struct hg_core_private_addr *hg_core_addr = NULL;
     hg_return_t ret = HG_SUCCESS;
     na_return_t na_ret;
 
+    hg_core_addr = hg_core_addr_create(hg_core_class, hg_core_class->na_class);
-    hg_core_addr = hg_core_addr_create(hg_core_class,
-        hg_core_class->core_class.na_class);
     if (!hg_core_addr) {
         HG_LOG_ERROR("Could not create HG addr");
         ret = HG_NOMEM_ERROR;
         goto done;
     }
 
+    na_ret = NA_Addr_self(hg_core_class->na_class, &hg_core_addr->na_addr);
-    na_ret = NA_Addr_self(hg_core_class->core_class.na_class,
-        &hg_core_addr->core_addr.na_addr);
     if (na_ret != NA_SUCCESS) {
         HG_LOG_ERROR("Could not get self address");
         ret = HG_NA_ERROR;
@@ -1532,10 +1587,9 @@
     }
 
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_class->na_sm_class) {
-    if (hg_core_class->core_class.na_sm_class) {
         /* Get SM address */
+        na_ret = NA_Addr_self(hg_core_class->na_sm_class, &hg_core_addr->na_sm_addr);
-        na_ret = NA_Addr_self(hg_core_class->core_class.na_sm_class,
-            &hg_core_addr->core_addr.na_sm_addr);
         if (na_ret != NA_SUCCESS) {
             HG_LOG_ERROR("Could not get self SM address");
             ret = HG_NA_ERROR;
@@ -1555,9 +1609,8 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_addr_dup(struct hg_core_class *hg_core_class,
+    struct hg_core_addr *hg_core_addr, struct hg_core_addr **hg_new_addr)
-hg_core_addr_dup(struct hg_core_private_class *hg_core_class,
-    struct hg_core_private_addr *hg_core_addr,
-    struct hg_core_private_addr **hg_new_addr)
 {
     hg_return_t ret = HG_SUCCESS;
     na_return_t na_ret;
@@ -1568,17 +1621,16 @@
      * refcount of original address.
      */
     if (hg_core_addr->is_mine) {
+        struct hg_core_addr *dup = NULL;
-        struct hg_core_private_addr *dup = NULL;
 
+        dup = hg_core_addr_create(hg_core_class, hg_core_addr->na_class);
-        dup = hg_core_addr_create(hg_core_class,
-            hg_core_addr->core_addr.na_class);
         if (!dup) {
             HG_LOG_ERROR("Could not create HG addr");
             ret = HG_NOMEM_ERROR;
             goto done;
         }
+        na_ret = NA_Addr_dup(hg_core_addr->na_class, hg_core_addr->na_addr,
+            &dup->na_addr);
-        na_ret = NA_Addr_dup(hg_core_addr->core_addr.na_class,
-            hg_core_addr->core_addr.na_addr, &dup->core_addr.na_addr);
         if (na_ret != NA_SUCCESS) {
             HG_LOG_ERROR("Could not duplicate address");
             ret = HG_NA_ERROR;
@@ -1596,8 +1648,8 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_addr_to_string(struct hg_core_class *hg_core_class, char *buf, hg_size_t *buf_size,
+    struct hg_core_addr *hg_core_addr)
-hg_core_addr_to_string(struct hg_core_private_class *hg_core_class, char *buf,
-    hg_size_t *buf_size, struct hg_core_private_addr *hg_core_addr)
 {
     char *buf_ptr = buf;
     hg_size_t new_buf_size = 0, buf_size_used = 0;
@@ -1612,7 +1664,7 @@
     new_buf_size = *buf_size;
 
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_addr->na_sm_addr) {
-    if (hg_core_addr->core_addr.na_sm_addr) {
         char addr_str[HG_CORE_ADDR_MAX_SIZE];
         char uuid_str[HG_CORE_UUID_MAX_LEN + 1];
         int desc_len;
@@ -1635,8 +1687,8 @@
             new_buf_size = *buf_size - (hg_size_t) desc_len;
 
         /* Get NA SM address string */
+        na_ret = NA_Addr_to_string(hg_core_class->na_sm_class, buf_ptr,
+            &new_buf_size, hg_core_addr->na_sm_addr);
-        na_ret = NA_Addr_to_string(hg_core_class->core_class.na_sm_class,
-            buf_ptr, &new_buf_size, hg_core_addr->core_addr.na_sm_addr);
         if (na_ret != NA_SUCCESS) {
             HG_LOG_ERROR("Could not convert SM address to string");
             ret = HG_NA_ERROR;
@@ -1653,8 +1705,8 @@
 #endif
 
     /* Get NA address string */
+    na_ret = NA_Addr_to_string(hg_core_class->na_class, buf_ptr, &new_buf_size,
+        hg_core_addr->na_addr);
-    na_ret = NA_Addr_to_string(hg_core_class->core_class.na_class, buf_ptr,
-        &new_buf_size, hg_core_addr->core_addr.na_addr);
     if (na_ret != NA_SUCCESS) {
         HG_LOG_ERROR("Could not convert address to string");
         ret = HG_NA_ERROR;
@@ -1667,34 +1719,31 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static struct hg_core_handle *
+hg_core_create(struct hg_core_context *context, hg_bool_t HG_UNUSED use_sm)
-static struct hg_core_private_handle *
-hg_core_create(struct hg_core_private_context *context,
-    hg_bool_t HG_UNUSED use_sm)
 {
+    na_class_t *na_class = context->hg_core_class->na_class;
+    na_context_t *na_context = context->na_context;
+    struct hg_core_handle *hg_core_handle = NULL;
-    na_class_t *na_class = context->core_context.core_class->na_class;
-    na_context_t *na_context = context->core_context.na_context;
-    struct hg_core_private_handle *hg_core_handle = NULL;
     hg_return_t ret = HG_SUCCESS;
 
+    hg_core_handle = (struct hg_core_handle *) malloc(sizeof(struct hg_core_handle));
-    hg_core_handle = (struct hg_core_private_handle *) malloc(
-        sizeof(struct hg_core_private_handle));
     if (!hg_core_handle) {
         HG_LOG_ERROR("Could not allocate handle");
         goto done;
     }
+    memset(hg_core_handle, 0, sizeof(struct hg_core_handle));
-    memset(hg_core_handle, 0, sizeof(struct hg_core_private_handle));
 
     hg_core_handle->op_type = HG_CORE_PROCESS; /* Default */
+    hg_core_handle->hg_info.hg_core_class = context->hg_core_class;
+    hg_core_handle->hg_info.context = context;
+    hg_core_handle->hg_info.addr = HG_CORE_ADDR_NULL;
+    hg_core_handle->hg_info.id = 0;
+    hg_core_handle->hg_info.context_id = 0;
-    hg_core_handle->core_handle.info.core_class =
-        context->core_context.core_class;
-    hg_core_handle->core_handle.info.context = &context->core_context;
-    hg_core_handle->core_handle.info.addr = HG_CORE_ADDR_NULL;
-    hg_core_handle->core_handle.info.id = 0;
-    hg_core_handle->core_handle.info.context_id = 0;
 #ifdef HG_HAS_SM_ROUTING
     if (use_sm) {
+        na_class = context->hg_core_class->na_sm_class;
+        na_context = context->na_sm_context;
-        na_class = context->core_context.core_class->na_sm_class;
-        na_context = context->core_context.na_sm_context;
     }
 #endif
     hg_core_handle->na_class = na_class;
@@ -1702,45 +1751,37 @@
     hg_core_handle->ret = HG_SUCCESS;
 
     /* Add handle to handle list so that we can track it */
+    hg_thread_spin_lock(&hg_core_handle->hg_info.context->created_list_lock);
+    HG_LIST_INSERT_HEAD(&hg_core_handle->hg_info.context->created_list,
-    hg_thread_spin_lock(&HG_CORE_HANDLE_CONTEXT(hg_core_handle)->created_list_lock);
-    HG_LIST_INSERT_HEAD(&HG_CORE_HANDLE_CONTEXT(hg_core_handle)->created_list,
         hg_core_handle, created);
+    hg_thread_spin_unlock(&hg_core_handle->hg_info.context->created_list_lock);
-    hg_thread_spin_unlock(&HG_CORE_HANDLE_CONTEXT(hg_core_handle)->created_list_lock);
 
     /* Handle is not in use */
     hg_atomic_init32(&hg_core_handle->in_use, HG_FALSE);
 
     /* Initialize processing buffers and use unexpected message size */
+    hg_core_handle->in_buf_size = NA_Msg_get_max_unexpected_size(na_class);
+    hg_core_handle->out_buf_size = NA_Msg_get_max_expected_size(na_class);
+    hg_core_handle->na_in_header_offset = NA_Msg_get_unexpected_header_size(na_class);
+    hg_core_handle->na_out_header_offset = NA_Msg_get_expected_header_size(na_class);
+
+    hg_core_handle->in_buf = NA_Msg_buf_alloc(na_class, hg_core_handle->in_buf_size,
-    hg_core_handle->core_handle.in_buf_size =
-        NA_Msg_get_max_unexpected_size(na_class);
-    hg_core_handle->core_handle.out_buf_size =
-        NA_Msg_get_max_expected_size(na_class);
-    hg_core_handle->core_handle.na_in_header_offset =
-        NA_Msg_get_unexpected_header_size(na_class);
-    hg_core_handle->core_handle.na_out_header_offset =
-        NA_Msg_get_expected_header_size(na_class);
-
-    hg_core_handle->core_handle.in_buf = NA_Msg_buf_alloc(na_class,
-        hg_core_handle->core_handle.in_buf_size,
         &hg_core_handle->in_buf_plugin_data);
+    if (!hg_core_handle->in_buf) {
-    if (!hg_core_handle->core_handle.in_buf) {
         HG_LOG_ERROR("Could not allocate buffer for input");
         ret = HG_NOMEM_ERROR;
         goto done;
     }
+    NA_Msg_init_unexpected(na_class, hg_core_handle->in_buf, hg_core_handle->in_buf_size);
-    NA_Msg_init_unexpected(na_class, hg_core_handle->core_handle.in_buf,
-        hg_core_handle->core_handle.in_buf_size);
 
+    hg_core_handle->out_buf = NA_Msg_buf_alloc(na_class, hg_core_handle->out_buf_size,
-    hg_core_handle->core_handle.out_buf = NA_Msg_buf_alloc(na_class,
-        hg_core_handle->core_handle.out_buf_size,
         &hg_core_handle->out_buf_plugin_data);
+    if (!hg_core_handle->out_buf) {
-    if (!hg_core_handle->core_handle.out_buf) {
         HG_LOG_ERROR("Could not allocate buffer for output");
         ret = HG_NOMEM_ERROR;
         goto done;
     }
+    NA_Msg_init_expected(na_class, hg_core_handle->out_buf, hg_core_handle->out_buf_size);
-    NA_Msg_init_expected(na_class, hg_core_handle->core_handle.out_buf,
-        hg_core_handle->core_handle.out_buf_size);
 
     /* Init in/out header */
     hg_core_header_request_init(&hg_core_handle->in_header);
@@ -1777,7 +1818,7 @@
 
 /*---------------------------------------------------------------------------*/
 static void
+hg_core_destroy(struct hg_core_handle *hg_core_handle)
-hg_core_destroy(struct hg_core_private_handle *hg_core_handle)
 {
     na_return_t na_ret;
 
@@ -1789,16 +1830,15 @@
     }
 
     /* Remove handle from list */
+    hg_thread_spin_lock(&hg_core_handle->hg_info.context->created_list_lock);
-    hg_thread_spin_lock(&HG_CORE_HANDLE_CONTEXT(hg_core_handle)->created_list_lock);
     HG_LIST_REMOVE(hg_core_handle, created);
+    hg_thread_spin_unlock(&hg_core_handle->hg_info.context->created_list_lock);
-    hg_thread_spin_unlock(&HG_CORE_HANDLE_CONTEXT(hg_core_handle)->created_list_lock);
 
     /* Decrement N handles from HG context */
+    hg_atomic_decr32(&hg_core_handle->hg_info.context->n_handles);
-    hg_atomic_decr32(&HG_CORE_HANDLE_CONTEXT(hg_core_handle)->n_handles);
 
     /* Remove reference to HG addr */
+    hg_core_addr_free(hg_core_handle->hg_info.hg_core_class, hg_core_handle->hg_info.addr);
-    hg_core_addr_free(HG_CORE_HANDLE_CLASS(hg_core_handle),
-        (struct hg_core_private_addr *) hg_core_handle->core_handle.info.addr);
 
     na_ret = NA_Op_destroy(hg_core_handle->na_class, hg_core_handle->na_send_op_id);
     if (na_ret != NA_SUCCESS)
@@ -1810,27 +1850,26 @@
     hg_core_header_request_finalize(&hg_core_handle->in_header);
     hg_core_header_response_finalize(&hg_core_handle->out_header);
 
+    na_ret = NA_Msg_buf_free(hg_core_handle->na_class, hg_core_handle->in_buf,
+        hg_core_handle->in_buf_plugin_data);
-    na_ret = NA_Msg_buf_free(hg_core_handle->na_class,
-        hg_core_handle->core_handle.in_buf, hg_core_handle->in_buf_plugin_data);
     if (na_ret != NA_SUCCESS)
         HG_LOG_ERROR("Could not destroy NA input msg buffer");
+    na_ret = NA_Msg_buf_free(hg_core_handle->na_class, hg_core_handle->out_buf,
+        hg_core_handle->out_buf_plugin_data);
-    na_ret = NA_Msg_buf_free(hg_core_handle->na_class,
-        hg_core_handle->core_handle.out_buf, hg_core_handle->out_buf_plugin_data);
     if (na_ret != NA_SUCCESS)
         HG_LOG_ERROR("Could not destroy NA output msg buffer");
 
     /* Free extra data here if needed */
+    if (hg_core_handle->hg_info.hg_core_class->more_data_release)
+        hg_core_handle->hg_info.hg_core_class->more_data_release(
-    if (HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_release)
-        HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_release(
             (hg_core_handle_t) hg_core_handle);
     if (hg_core_handle->ack_buf)
         NA_Msg_buf_free(hg_core_handle->na_class, hg_core_handle->ack_buf,
             hg_core_handle->ack_buf_plugin_data);
 
     /* Free user data */
+    if (hg_core_handle->data_free_callback)
+        hg_core_handle->data_free_callback(hg_core_handle->data);
-    if (hg_core_handle->core_handle.data_free_callback)
-        hg_core_handle->core_handle.data_free_callback(
-            hg_core_handle->core_handle.data);
 
     free(hg_core_handle);
 
@@ -1840,20 +1879,18 @@
 
 /*---------------------------------------------------------------------------*/
 static void
+hg_core_reset(struct hg_core_handle *hg_core_handle, hg_bool_t reset_info)
-hg_core_reset(struct hg_core_private_handle *hg_core_handle,
-    hg_bool_t reset_info)
 {
     /* Reset source address */
     if (reset_info) {
+        if (hg_core_handle->hg_info.addr != HG_CORE_ADDR_NULL
+            && hg_core_handle->hg_info.addr->na_addr != NA_ADDR_NULL) {
+            NA_Addr_free(hg_core_handle->na_class, hg_core_handle->hg_info.addr->na_addr);
+            hg_core_handle->hg_info.addr->na_addr = NA_ADDR_NULL;
-        if (hg_core_handle->core_handle.info.addr != HG_CORE_ADDR_NULL
-            && hg_core_handle->core_handle.info.addr->na_addr != NA_ADDR_NULL) {
-            NA_Addr_free(hg_core_handle->core_handle.info.addr->na_class,
-                hg_core_handle->core_handle.info.addr->na_addr);
-            hg_core_handle->core_handle.info.addr->na_addr = NA_ADDR_NULL;
         }
+        hg_core_handle->hg_info.id = 0;
-        hg_core_handle->core_handle.info.id = 0;
     }
+    hg_core_handle->hg_info.context_id = 0;
-    hg_core_handle->core_handle.info.context_id = 0;
     hg_core_handle->request_callback = NULL;
     hg_core_handle->request_arg = NULL;
     hg_core_handle->response_callback = NULL;
@@ -1869,8 +1906,8 @@
     hg_core_handle->no_response = HG_FALSE;
 
     /* Free extra data here if needed */
+    if (hg_core_handle->hg_info.hg_core_class->more_data_release)
+        hg_core_handle->hg_info.hg_core_class->more_data_release(
-    if (HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_release)
-        HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_release(
             (hg_core_handle_t) hg_core_handle);
     if (hg_core_handle->ack_buf) {
         NA_Msg_buf_free(hg_core_handle->na_class, hg_core_handle->ack_buf,
@@ -1885,27 +1922,23 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_set_rpc(struct hg_core_handle *hg_core_handle, hg_core_addr_t addr, hg_id_t id)
-hg_core_set_rpc(struct hg_core_private_handle *hg_core_handle,
-    struct hg_core_private_addr *addr, hg_id_t id)
 {
+    struct hg_core_info *hg_info = &hg_core_handle->hg_info;
-    struct hg_core_private_addr **handle_addr =
-        (struct hg_core_private_addr **) &hg_core_handle->core_handle.info.addr;
     hg_return_t ret = HG_SUCCESS;
 
     /* We allow for NULL addr to be passed at creation time, this allows
      * for pool of handles to be created and later re-used after a call to
      * HG_Core_reset() */
+    if (addr != HG_CORE_ADDR_NULL && hg_info->addr != addr) {
+        if (hg_info->addr != HG_CORE_ADDR_NULL)
+             hg_core_addr_free(hg_info->hg_core_class, hg_info->addr);
+        hg_info->addr = addr;
+        hg_atomic_incr32(&addr->ref_count); /* Increase ref to addr */
-    if (addr && *handle_addr != addr) {
-        if (*handle_addr)
-             hg_core_addr_free(HG_CORE_HANDLE_CLASS(hg_core_handle),
-                 *handle_addr);
-        *handle_addr = addr;
-        hg_atomic_incr32(&(*addr).ref_count); /* Increase ref to addr */
 
         /* Set forward call depending on address self */
+        hg_core_handle->is_self = NA_Addr_is_self(hg_info->addr->na_class,
+            hg_info->addr->na_addr);
-        hg_core_handle->is_self = NA_Addr_is_self(
-            (*handle_addr)->core_addr.na_class,
-            (*handle_addr)->core_addr.na_addr);
 #ifdef HG_HAS_SELF_FORWARD
         hg_core_handle->forward =
             hg_core_handle->is_self ? hg_core_forward_self : hg_core_forward_na;
@@ -1915,26 +1948,24 @@
     }
 
     /* We also allow for NULL RPC id to be passed (same reason as above) */
+    if (id && hg_core_handle->hg_info.id != id) {
-    if (id && hg_core_handle->core_handle.info.id != id) {
         struct hg_core_rpc_info *hg_core_rpc_info;
+        hg_core_context_t *context = hg_core_handle->hg_info.context;
 
         /* Retrieve ID function from function map */
+        hg_thread_spin_lock(&context->hg_core_class->func_map_lock);
-        hg_thread_spin_lock(
-            &HG_CORE_HANDLE_CLASS(hg_core_handle)->func_map_lock);
         hg_core_rpc_info = (struct hg_core_rpc_info *) hg_hash_table_lookup(
+            context->hg_core_class->func_map, (hg_hash_table_key_t) &id);
+        hg_thread_spin_unlock(&context->hg_core_class->func_map_lock);
-        HG_CORE_HANDLE_CLASS(hg_core_handle)->func_map,
-            (hg_hash_table_key_t) &id);
-        hg_thread_spin_unlock(
-            &HG_CORE_HANDLE_CLASS(hg_core_handle)->func_map_lock);
         if (!hg_core_rpc_info) {
             /* HG_LOG_ERROR("Could not find RPC ID in function map"); */
             ret = HG_NO_MATCH;
             goto done;
         }
+        hg_core_handle->hg_info.id = id;
-        hg_core_handle->core_handle.info.id = id;
 
         /* Cache RPC info */
+        hg_core_handle->hg_core_rpc_info = hg_core_rpc_info;
-        hg_core_handle->core_handle.rpc_info = hg_core_rpc_info;
     }
 
 done:
@@ -1942,9 +1973,21 @@
 }
 
 /*---------------------------------------------------------------------------*/
+void *
+hg_core_get_rpc_data(struct hg_core_handle *hg_core_handle)
+{
+    void *data = NULL;
+
+    if (hg_core_handle->hg_core_rpc_info)
+        data = hg_core_handle->hg_core_rpc_info->data;
+
+    return data;
+}
+
+/*---------------------------------------------------------------------------*/
 #ifdef HG_HAS_SELF_FORWARD
 static hg_return_t
+hg_core_forward_self(struct hg_core_handle *hg_core_handle)
-hg_core_forward_self(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -1952,16 +1995,15 @@
     hg_core_handle->op_type = HG_CORE_FORWARD_SELF;
 
     /* Initialize thread pool if not initialized yet */
+    if (!hg_core_handle->hg_info.context->self_processing_pool) {
-    if (!HG_CORE_HANDLE_CONTEXT(hg_core_handle)->self_processing_pool) {
         hg_thread_pool_init(HG_CORE_MAX_SELF_THREADS,
+            &hg_core_handle->hg_info.context->self_processing_pool);
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->self_processing_pool);
     }
 
     /* Post operation to self processing pool */
     hg_core_handle->thread_work.func = hg_core_process_thread;
     hg_core_handle->thread_work.args = hg_core_handle;
+    hg_thread_pool_post(hg_core_handle->hg_info.context->self_processing_pool,
-    hg_thread_pool_post(
-        HG_CORE_HANDLE_CONTEXT(hg_core_handle)->self_processing_pool,
         &hg_core_handle->thread_work);
 
     return ret;
@@ -1970,8 +2012,9 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_forward_na(struct hg_core_handle *hg_core_handle)
-hg_core_forward_na(struct hg_core_private_handle *hg_core_handle)
 {
+    struct hg_core_class *hg_core_class = hg_core_handle->hg_info.hg_core_class;
     na_return_t na_ret;
     hg_return_t ret = HG_SUCCESS;
 
@@ -1979,8 +2022,7 @@
     hg_core_handle->op_type = HG_CORE_FORWARD;
 
     /* Generate tag */
+    hg_core_handle->tag = hg_core_gen_request_tag(hg_core_class);
-    hg_core_handle->tag = hg_core_gen_request_tag(
-        HG_CORE_HANDLE_CLASS(hg_core_handle));
 
     if (!hg_core_handle->no_response) {
         /* Increment number of expected NA operations */
@@ -1989,11 +2031,9 @@
         /* Pre-post the recv message (output) if response is expected */
         na_ret = NA_Msg_recv_expected(hg_core_handle->na_class,
             hg_core_handle->na_context, hg_core_recv_output_cb, hg_core_handle,
+            hg_core_handle->out_buf, hg_core_handle->out_buf_size,
+            hg_core_handle->out_buf_plugin_data, hg_core_handle->hg_info.addr->na_addr,
+            hg_core_handle->hg_info.context_id, hg_core_handle->tag,
-            hg_core_handle->core_handle.out_buf,
-            hg_core_handle->core_handle.out_buf_size,
-            hg_core_handle->out_buf_plugin_data,
-            hg_core_handle->core_handle.info.addr->na_addr,
-            hg_core_handle->core_handle.info.context_id, hg_core_handle->tag,
             &hg_core_handle->na_recv_op_id);
         if (na_ret != NA_SUCCESS) {
             HG_LOG_ERROR("Could not post recv for output buffer");
@@ -2003,13 +2043,11 @@
     }
 
     /* And post the send message (input) */
+    na_ret = NA_Msg_send_unexpected(hg_core_handle->na_class, hg_core_handle->na_context,
+        hg_core_send_input_cb, hg_core_handle, hg_core_handle->in_buf,
+        hg_core_handle->in_buf_used, hg_core_handle->in_buf_plugin_data,
+        hg_core_handle->hg_info.addr->na_addr, hg_core_handle->hg_info.context_id,
+        hg_core_handle->tag, &hg_core_handle->na_send_op_id);
-    na_ret = NA_Msg_send_unexpected(hg_core_handle->na_class,
-        hg_core_handle->na_context, hg_core_send_input_cb, hg_core_handle,
-        hg_core_handle->core_handle.in_buf, hg_core_handle->in_buf_used,
-        hg_core_handle->in_buf_plugin_data,
-        hg_core_handle->core_handle.info.addr->na_addr,
-        hg_core_handle->core_handle.info.context_id, hg_core_handle->tag,
-        &hg_core_handle->na_send_op_id);
     if (na_ret != NA_SUCCESS) {
         HG_LOG_ERROR("Could not post send for input buffer");
         /* Cancel the above posted recv op */
@@ -2029,7 +2067,7 @@
 /*---------------------------------------------------------------------------*/
 #ifdef HG_HAS_SELF_FORWARD
 static HG_INLINE hg_return_t
+hg_core_respond_self(struct hg_core_handle *hg_core_handle)
-hg_core_respond_self(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -2037,7 +2075,7 @@
     hg_core_handle->op_type = HG_CORE_RESPOND_SELF;
 
     /* Complete and add to completion queue */
+    ret = hg_core_complete(hg_core_handle);
-    ret = hg_core_complete((hg_core_handle_t) hg_core_handle);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not complete handle");
         goto done;
@@ -2049,7 +2087,7 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_INLINE hg_return_t
+hg_core_no_respond_self(struct hg_core_handle *hg_core_handle)
-hg_core_no_respond_self(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -2057,7 +2095,7 @@
     hg_core_handle->op_type = HG_CORE_FORWARD_SELF;
 
     /* Complete and add to completion queue */
+    ret = hg_core_complete(hg_core_handle);
-    ret = hg_core_complete((hg_core_handle_t) hg_core_handle);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not complete handle");
         goto done;
@@ -2070,7 +2108,7 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_respond_na(struct hg_core_handle *hg_core_handle)
-hg_core_respond_na(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
     na_return_t na_ret;
@@ -2101,8 +2139,8 @@
             hg_core_handle->na_context, hg_core_recv_ack_cb, hg_core_handle,
             hg_core_handle->ack_buf, sizeof(hg_uint8_t),
             hg_core_handle->ack_buf_plugin_data,
+            hg_core_handle->hg_info.addr->na_addr,
+            hg_core_handle->hg_info.context_id, hg_core_handle->tag,
-            hg_core_handle->core_handle.info.addr->na_addr,
-            hg_core_handle->core_handle.info.context_id, hg_core_handle->tag,
             &hg_core_handle->na_ack_op_id);
         if (na_ret != NA_SUCCESS) {
             HG_LOG_ERROR("Could not post recv for ack buffer");
@@ -2114,10 +2152,10 @@
     /* Respond back */
     na_ret = NA_Msg_send_expected(hg_core_handle->na_class,
         hg_core_handle->na_context, hg_core_send_output_cb, hg_core_handle,
+        hg_core_handle->out_buf, hg_core_handle->out_buf_used,
-        hg_core_handle->core_handle.out_buf, hg_core_handle->out_buf_used,
         hg_core_handle->out_buf_plugin_data,
+        hg_core_handle->hg_info.addr->na_addr,
+        hg_core_handle->hg_info.context_id, hg_core_handle->tag,
-        hg_core_handle->core_handle.info.addr->na_addr,
-        hg_core_handle->core_handle.info.context_id, hg_core_handle->tag,
         &hg_core_handle->na_send_op_id);
     if (na_ret != NA_SUCCESS) {
         HG_LOG_ERROR("Could not post send for output buffer");
@@ -2131,14 +2169,14 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_INLINE hg_return_t
+hg_core_no_respond_na(struct hg_core_handle *hg_core_handle)
-hg_core_no_respond_na(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
 
     /* Set operation type for trigger */
     hg_core_handle->op_type = HG_CORE_NO_RESPOND;
 
+    ret = hg_core_complete(hg_core_handle);
-    ret = hg_core_complete((hg_core_handle_t) hg_core_handle);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not complete operation");
         goto done;
@@ -2152,8 +2190,8 @@
 static HG_INLINE int
 hg_core_send_input_cb(const struct na_cb_info *callback_info)
 {
+    struct hg_core_handle *hg_core_handle =
+        (struct hg_core_handle *) callback_info->arg;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) callback_info->arg;
     na_return_t na_ret = NA_SUCCESS;
     hg_bool_t completed = HG_TRUE;
 
@@ -2182,8 +2220,9 @@
 static int
 hg_core_recv_input_cb(const struct na_cb_info *callback_info)
 {
+    struct hg_core_handle *hg_core_handle =
+        (struct hg_core_handle *) callback_info->arg;
+    struct hg_core_context *hg_core_context = hg_core_handle->hg_info.context;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) callback_info->arg;
     const struct na_cb_info_recv_unexpected *na_cb_info_recv_unexpected =
         &callback_info->info.recv_unexpected;
 #ifndef HG_HAS_POST_LIMIT
@@ -2208,11 +2247,9 @@
     }
 
     /* Fill unexpected info */
+    hg_core_handle->hg_info.addr->na_addr = na_cb_info_recv_unexpected->source;
-    hg_core_handle->core_handle.info.addr->na_addr =
-        na_cb_info_recv_unexpected->source;
     hg_core_handle->tag = na_cb_info_recv_unexpected->tag;
+    if (na_cb_info_recv_unexpected->actual_buf_size > hg_core_handle->in_buf_size) {
-    if (na_cb_info_recv_unexpected->actual_buf_size >
-    hg_core_handle->core_handle.in_buf_size) {
         HG_LOG_ERROR("Actual transfer size is too large for unexpected recv");
         goto done;
     }
@@ -2220,44 +2257,35 @@
 
     /* Remove handle from pending list */
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_handle->na_class == hg_core_handle->hg_info.hg_core_class->na_sm_class) {
+        hg_thread_spin_lock(&hg_core_context->sm_pending_list_lock);
-    if (hg_core_handle->na_class ==
-        hg_core_handle->core_handle.info.core_class->na_sm_class) {
-        hg_thread_spin_lock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->sm_pending_list_lock);
         HG_LIST_REMOVE(hg_core_handle, pending);
 # ifndef HG_HAS_POST_LIMIT
+        sm_pending_empty = HG_LIST_IS_EMPTY(&hg_core_context->sm_pending_list);
-        sm_pending_empty = HG_LIST_IS_EMPTY(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->sm_pending_list);
 # endif
+        hg_thread_spin_unlock(&hg_core_context->sm_pending_list_lock);
-        hg_thread_spin_unlock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->sm_pending_list_lock);
     } else {
 #endif
+        hg_thread_spin_lock(&hg_core_context->pending_list_lock);
-        hg_thread_spin_lock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->pending_list_lock);
         HG_LIST_REMOVE(hg_core_handle, pending);
 #ifndef HG_HAS_POST_LIMIT
+        pending_empty = HG_LIST_IS_EMPTY(&hg_core_context->pending_list);
-        pending_empty = HG_LIST_IS_EMPTY(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->pending_list);
 #endif
+        hg_thread_spin_unlock(&hg_core_context->pending_list_lock);
-        hg_thread_spin_unlock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->pending_list_lock);
 #ifdef HG_HAS_SM_ROUTING
     }
 #endif
 
 #ifndef HG_HAS_POST_LIMIT
     /* If pending list is empty, post more handles */
+    if (pending_empty && hg_core_context_post(hg_core_context,
-    if (pending_empty
-        && hg_core_context_post(HG_CORE_HANDLE_CONTEXT(hg_core_handle),
         HG_CORE_PENDING_INCR, hg_core_handle->repost, HG_FALSE) != HG_SUCCESS) {
         HG_LOG_ERROR("Could not post additional handles");
         goto done;
     }
 # ifdef HG_HAS_SM_ROUTING
     /* If pending list is empty, post more handles */
+    if (sm_pending_empty && hg_core_context_post(hg_core_context,
-    if (sm_pending_empty
-        && hg_core_context_post(HG_CORE_HANDLE_CONTEXT(hg_core_handle),
         HG_CORE_PENDING_INCR, hg_core_handle->repost, HG_TRUE) != HG_SUCCESS) {
         HG_LOG_ERROR("Could not post additional SM handles");
         goto done;
@@ -2289,9 +2317,10 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_process_input(struct hg_core_handle *hg_core_handle,
-hg_core_process_input(struct hg_core_private_handle *hg_core_handle,
     hg_bool_t *completed)
 {
+    struct hg_core_context *hg_core_context = hg_core_handle->hg_info.context;
     hg_return_t ret = HG_SUCCESS;
 
 #ifdef HG_HAS_COLLECT_STATS
@@ -2300,7 +2329,7 @@
 #endif
 
     /* Get and verify input header */
+    ret = hg_core_proc_header_request(hg_core_handle,
-    ret = hg_core_proc_header_request(&hg_core_handle->core_handle,
         &hg_core_handle->in_header, HG_DECODE);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not get request header");
@@ -2308,11 +2337,10 @@
     }
 
     /* Get operation ID from header */
+    hg_core_handle->hg_info.id = hg_core_handle->in_header.msg.request.id;
-    hg_core_handle->core_handle.info.id =
-        hg_core_handle->in_header.msg.request.id;
     hg_core_handle->cookie = hg_core_handle->in_header.msg.request.cookie;
     /* TODO assign target ID from cookie directly for now */
+    hg_core_handle->hg_info.context_id = hg_core_handle->cookie;
-    hg_core_handle->core_handle.info.context_id = hg_core_handle->cookie;
 
     /* Parse flags */
     hg_core_handle->no_response = hg_core_handle->in_header.msg.request.flags
@@ -2329,7 +2357,7 @@
 
     /* Must let upper layer get extra payload if HG_CORE_MORE_DATA is set */
     if (hg_core_handle->in_header.msg.request.flags & HG_CORE_MORE_DATA) {
+        if (!hg_core_context->hg_core_class->more_data_acquire) {
-        if (!HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_acquire) {
             HG_LOG_ERROR("No callback defined for acquiring more data");
             ret = HG_PROTOCOL_ERROR;
             goto done;
@@ -2338,7 +2366,7 @@
         /* Increment counter */
         hg_core_stat_incr(&hg_core_rpc_extra_count_g);
 #endif
+        ret = hg_core_context->hg_core_class->more_data_acquire(
-        ret = HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_acquire(
             (hg_core_handle_t) hg_core_handle, HG_INPUT, hg_core_complete);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Error in HG core handle more data acquire callback");
@@ -2356,8 +2384,8 @@
 static HG_INLINE int
 hg_core_send_output_cb(const struct na_cb_info *callback_info)
 {
+    struct hg_core_handle *hg_core_handle =
+        (struct hg_core_handle *) callback_info->arg;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) callback_info->arg;
     na_return_t na_ret = NA_SUCCESS;
     hg_bool_t completed = HG_TRUE;
 
@@ -2387,8 +2415,8 @@
 static HG_INLINE int
 hg_core_recv_output_cb(const struct na_cb_info *callback_info)
 {
+    struct hg_core_handle *hg_core_handle =
+        (struct hg_core_handle *) callback_info->arg;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) callback_info->arg;
     na_return_t na_ret = NA_SUCCESS;
     hg_bool_t completed = HG_TRUE;
 
@@ -2424,15 +2452,15 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_process_output(struct hg_core_handle *hg_core_handle,
+    hg_bool_t *completed, hg_return_t (*done_callback)(hg_core_handle_t))
-hg_core_process_output(struct hg_core_private_handle *hg_core_handle,
-    hg_bool_t *completed,
-    hg_return_t (*done_callback)(hg_core_handle_t))
 {
+    struct hg_core_context *hg_core_context = hg_core_handle->hg_info.context;
     hg_return_t ret = HG_SUCCESS;
 
     /* Get and verify output header */
+    if (hg_core_proc_header_response(hg_core_handle, &hg_core_handle->out_header,
+        HG_DECODE) != HG_SUCCESS) {
-    if (hg_core_proc_header_response(&hg_core_handle->core_handle,
-        &hg_core_handle->out_header, HG_DECODE) != HG_SUCCESS) {
         HG_LOG_ERROR("Could not decode header");
         goto done;
     }
@@ -2445,12 +2473,12 @@
 
     /* Must let upper layer get extra payload if HG_CORE_MORE_DATA is set */
     if (hg_core_handle->out_header.msg.response.flags & HG_CORE_MORE_DATA) {
+        if (!hg_core_context->hg_core_class->more_data_acquire) {
-        if (!HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_acquire) {
             HG_LOG_ERROR("No callback defined for acquiring more data");
             ret = HG_PROTOCOL_ERROR;
             goto done;
         }
+        ret = hg_core_context->hg_core_class->more_data_acquire(
-        ret = HG_CORE_HANDLE_CLASS(hg_core_handle)->more_data_acquire(
             (hg_core_handle_t) hg_core_handle, HG_OUTPUT, done_callback);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Error in HG core handle more data acquire callback");
@@ -2466,10 +2494,8 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_send_ack(struct hg_core_handle *hg_core_handle)
-hg_core_send_ack(hg_core_handle_t handle)
 {
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
     hg_return_t ret = HG_SUCCESS;
     na_return_t na_ret;
 
@@ -2492,8 +2518,8 @@
         hg_core_handle->na_context, hg_core_send_ack_cb, hg_core_handle,
         hg_core_handle->ack_buf, sizeof(hg_uint8_t),
         hg_core_handle->ack_buf_plugin_data,
+        hg_core_handle->hg_info.addr->na_addr,
+        hg_core_handle->hg_info.context_id, hg_core_handle->tag,
-        hg_core_handle->core_handle.info.addr->na_addr,
-        hg_core_handle->core_handle.info.context_id, hg_core_handle->tag,
         &hg_core_handle->na_ack_op_id);
     if (na_ret != NA_SUCCESS) {
         HG_LOG_ERROR("Could not post send for ack buffer");
@@ -2509,8 +2535,8 @@
 static HG_INLINE int
 hg_core_send_ack_cb(const struct na_cb_info *callback_info)
 {
+    struct hg_core_handle *hg_core_handle =
+        (struct hg_core_handle *) callback_info->arg;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) callback_info->arg;
     na_return_t na_ret = NA_SUCCESS;
     hg_bool_t completed = HG_TRUE;
 
@@ -2540,8 +2566,8 @@
 static HG_INLINE int
 hg_core_recv_ack_cb(const struct na_cb_info *callback_info)
 {
+    struct hg_core_handle *hg_core_handle =
+        (struct hg_core_handle *) callback_info->arg;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) callback_info->arg;
     na_return_t na_ret = NA_SUCCESS;
     hg_bool_t completed = HG_TRUE;
 
@@ -2572,8 +2598,8 @@
 static hg_return_t
 hg_core_self_cb(const struct hg_core_cb_info *callback_info)
 {
+    struct hg_core_handle *hg_core_handle =
+        (struct hg_core_handle *) callback_info->info.respond.handle;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) callback_info->info.respond.handle;
     hg_return_t ret;
     hg_bool_t completed = HG_TRUE;
 
@@ -2603,8 +2629,7 @@
    }
 
     /* Mark as completed */
+    if (completed && hg_core_complete(hg_core_handle) != HG_SUCCESS) {
-    if (completed
-        && hg_core_complete((hg_core_handle_t) hg_core_handle) != HG_SUCCESS) {
         HG_LOG_ERROR("Could not complete operation");
     }
 
@@ -2617,8 +2642,7 @@
 hg_core_process_thread(void *arg)
 {
     hg_thread_ret_t thread_ret = (hg_thread_ret_t) 0;
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) arg;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) arg;
     hg_bool_t completed = HG_FALSE;
 
     /* Set operation type for trigger */
@@ -2630,8 +2654,7 @@
    }
 
    /* Mark as completed */
+   if (completed && hg_core_complete(hg_core_handle) != HG_SUCCESS) {
-    if (completed
-        && hg_core_complete((hg_core_handle_t) hg_core_handle) != HG_SUCCESS) {
        HG_LOG_ERROR("Could not complete operation");
    }
 
@@ -2641,17 +2664,17 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_process(struct hg_core_handle *hg_core_handle)
-hg_core_process(struct hg_core_private_handle *hg_core_handle)
 {
+    struct hg_core_class *hg_core_class = hg_core_handle->hg_info.hg_core_class;
     struct hg_core_rpc_info *hg_core_rpc_info;
     hg_return_t ret = HG_SUCCESS;
 
     /* Retrieve exe function from function map */
+    hg_thread_spin_lock(&hg_core_class->func_map_lock);
-    hg_thread_spin_lock(&HG_CORE_HANDLE_CLASS(hg_core_handle)->func_map_lock);
     hg_core_rpc_info = (struct hg_core_rpc_info *) hg_hash_table_lookup(
+        hg_core_class->func_map, (hg_hash_table_key_t) &hg_core_handle->hg_info.id);
+    hg_thread_spin_unlock(&hg_core_class->func_map_lock);
-        HG_CORE_HANDLE_CLASS(hg_core_handle)->func_map,
-        (hg_hash_table_key_t) &hg_core_handle->core_handle.info.id);
-    hg_thread_spin_unlock(&HG_CORE_HANDLE_CLASS(hg_core_handle)->func_map_lock);
     if (!hg_core_rpc_info) {
         HG_LOG_WARNING("Could not find RPC ID in function map");
         ret = HG_NO_MATCH;
@@ -2665,7 +2688,7 @@
     }
 
     /* Cache RPC info */
+    hg_core_handle->hg_core_rpc_info = hg_core_rpc_info;
-    hg_core_handle->core_handle.rpc_info = hg_core_rpc_info;
 
     /* Increment ref count here so that a call to HG_Destroy in user's RPC
      * callback does not free the handle but only schedules its completion */
@@ -2684,8 +2707,8 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_INLINE hg_return_t
+hg_core_complete_na(struct hg_core_handle *hg_core_handle, na_op_id_t *op_id,
+    hg_bool_t *completed)
-hg_core_complete_na(struct hg_core_private_handle *hg_core_handle,
-    na_op_id_t *op_id, hg_bool_t *completed)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -2697,7 +2720,7 @@
     if (hg_atomic_incr32(&hg_core_handle->na_op_completed_count)
         == (hg_util_int32_t) hg_core_handle->na_op_count && *completed) {
         /* Mark as completed */
+        if (hg_core_complete(hg_core_handle) != HG_SUCCESS) {
-        if (hg_core_complete((hg_core_handle_t) hg_core_handle) != HG_SUCCESS) {
             HG_LOG_ERROR("Could not complete operation");
             goto done;
         }
@@ -2712,17 +2735,15 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_INLINE hg_return_t
+hg_core_complete(struct hg_core_handle *hg_core_handle)
-hg_core_complete(hg_core_handle_t handle)
 {
+    struct hg_core_context *context = hg_core_handle->hg_info.context;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
-    struct hg_core_context *context = hg_core_handle->core_handle.info.context;
     struct hg_completion_entry *hg_completion_entry =
         &hg_core_handle->hg_completion_entry;
     hg_return_t ret = HG_SUCCESS;
 
     hg_completion_entry->op_type = HG_RPC;
+    hg_completion_entry->op_id.hg_core_handle = hg_core_handle;
-    hg_completion_entry->op_id.hg_core_handle = handle;
 
     ret = hg_core_completion_add(context, hg_completion_entry,
         hg_core_handle->is_self);
@@ -2740,8 +2761,6 @@
 hg_core_completion_add(struct hg_core_context *context,
     struct hg_completion_entry *hg_completion_entry, hg_bool_t self_notify)
 {
-    struct hg_core_private_context *private_context =
-        (struct hg_core_private_context *) context;
     hg_return_t ret = HG_SUCCESS;
 
 #ifdef HG_HAS_COLLECT_STATS
@@ -2750,28 +2769,28 @@
         hg_core_stat_incr(&hg_core_bulk_count_g);
 #endif
 
+    if (hg_atomic_queue_push(context->completion_queue, hg_completion_entry)
-    if (hg_atomic_queue_push(private_context->completion_queue, hg_completion_entry)
         != HG_UTIL_SUCCESS) {
         /* Queue is full */
+        hg_thread_mutex_lock(&context->completion_queue_mutex);
+        HG_QUEUE_PUSH_TAIL(&context->backfill_queue, hg_completion_entry,
-        hg_thread_mutex_lock(&private_context->completion_queue_mutex);
-        HG_QUEUE_PUSH_TAIL(&private_context->backfill_queue, hg_completion_entry,
             entry);
+        hg_atomic_incr32(&context->backfill_queue_count);
+        hg_thread_mutex_unlock(&context->completion_queue_mutex);
-        hg_atomic_incr32(&private_context->backfill_queue_count);
-        hg_thread_mutex_unlock(&private_context->completion_queue_mutex);
     }
 
+    if (hg_atomic_get32(&context->trigger_waiting)) {
+        hg_thread_mutex_lock(&context->completion_queue_mutex);
-    if (hg_atomic_get32(&private_context->trigger_waiting)) {
-        hg_thread_mutex_lock(&private_context->completion_queue_mutex);
         /* Callback is pushed to the completion queue when something completes
          * so wake up anyone waiting in the trigger */
+        hg_thread_cond_signal(&context->completion_queue_cond);
+        hg_thread_mutex_unlock(&context->completion_queue_mutex);
-        hg_thread_cond_signal(&private_context->completion_queue_cond);
-        hg_thread_mutex_unlock(&private_context->completion_queue_mutex);
     }
 
 #ifdef HG_HAS_SELF_FORWARD
     /* TODO could prevent from self notifying if hg_poll_wait() not entered */
+    if (self_notify && context->completion_queue_notify
+        && hg_event_set(context->completion_queue_notify) != HG_UTIL_SUCCESS) {
-    if (self_notify && private_context->completion_queue_notify
-        && hg_event_set(private_context->completion_queue_notify) != HG_UTIL_SUCCESS) {
         HG_LOG_ERROR("Could not signal completion queue");
         ret = HG_PROTOCOL_ERROR;
     }
@@ -2784,16 +2803,16 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_context_post(struct hg_core_context *context, unsigned int request_count,
+    hg_bool_t repost, hg_bool_t use_sm)
-hg_core_context_post(struct hg_core_private_context *context,
-    unsigned int request_count, hg_bool_t repost, hg_bool_t use_sm)
 {
     unsigned int nentry = 0;
     hg_return_t ret = HG_SUCCESS;
 
     /* Create a bunch of handles and post unexpected receives */
     for (nentry = 0; nentry < request_count; nentry++) {
+        struct hg_core_handle *hg_core_handle = NULL;
+        struct hg_core_addr *hg_core_addr = NULL;
-        struct hg_core_private_handle *hg_core_handle = NULL;
-        struct hg_core_private_addr *hg_core_addr = NULL;
 
         /* Create a new handle */
         hg_core_handle = hg_core_create(context, use_sm);
@@ -2806,7 +2825,7 @@
         /* Execute class callback on handle, this allows upper layers to
          * allocate private data on handle creation */
         if (context->handle_create) {
+            ret = context->handle_create(hg_core_handle,
-            ret = context->handle_create((hg_core_handle_t) hg_core_handle,
                 context->handle_create_arg);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Error in HG core handle create callback");
@@ -2815,7 +2834,7 @@
         }
 
         /* Create internal addresses */
+        hg_core_addr = hg_core_addr_create(context->hg_core_class,
-        hg_core_addr = hg_core_addr_create(HG_CORE_CONTEXT_CLASS(context),
             hg_core_handle->na_class);
         if (!hg_core_addr) {
             HG_LOG_ERROR("Could not create HG addr");
@@ -2824,7 +2843,7 @@
         }
         /* To safely repost handle and prevent externally referenced address */
         hg_core_addr->is_mine = HG_TRUE;
+        hg_core_handle->hg_info.addr = hg_core_addr;
-        hg_core_handle->core_handle.info.addr = (hg_core_addr_t) hg_core_addr;
 
         /* Repost handle on completion if told so */
         hg_core_handle->repost = repost;
@@ -2842,8 +2861,9 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_post(struct hg_core_handle *hg_core_handle)
-hg_core_post(struct hg_core_private_handle *hg_core_handle)
 {
+    struct hg_core_context *context = hg_core_handle->hg_info.context;
     na_return_t na_ret;
     hg_return_t ret = HG_SUCCESS;
 
@@ -2851,34 +2871,24 @@
     hg_atomic_set32(&hg_core_handle->in_use, HG_TRUE);
 
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_handle->na_class == hg_core_handle->hg_info.hg_core_class->na_sm_class) {
+        hg_thread_spin_lock(&context->sm_pending_list_lock);
+        HG_LIST_INSERT_HEAD(&context->sm_pending_list, hg_core_handle, pending);
+        hg_thread_spin_unlock(&context->sm_pending_list_lock);
-    if (hg_core_handle->na_class ==
-        hg_core_handle->core_handle.info.core_class->na_sm_class) {
-        hg_thread_spin_lock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->sm_pending_list_lock);
-        HG_LIST_INSERT_HEAD(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->sm_pending_list,
-            hg_core_handle, pending);
-        hg_thread_spin_unlock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->sm_pending_list_lock);
     } else {
 #endif
+        hg_thread_spin_lock(&context->pending_list_lock);
+        HG_LIST_INSERT_HEAD(&context->pending_list, hg_core_handle, pending);
+        hg_thread_spin_unlock(&context->pending_list_lock);
-        hg_thread_spin_lock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->pending_list_lock);
-        HG_LIST_INSERT_HEAD(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->pending_list,
-            hg_core_handle, pending);
-        hg_thread_spin_unlock(
-            &HG_CORE_HANDLE_CONTEXT(hg_core_handle)->pending_list_lock);
 #ifdef HG_HAS_SM_ROUTING
     }
 #endif
 
     /* Post a new unexpected receive */
+    na_ret = NA_Msg_recv_unexpected(hg_core_handle->na_class, hg_core_handle->na_context,
+        hg_core_recv_input_cb, hg_core_handle, hg_core_handle->in_buf,
+        hg_core_handle->in_buf_size, hg_core_handle->in_buf_plugin_data,
+        &hg_core_handle->na_recv_op_id);
-    na_ret = NA_Msg_recv_unexpected(hg_core_handle->na_class,
-        hg_core_handle->na_context, hg_core_recv_input_cb, hg_core_handle,
-        hg_core_handle->core_handle.in_buf,
-        hg_core_handle->core_handle.in_buf_size,
-        hg_core_handle->in_buf_plugin_data, &hg_core_handle->na_recv_op_id);
     if (na_ret != NA_SUCCESS) {
         HG_LOG_ERROR("Could not post unexpected recv for input buffer");
         ret = HG_NA_ERROR;
@@ -2891,7 +2901,7 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_reset_post(struct hg_core_handle *hg_core_handle)
-hg_core_reset_post(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -2903,7 +2913,7 @@
 
     /* Also reset additional handle parameters */
     hg_atomic_set32(&hg_core_handle->ref_count, 1);
+    hg_core_handle->hg_core_rpc_info = NULL;
-    hg_core_handle->core_handle.rpc_info = NULL;
 
     /* Safe to repost */
     ret = hg_core_post(hg_core_handle);
@@ -2918,12 +2928,11 @@
 
 /*---------------------------------------------------------------------------*/
 #ifdef HG_HAS_SELF_FORWARD
+static int
-static HG_INLINE int
 hg_core_completion_queue_notify_cb(void *arg, unsigned int timeout,
     int HG_UNUSED error, hg_util_bool_t *progressed)
 {
+    struct hg_core_context *context = (struct hg_core_context *) arg;
-    struct hg_core_private_context *context =
-        (struct hg_core_private_context *) arg;
     hg_util_bool_t notified = HG_UTIL_FALSE;
     int ret = HG_UTIL_SUCCESS;
 
@@ -2951,17 +2960,16 @@
 hg_core_progress_na_cb(void *arg, unsigned int timeout, int HG_UNUSED error,
     hg_util_bool_t *progressed)
 {
+    struct hg_core_context *context = (struct hg_core_context *) arg;
+    struct hg_core_class *hg_core_class = context->hg_core_class;
+    unsigned int actual_count = 0;
-    struct hg_core_private_context *context =
-        (struct hg_core_private_context *) arg;
-     unsigned int actual_count = 0;
     na_return_t na_ret;
     unsigned int completed_count = 0;
+    int cb_ret[1] = {0};
-    int cb_ret[HG_CORE_MAX_TRIGGER_COUNT] = {0};
     int ret = HG_UTIL_SUCCESS;
 
     /* Check progress on NA (no need to call try_wait here) */
+    na_ret = NA_Progress(hg_core_class->na_class, context->na_context, timeout);
-    na_ret = NA_Progress(HG_CORE_CONTEXT_CLASS(context)->core_class.na_class,
-        context->core_context.na_context, timeout);
     if (na_ret != NA_SUCCESS && na_ret != NA_TIMEOUT) {
         HG_LOG_ERROR("Could not make progress on NA");
         ret = HG_UTIL_FAIL;
@@ -2976,14 +2984,10 @@
     /* Trigger everything we can from NA, if something completed it will
      * be moved to the HG context completion queue */
     do {
+        na_ret = NA_Trigger(context->na_context, 0, 1, cb_ret, &actual_count);
-        unsigned int i;
-
-        na_ret = NA_Trigger(context->core_context.na_context, 0,
-            HG_CORE_MAX_TRIGGER_COUNT, cb_ret, &actual_count);
 
         /* Return value of callback is completion count */
+        completed_count += (unsigned int) cb_ret[0];
-        for (i = 0; i < actual_count; i++)
-            completed_count += (unsigned int) cb_ret[i];
     } while ((na_ret == NA_SUCCESS) && actual_count);
 
     /* We can't only verify that the completion queue is not empty, we need
@@ -3008,17 +3012,16 @@
 hg_core_progress_na_sm_cb(void *arg, unsigned int timeout, int HG_UNUSED error,
     hg_util_bool_t *progressed)
 {
+    struct hg_core_context *context = (struct hg_core_context *) arg;
+    struct hg_core_class *hg_core_class = context->hg_core_class;
-    struct hg_core_private_context *context =
-        (struct hg_core_private_context *) arg;
     unsigned int actual_count = 0;
     na_return_t na_ret;
     unsigned int completed_count = 0;
+    int cb_ret[1] = {0};
-    int cb_ret[HG_CORE_MAX_TRIGGER_COUNT] = {0};
     int ret = HG_UTIL_SUCCESS;
 
     /* Check progress on NA SM (no need to call try_wait here) */
+    na_ret = NA_Progress(hg_core_class->na_sm_class, context->na_sm_context, timeout);
-    na_ret = NA_Progress(HG_CORE_CONTEXT_CLASS(context)->core_class.na_sm_class,
-        context->core_context.na_sm_context, timeout);
     if (na_ret != NA_SUCCESS && na_ret != NA_TIMEOUT) {
         HG_LOG_ERROR("Could not make progress on NA SM");
         ret = HG_UTIL_FAIL;
@@ -3033,14 +3036,10 @@
     /* Trigger everything we can from NA, if something completed it will
      * be moved to the HG context completion queue */
     do {
+        na_ret = NA_Trigger(context->na_sm_context, 0, 1, cb_ret, &actual_count);
-        unsigned int i;
-
-        na_ret = NA_Trigger(context->core_context.na_sm_context, 0,
-            HG_CORE_MAX_TRIGGER_COUNT, cb_ret, &actual_count);
 
         /* Return value of callback is completion count */
+        completed_count += (unsigned int) cb_ret[0];
-        for (i = 0; i < actual_count; i++)
-            completed_count += (unsigned int)cb_ret[i];
     } while ((na_ret == NA_SUCCESS) && actual_count);
 
     /* We can't only verify that the completion queue is not empty, we need
@@ -3062,14 +3061,13 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_progress_na(struct hg_core_context *context, unsigned int timeout)
-hg_core_progress_na(struct hg_core_private_context *context,
-    unsigned int timeout)
 {
     double remaining;
     hg_return_t ret = HG_TIMEOUT;
 
     /* Do not block if NA_NO_BLOCK option is passed */
+    if (context->hg_core_class->progress_mode == NA_NO_BLOCK) {
-    if (HG_CORE_CONTEXT_CLASS(context)->progress_mode == NA_NO_BLOCK) {
         timeout = 0;
         remaining = 0;
     } else {
@@ -3077,8 +3075,9 @@
     }
 
     for (;;) {
+        struct hg_core_class *hg_core_class = context->hg_core_class;
         unsigned int actual_count = 0;
+        int cb_ret[1] = {0};
-        int cb_ret[HG_CORE_MAX_TRIGGER_COUNT] = {0};
         unsigned int completed_count = 0;
         unsigned int progress_timeout;
         na_return_t na_ret;
@@ -3087,14 +3086,11 @@
         /* Trigger everything we can from NA, if something completed it will
          * be moved to the HG context completion queue */
         do {
+            na_ret = NA_Trigger(context->na_context, 0, 1, cb_ret,
+                &actual_count);
-            unsigned int i;
-
-            na_ret = NA_Trigger(context->core_context.na_context, 0,
-                HG_CORE_MAX_TRIGGER_COUNT, cb_ret, &actual_count);
 
             /* Return value of callback is completion count */
+            completed_count += (unsigned int)cb_ret[0];
-            for (i = 0; i < actual_count; i++)
-                completed_count += (unsigned int)cb_ret[i];
         } while ((na_ret == NA_SUCCESS) && actual_count);
 
         /* We can't only verify that the completion queue is not empty, we need
@@ -3114,17 +3110,15 @@
             hg_time_get_current(&t1);
 
         /* Make sure that it is safe to block */
+        if (timeout &&
+            NA_Poll_try_wait(hg_core_class->na_class, context->na_context))
-        if (timeout && NA_Poll_try_wait(
-            HG_CORE_CONTEXT_CLASS(context)->core_class.na_class,
-            context->core_context.na_context))
             progress_timeout = (unsigned int) (remaining * 1000.0);
         else
             progress_timeout = 0;
 
         /* Otherwise try to make progress on NA */
+        na_ret = NA_Progress(hg_core_class->na_class, context->na_context,
+            progress_timeout);
-        na_ret = NA_Progress(
-            HG_CORE_CONTEXT_CLASS(context)->core_class.na_class,
-            context->core_context.na_context, progress_timeout);
 
         if (timeout) {
             hg_time_get_current(&t2);
@@ -3151,43 +3145,40 @@
 static HG_INLINE hg_util_bool_t
 hg_core_poll_try_wait_cb(void *arg)
 {
+    struct hg_core_context *hg_core_context = (struct hg_core_context *) arg;
-    struct hg_core_private_context *context =
-        (struct hg_core_private_context *) arg;
 
     /* Do not try to wait if NA_NO_BLOCK is set */
+    if (hg_core_context->hg_core_class->progress_mode == NA_NO_BLOCK)
-    if (HG_CORE_CONTEXT_CLASS(context)->progress_mode == NA_NO_BLOCK)
         return NA_FALSE;
 
     /* Something is in one of the completion queues */
+    if (!hg_atomic_queue_is_empty(hg_core_context->completion_queue) ||
+        hg_atomic_get32(&hg_core_context->backfill_queue_count)) {
-    if (!hg_atomic_queue_is_empty(context->completion_queue) ||
-        hg_atomic_get32(&context->backfill_queue_count)) {
         return NA_FALSE;
     }
 
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_context->hg_core_class->na_sm_class) {
+        na_bool_t ret = NA_Poll_try_wait(hg_core_context->hg_core_class->na_sm_class,
+            hg_core_context->na_sm_context);
-    if (context->core_context.core_class->na_sm_class) {
-        na_bool_t ret = NA_Poll_try_wait(
-            context->core_context.core_class->na_sm_class,
-            context->core_context.na_sm_context);
         if (ret)
             return ret;
     }
 #endif
 
+    return NA_Poll_try_wait(hg_core_context->hg_core_class->na_class,
+        hg_core_context->na_context);
-    return NA_Poll_try_wait(context->core_context.core_class->na_class,
-        context->core_context.na_context);
 }
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_progress_poll(struct hg_core_context *context, unsigned int timeout)
-hg_core_progress_poll(struct hg_core_private_context *context,
-    unsigned int timeout)
 {
     double remaining;
     hg_return_t ret = HG_TIMEOUT;
 
     /* Do not block if NA_NO_BLOCK option is passed */
+    if (context->hg_core_class->progress_mode == NA_NO_BLOCK) {
-    if (HG_CORE_CONTEXT_CLASS(context)->progress_mode == NA_NO_BLOCK) {
         timeout = 0;
         remaining = 0;
     } else {
@@ -3227,7 +3218,7 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_trigger(struct hg_core_context *context, unsigned int timeout,
-hg_core_trigger(struct hg_core_private_context *context, unsigned int timeout,
     unsigned int max_count, unsigned int *actual_count)
 {
     double remaining;
@@ -3235,7 +3226,7 @@
     hg_return_t ret = HG_SUCCESS;
 
     /* Do not block if NA_NO_BLOCK option is passed */
+    if (context->hg_core_class->progress_mode == NA_NO_BLOCK) {
-    if (HG_CORE_CONTEXT_CLASS(context)->progress_mode == NA_NO_BLOCK) {
         timeout = 0;
         remaining = 0;
     } else {
@@ -3306,24 +3297,21 @@
         /* Trigger entry */
         switch(hg_completion_entry->op_type) {
             case HG_ADDR:
+                ret = hg_core_trigger_lookup_entry(hg_completion_entry->op_id.hg_core_op_id);
-                ret = hg_core_trigger_lookup_entry(
-                    hg_completion_entry->op_id.hg_core_op_id);
                 if (ret != HG_SUCCESS) {
                     HG_LOG_ERROR("Could not trigger completion entry");
                     goto done;
                 }
                 break;
             case HG_RPC:
+                ret = hg_core_trigger_entry(hg_completion_entry->op_id.hg_core_handle);
-                ret = hg_core_trigger_entry((struct hg_core_private_handle *)
-                    hg_completion_entry->op_id.hg_core_handle);
                 if (ret != HG_SUCCESS) {
                     HG_LOG_ERROR("Could not trigger completion entry");
                     goto done;
                 }
                 break;
             case HG_BULK:
+                ret = hg_bulk_trigger_entry(hg_completion_entry->op_id.hg_bulk_op_id);
-                ret = hg_bulk_trigger_entry(
-                    hg_completion_entry->op_id.hg_bulk_op_id);
                 if (ret != HG_SUCCESS) {
                     HG_LOG_ERROR("Could not trigger completion entry");
                     goto done;
@@ -3357,8 +3345,7 @@
         hg_core_cb_info.arg = hg_core_op_id->arg;
         hg_core_cb_info.ret =  HG_SUCCESS; /* TODO report failure */
         hg_core_cb_info.type = HG_CB_LOOKUP;
+        hg_core_cb_info.info.lookup.addr = hg_core_op_id->info.lookup.hg_core_addr;
-        hg_core_cb_info.info.lookup.addr =
-            (hg_core_addr_t) hg_core_op_id->info.lookup.hg_core_addr;
 
         hg_core_op_id->callback(&hg_core_cb_info);
     }
@@ -3370,7 +3357,7 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_trigger_entry(struct hg_core_handle *hg_core_handle)
-hg_core_trigger_entry(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -3382,12 +3369,11 @@
         ret = hg_core_process(hg_core_handle);
         if (ret != HG_SUCCESS && !hg_core_handle->no_response) {
             hg_size_t header_size = hg_core_header_response_get_size() +
+                hg_core_handle->na_out_header_offset;
-                hg_core_handle->core_handle.na_out_header_offset;
 
             /* Respond in case of error */
             hg_core_handle->ret = ret;
+            ret = HG_Core_respond(hg_core_handle, NULL, NULL, 0, header_size);
-            ret = HG_Core_respond((hg_core_handle_t) hg_core_handle, NULL, NULL,
-                0, header_size);
             if (ret != HG_SUCCESS) {
                 HG_LOG_ERROR("Could not respond");
                 goto done;
@@ -3419,23 +3405,20 @@
                 hg_cb = hg_core_handle->request_callback;
                 hg_core_cb_info.arg = hg_core_handle->request_arg;
                 hg_core_cb_info.type = HG_CB_FORWARD;
+                hg_core_cb_info.info.forward.handle = (hg_core_handle_t) hg_core_handle;
-                hg_core_cb_info.info.forward.handle =
-                    (hg_core_handle_t) hg_core_handle;
                 break;
             case HG_CORE_RESPOND:
                 hg_cb = hg_core_handle->response_callback;
                 hg_core_cb_info.arg = hg_core_handle->response_arg;
                 hg_core_cb_info.type = HG_CB_RESPOND;
+                hg_core_cb_info.info.respond.handle = (hg_core_handle_t) hg_core_handle;
-                hg_core_cb_info.info.respond.handle =
-                    (hg_core_handle_t) hg_core_handle;
                 break;
 #ifdef HG_HAS_SELF_FORWARD
             case HG_CORE_RESPOND_SELF:
                 hg_cb = hg_core_self_cb;
                 hg_core_cb_info.arg = hg_core_handle->response_arg;
                 hg_core_cb_info.type = HG_CB_RESPOND;
+                hg_core_cb_info.info.respond.handle = (hg_core_handle_t) hg_core_handle;
-                hg_core_cb_info.info.respond.handle =
-                    (hg_core_handle_t) hg_core_handle;
                 break;
 #endif
             case HG_CORE_NO_RESPOND:
@@ -3455,7 +3438,7 @@
 
     /* Repost handle if we were listening, otherwise destroy it */
     if (hg_core_handle->repost
+        && !hg_core_handle->hg_info.context->finalizing) {
-        && !HG_CORE_HANDLE_CONTEXT(hg_core_handle)->finalizing) {
         /* Repost handle */
         ret = hg_core_reset_post(hg_core_handle);
         if (ret != HG_SUCCESS) {
@@ -3471,13 +3454,13 @@
 
 /*---------------------------------------------------------------------------*/
 static hg_return_t
+hg_core_cancel(struct hg_core_handle *hg_core_handle)
-hg_core_cancel(struct hg_core_private_handle *hg_core_handle)
 {
     hg_return_t ret = HG_SUCCESS;
 
     if (hg_core_handle->is_self) {
         HG_LOG_ERROR("Local cancelation is not supported");
+        ret = NA_PROTOCOL_ERROR;
-        ret = HG_PROTOCOL_ERROR;
         goto done;
     }
 
@@ -3536,7 +3519,7 @@
 HG_Core_init_opt(const char *na_info_string, hg_bool_t na_listen,
     const struct hg_init_info *hg_init_info)
 {
+    struct hg_core_class *hg_core_class = NULL;
-    struct hg_core_private_class *hg_core_class = NULL;
     hg_return_t ret = HG_SUCCESS;
 
     hg_core_class = hg_core_init(na_info_string, na_listen, hg_init_info);
@@ -3550,7 +3533,7 @@
     if (ret != HG_SUCCESS) {
         /* Nothing */
     }
+    return hg_core_class;
-    return (hg_core_class_t *) hg_core_class;
 }
 
 /*---------------------------------------------------------------------------*/
@@ -3559,7 +3542,7 @@
 {
     hg_return_t ret = HG_SUCCESS;
 
+    ret = hg_core_finalize(hg_core_class);
-    ret = hg_core_finalize((struct hg_core_private_class *) hg_core_class);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Cannot finalize HG core layer");
         goto done;
@@ -3583,8 +3566,6 @@
         hg_return_t (*done_callback)(hg_core_handle_t)),
     void (*more_data_release_callback)(hg_core_handle_t))
 {
-    struct hg_core_private_class *private_class =
-        (struct hg_core_private_class *) hg_core_class;
     hg_return_t ret = HG_SUCCESS;
 
     if (!hg_core_class) {
@@ -3593,8 +3574,174 @@
         goto done;
     }
 
+    hg_core_class->more_data_acquire = more_data_acquire_callback;
+    hg_core_class->more_data_release = more_data_release_callback;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+const char *
+HG_Core_class_get_name(const hg_core_class_t *hg_core_class)
+{
+    const char *ret = NULL;
+
+    if (!hg_core_class) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    ret = NA_Get_class_name(hg_core_class->na_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+const char *
+HG_Core_class_get_protocol(const hg_core_class_t *hg_core_class)
+{
+    const char *ret = NULL;
+
+    if (!hg_core_class) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    ret = NA_Get_class_protocol(hg_core_class->na_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_bool_t
+HG_Core_class_is_listening(const hg_core_class_t *hg_core_class)
+{
+    hg_bool_t ret = HG_FALSE;
+
+    if (!hg_core_class) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    ret = NA_Is_listening(hg_core_class->na_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_class_t *
+HG_Core_class_get_na(const hg_core_class_t *hg_core_class)
+{
+    na_class_t *ret = NULL;
+
+    if (!hg_core_class) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    ret = hg_core_class->na_class;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+#ifdef HG_HAS_SM_ROUTING
+na_class_t *
+HG_Core_class_get_na_sm(const hg_core_class_t *hg_core_class)
+{
+    na_class_t *ret = NULL;
+
+    if (!hg_core_class) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    ret = hg_core_class->na_sm_class;
+
+done:
+    return ret;
+}
+#endif
+
+/*---------------------------------------------------------------------------*/
+hg_size_t
+HG_Core_class_get_input_eager_size(const hg_core_class_t *hg_core_class)
+{
+    hg_size_t ret = 0, unexp, header;
+
+    if (hg_core_class == NULL) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    unexp  = NA_Msg_get_max_unexpected_size(hg_core_class->na_class);
+    header = hg_core_header_request_get_size() +
+        NA_Msg_get_unexpected_header_size(hg_core_class->na_class);
+    if (unexp > header)
+        ret = unexp - header;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_size_t
+HG_Core_class_get_output_eager_size(const hg_core_class_t *hg_core_class)
+{
+    hg_size_t ret = 0, exp, header;
+
+    if (hg_core_class == NULL) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    exp    = NA_Msg_get_max_expected_size(hg_core_class->na_class);
+    header = hg_core_header_response_get_size() +
+        NA_Msg_get_expected_header_size(hg_core_class->na_class);
+    if (exp > header)
+        ret = exp - header;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Core_class_set_data(hg_core_class_t *hg_core_class, void *data,
+    void (*free_callback)(void *))
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_core_class) {
+        HG_LOG_ERROR("NULL HG core class");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    hg_core_class->data = data;
+    hg_core_class->data_free_callback = free_callback;
+
+ done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+void *
+HG_Core_class_get_data(const hg_core_class_t *hg_core_class)
+{
+    void *ret = NULL;
+
+    if (!hg_core_class) {
+        HG_LOG_ERROR("NULL HG core class");
+        goto done;
+    }
+
+    ret = hg_core_class->data;
-    private_class->more_data_acquire = more_data_acquire_callback;
-    private_class->more_data_release = more_data_release_callback;
 
 done:
     return ret;
@@ -3612,7 +3759,7 @@
 HG_Core_context_create_id(hg_core_class_t *hg_core_class, hg_uint8_t id)
 {
     hg_return_t ret = HG_SUCCESS;
+    struct hg_core_context *context = NULL;
-    struct hg_core_private_context *context = NULL;
     int na_poll_fd;
 #ifdef HG_HAS_SELF_FORWARD
     int fd;
@@ -3624,15 +3771,14 @@
         goto done;
     }
 
+    context = (struct hg_core_context *) malloc(sizeof(struct hg_core_context));
-    context = (struct hg_core_private_context *) malloc(
-        sizeof(struct hg_core_private_context));
     if (!context) {
         HG_LOG_ERROR("Could not allocate HG context");
         ret = HG_NOMEM_ERROR;
         goto done;
     }
+    memset(context, 0, sizeof(struct hg_core_context));
+    context->hg_core_class = hg_core_class;
-    memset(context, 0, sizeof(struct hg_core_private_context));
-    context->core_context.core_class = hg_core_class;
     context->completion_queue =
         hg_atomic_queue_alloc(HG_CORE_ATOMIC_QUEUE_SIZE);
     if (!context->completion_queue) {
@@ -3662,18 +3808,16 @@
 #endif
     hg_thread_spin_init(&context->created_list_lock);
 
+    context->na_context = NA_Context_create_id(hg_core_class->na_class, id);
+    if (!context->na_context) {
-    context->core_context.na_context = NA_Context_create_id(
-        hg_core_class->na_class, id);
-    if (!context->core_context.na_context) {
         HG_LOG_ERROR("Could not create NA context");
         ret = HG_NA_ERROR;
         goto done;
     }
 #ifdef HG_HAS_SM_ROUTING
     if (hg_core_class->na_sm_class) {
+        context->na_sm_context = NA_Context_create(hg_core_class->na_sm_class);
+        if (!context->na_sm_context) {
-        context->core_context.na_sm_context = NA_Context_create(
-            hg_core_class->na_sm_class);
-        if (!context->core_context.na_sm_context) {
             HG_LOG_ERROR("Could not create NA SM context");
             ret = HG_NA_ERROR;
             goto done;
@@ -3704,14 +3848,13 @@
         hg_core_completion_queue_notify_cb, context);
 #endif
 
+    if (context->hg_core_class->progress_mode == NA_NO_BLOCK)
-    if (HG_CORE_CONTEXT_CLASS(context)->progress_mode == NA_NO_BLOCK)
         /* Force to use progress poll */
         na_poll_fd = 0;
     else
         /* If NA plugin exposes fd, add it to poll set and use appropriate
          * progress function */
+        na_poll_fd = NA_Poll_get_fd(hg_core_class->na_class, context->na_context);
-        na_poll_fd = NA_Poll_get_fd(hg_core_class->na_class,
-            context->core_context.na_context);
     if (na_poll_fd >= 0) {
         hg_poll_add(context->poll_set, na_poll_fd, HG_POLLIN,
             hg_core_progress_na_cb, context);
@@ -3723,18 +3866,18 @@
 
 #ifdef HG_HAS_SM_ROUTING
     /* Auto SM requires hg_core_progress_poll */
+    if (context->na_sm_context) {
-    if (context->core_context.na_sm_context) {
         if (context->progress != hg_core_progress_poll) {
             HG_LOG_ERROR("Auto SM mode not supported with selected plugin");
             ret = HG_PROTOCOL_ERROR;
             goto done;
         }
+        if (context->hg_core_class->progress_mode == NA_NO_BLOCK)
-        if (HG_CORE_CONTEXT_CLASS(context)->progress_mode == NA_NO_BLOCK)
             /* Force to use progress poll */
             na_poll_fd = 0;
         else {
             na_poll_fd = NA_Poll_get_fd(hg_core_class->na_sm_class,
+                context->na_sm_context);
-                context->core_context.na_sm_context);
             if (na_poll_fd < 0) {
                 HG_LOG_ERROR("Could not get NA SM poll fd");
                 ret = HG_NA_ERROR;
@@ -3747,25 +3890,23 @@
 #endif
 
     /* Assign context ID */
+    context->id = id;
-    context->core_context.id = id;
 
     /* Increment context count of parent class */
+    hg_atomic_incr32(&hg_core_class->n_contexts);
-    hg_atomic_incr32(&HG_CORE_CONTEXT_CLASS(context)->n_contexts);
 
 done:
     if (ret != HG_SUCCESS && context) {
+        HG_Core_context_destroy(context);
-        HG_Core_context_destroy((hg_core_context_t *) context);
         context = NULL;
     }
+    return context;
-    return (hg_core_context_t *) context;
 }
 
 /*---------------------------------------------------------------------------*/
 hg_return_t
 HG_Core_context_destroy(hg_core_context_t *context)
 {
-    struct hg_core_private_context *private_context =
-        (struct hg_core_private_context *) context;
     na_return_t na_ret;
     hg_return_t ret = HG_SUCCESS;
     unsigned int actual_count;
@@ -3775,11 +3916,11 @@
     if (!context) goto done;
 
     /* Prevent repost of handles */
+    context->finalizing = HG_TRUE;
-    private_context->finalizing = HG_TRUE;
 
     /* Check pending list and cancel posted handles */
+    if (!HG_LIST_IS_EMPTY(&context->pending_list)) {
+        ret = hg_core_pending_list_cancel(context);
-    if (!HG_LIST_IS_EMPTY(&private_context->pending_list)) {
-        ret = hg_core_pending_list_cancel(private_context);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Cannot cancel list of pending entries");
             goto done;
@@ -3787,8 +3928,8 @@
     }
 #ifdef HG_HAS_SM_ROUTING
     /* Check pending list and cancel posted handles */
+    if (!HG_LIST_IS_EMPTY(&context->sm_pending_list)) {
+        ret = hg_core_sm_pending_list_cancel(context);
-    if (!HG_LIST_IS_EMPTY(&private_context->sm_pending_list)) {
-        ret = hg_core_sm_pending_list_cancel(private_context);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Cannot cancel list of SM pending entries");
             goto done;
@@ -3805,14 +3946,13 @@
 #ifdef HG_HAS_SM_ROUTING
     if (context->na_sm_context) {
         do {
+            na_ret = NA_Trigger(context->na_sm_context, 0, 1, NULL, &actual_count);
-            na_ret = NA_Trigger(context->na_sm_context, 0, 1, NULL,
-                &actual_count);
         } while ((na_ret == NA_SUCCESS) && actual_count);
     }
 #endif
 
     /* Check that operations have completed */
+    ret = hg_core_created_list_wait(context);
-    ret = hg_core_created_list_wait(private_context);
     if (ret != HG_SUCCESS && ret != HG_TIMEOUT) {
         HG_LOG_ERROR("Could not wait on HG core handle list");
         goto done;
@@ -3820,53 +3960,52 @@
 
 #ifdef HG_HAS_SELF_FORWARD
     /* Destroy self processing pool if created */
+    hg_thread_pool_destroy(context->self_processing_pool);
-    hg_thread_pool_destroy(private_context->self_processing_pool);
 #endif
 
     /* Number of handles for that context should be 0 */
+    n_handles = hg_atomic_get32(&context->n_handles);
-    n_handles = hg_atomic_get32(&private_context->n_handles);
     if (n_handles != 0) {
+        struct hg_core_handle *hg_core_handle = NULL;
-        struct hg_core_private_handle *hg_core_handle = NULL;
         HG_LOG_ERROR("HG core handles must be freed before destroying context "
             "(%d remaining)", n_handles);
+        hg_thread_spin_lock(&context->created_list_lock);
+        HG_LIST_FOREACH(hg_core_handle, &context->created_list, created) {
-        hg_thread_spin_lock(&private_context->created_list_lock);
-        HG_LIST_FOREACH(hg_core_handle, &private_context->created_list, created) {
             HG_LOG_ERROR("HG core handle at address %p was not destroyed",
                 hg_core_handle);
         }
+        hg_thread_spin_unlock(&context->created_list_lock);
-        hg_thread_spin_unlock(&private_context->created_list_lock);
         ret = HG_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Check that completion queue is empty now */
+    if (!hg_atomic_queue_is_empty(context->completion_queue)) {
-    if (!hg_atomic_queue_is_empty(private_context->completion_queue)) {
         HG_LOG_ERROR("Completion queue should be empty");
         ret = HG_PROTOCOL_ERROR;
         goto done;
     }
+    hg_atomic_queue_free(context->completion_queue);
-    hg_atomic_queue_free(private_context->completion_queue);
 
     /* Check that completion queue is empty now */
+    hg_thread_mutex_lock(&context->completion_queue_mutex);
+    if (!HG_QUEUE_IS_EMPTY(&context->backfill_queue)) {
-    hg_thread_mutex_lock(&private_context->completion_queue_mutex);
-    if (!HG_QUEUE_IS_EMPTY(&private_context->backfill_queue)) {
         HG_LOG_ERROR("Completion queue should be empty");
         ret = HG_PROTOCOL_ERROR;
+        hg_thread_mutex_unlock(&context->completion_queue_mutex);
-        hg_thread_mutex_unlock(&private_context->completion_queue_mutex);
         goto done;
     }
+    hg_thread_mutex_unlock(&context->completion_queue_mutex);
-    hg_thread_mutex_unlock(&private_context->completion_queue_mutex);
 
 #ifdef HG_HAS_SELF_FORWARD
+    if (context->completion_queue_notify > 0) {
+        if (hg_poll_remove(context->poll_set, context->completion_queue_notify)
+            != HG_UTIL_SUCCESS) {
-    if (private_context->completion_queue_notify > 0) {
-        if (hg_poll_remove(private_context->poll_set,
-            private_context->completion_queue_notify) != HG_UTIL_SUCCESS) {
             HG_LOG_ERROR("Could not remove self processing event from poll set");
             ret = HG_PROTOCOL_ERROR;
             goto done;
         }
+        if (hg_event_destroy(context->completion_queue_notify) != HG_UTIL_SUCCESS) {
-        if (hg_event_destroy(private_context->completion_queue_notify)
-            != HG_UTIL_SUCCESS) {
             HG_LOG_ERROR("Could not destroy self processing event");
             ret = HG_PROTOCOL_ERROR;
             goto done;
@@ -3874,16 +4013,15 @@
     }
 #endif
 
+    if (context->hg_core_class->progress_mode == NA_NO_BLOCK)
-    if (HG_CORE_CONTEXT_CLASS(private_context)->progress_mode == NA_NO_BLOCK)
         /* Was forced to use progress poll */
         na_poll_fd = 0;
     else
         /* If NA plugin exposes fd, remove it from poll set */
+        na_poll_fd = NA_Poll_get_fd(context->hg_core_class->na_class,
-        na_poll_fd = NA_Poll_get_fd(context->core_class->na_class,
             context->na_context);
     if ((na_poll_fd >= 0)
+        && hg_poll_remove(context->poll_set, na_poll_fd) != HG_UTIL_SUCCESS) {
-        && hg_poll_remove(private_context->poll_set, na_poll_fd)
-        != HG_UTIL_SUCCESS) {
         HG_LOG_ERROR("Could not remove NA poll descriptor from poll set");
         ret = HG_PROTOCOL_ERROR;
         goto done;
@@ -3891,16 +4029,15 @@
 
 #ifdef HG_HAS_SM_ROUTING
     if (context->na_sm_context) {
+        if (context->hg_core_class->progress_mode == NA_NO_BLOCK)
-        if (HG_CORE_CONTEXT_CLASS(private_context)->progress_mode == NA_NO_BLOCK)
             /* Was forced to use progress poll */
             na_poll_fd = 0;
         else
             /* If NA plugin exposes fd, remove it from poll set */
+            na_poll_fd = NA_Poll_get_fd(context->hg_core_class->na_sm_class,
-            na_poll_fd = NA_Poll_get_fd(context->core_class->na_sm_class,
                 context->na_sm_context);
         if ((na_poll_fd >= 0)
+            && hg_poll_remove(context->poll_set, na_poll_fd) != HG_UTIL_SUCCESS) {
-            && hg_poll_remove(private_context->poll_set, na_poll_fd)
-            != HG_UTIL_SUCCESS) {
             HG_LOG_ERROR("Could not remove NA poll descriptor from poll set");
             ret = HG_PROTOCOL_ERROR;
             goto done;
@@ -3909,14 +4046,14 @@
 #endif
 
     /* Destroy poll set */
+    if (hg_poll_destroy(context->poll_set) != HG_UTIL_SUCCESS) {
-    if (hg_poll_destroy(private_context->poll_set) != HG_UTIL_SUCCESS) {
         HG_LOG_ERROR("Could not destroy poll set");
         ret = HG_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Destroy NA context */
+    if (context->na_context && NA_Context_destroy(context->hg_core_class->na_class,
-    if (context->na_context && NA_Context_destroy(context->core_class->na_class,
             context->na_context) != NA_SUCCESS) {
         HG_LOG_ERROR("Could not destroy NA context");
         ret = HG_NA_ERROR;
@@ -3926,7 +4063,7 @@
 #ifdef HG_HAS_SM_ROUTING
     /* Destroy NA SM context */
     if (context->na_sm_context && NA_Context_destroy(
+        context->hg_core_class->na_sm_class, context->na_sm_context) != NA_SUCCESS) {
-        context->core_class->na_sm_class, context->na_sm_context) != NA_SUCCESS) {
         HG_LOG_ERROR("Could not destroy NA SM context");
         ret = HG_NA_ERROR;
         goto done;
@@ -3938,18 +4075,126 @@
         context->data_free_callback(context->data);
 
     /* Destroy completion queue mutex/cond */
+    hg_thread_mutex_destroy(&context->completion_queue_mutex);
+    hg_thread_cond_destroy(&context->completion_queue_cond);
+    hg_thread_spin_destroy(&context->pending_list_lock);
-    hg_thread_mutex_destroy(&private_context->completion_queue_mutex);
-    hg_thread_cond_destroy(&private_context->completion_queue_cond);
-    hg_thread_spin_destroy(&private_context->pending_list_lock);
 #ifdef HG_HAS_SM_ROUTING
+    hg_thread_spin_destroy(&context->sm_pending_list_lock);
-    hg_thread_spin_destroy(&private_context->sm_pending_list_lock);
 #endif
+    hg_thread_spin_destroy(&context->created_list_lock);
-    hg_thread_spin_destroy(&private_context->created_list_lock);
 
     /* Decrement context count of parent class */
+    hg_atomic_decr32(&context->hg_core_class->n_contexts);
+
+    free(context);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_core_class_t *
+HG_Core_context_get_class(const hg_core_context_t *context)
+{
+    hg_core_class_t *ret = NULL;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG core context");
+        goto done;
+    }
+
+    ret = context->hg_core_class;
+
+ done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_context_t *
+HG_Core_context_get_na(const hg_core_context_t *context)
+{
+    na_context_t *ret = NULL;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG core context");
+        goto done;
+    }
+
+    ret = context->na_context;
+
+ done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+#ifdef HG_HAS_SM_ROUTING
+na_context_t *
+HG_Core_context_get_na_sm(const hg_core_context_t *context)
+{
+    na_context_t *ret = NULL;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG core context");
+        goto done;
+    }
+
+    ret = context->na_sm_context;
+
+done:
+    return ret;
+}
+#endif
+
+/*---------------------------------------------------------------------------*/
+hg_uint8_t
+HG_Core_context_get_id(const hg_core_context_t *context)
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG core context");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    ret = context->id;
+
+ done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Core_context_set_data(hg_core_context_t *context, void *data,
+    void (*free_callback)(void *))
+{
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG core context");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    context->data = data;
+    context->data_free_callback = free_callback;
+
+ done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+void *
+HG_Core_context_get_data(const hg_core_context_t *context)
+{
+    void *ret = NULL;
+
+    if (!context) {
+        HG_LOG_ERROR("NULL HG core context");
+        goto done;
+    }
-    hg_atomic_decr32(&HG_CORE_CONTEXT_CLASS(private_context)->n_contexts);
 
+    ret = context->data;
-    free(private_context);
 
 done:
     return ret;
@@ -3960,8 +4205,6 @@
 HG_Core_context_set_handle_create_callback(hg_core_context_t *context,
     hg_return_t (*callback)(hg_core_handle_t, void *), void *arg)
 {
-    struct hg_core_private_context *private_context =
-        (struct hg_core_private_context *) context;
     hg_return_t ret = HG_SUCCESS;
 
     if (!context) {
@@ -3970,8 +4213,8 @@
         goto done;
     }
 
+    context->handle_create = callback;
+    context->handle_create_arg = arg;
-    private_context->handle_create = callback;
-    private_context->handle_create_arg = arg;
 
  done:
     return ret;
@@ -3999,8 +4242,7 @@
 #ifdef HG_HAS_SM_ROUTING
     do {
 #endif
+        ret = hg_core_context_post(context, request_count, repost, use_sm);
-        ret = hg_core_context_post((struct hg_core_private_context *) context,
-            request_count, repost, use_sm);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Could not post requests on context");
             goto done;
@@ -4020,8 +4262,6 @@
 HG_Core_register(hg_core_class_t *hg_core_class, hg_id_t id,
     hg_core_rpc_cb_t rpc_cb)
 {
-    struct hg_core_private_class *private_class =
-        (struct hg_core_private_class *) hg_core_class;
     hg_id_t *func_key = NULL;
     struct hg_core_rpc_info *hg_core_rpc_info = NULL;
     hg_return_t ret = HG_SUCCESS;
@@ -4034,12 +4274,12 @@
     }
 
     /* Check if registered and set RPC CB */
+    hg_thread_spin_lock(&hg_core_class->func_map_lock);
-    hg_thread_spin_lock(&private_class->func_map_lock);
     hg_core_rpc_info = (struct hg_core_rpc_info *) hg_hash_table_lookup(
+            hg_core_class->func_map, (hg_hash_table_key_t) &id);
-            private_class->func_map, (hg_hash_table_key_t) &id);
     if (hg_core_rpc_info && rpc_cb)
         hg_core_rpc_info->rpc_cb = rpc_cb;
+    hg_thread_spin_unlock(&hg_core_class->func_map_lock);
-    hg_thread_spin_unlock(&private_class->func_map_lock);
 
     if (!hg_core_rpc_info) {
         /* Allocate the key */
@@ -4052,8 +4292,7 @@
         *func_key = id;
 
         /* Fill info and store it into the function map */
+        hg_core_rpc_info = (struct hg_core_rpc_info *) malloc(sizeof(struct hg_core_rpc_info));
-        hg_core_rpc_info = (struct hg_core_rpc_info *) malloc(
-            sizeof(struct hg_core_rpc_info));
         if (!hg_core_rpc_info) {
             HG_LOG_ERROR("Could not allocate HG info");
             ret = HG_NOMEM_ERROR;
@@ -4064,10 +4303,10 @@
         hg_core_rpc_info->data = NULL;
         hg_core_rpc_info->free_callback = NULL;
 
+        hg_thread_spin_lock(&hg_core_class->func_map_lock);
+        hash_ret = hg_hash_table_insert(hg_core_class->func_map,
-        hg_thread_spin_lock(&private_class->func_map_lock);
-        hash_ret = hg_hash_table_insert(private_class->func_map,
             (hg_hash_table_key_t) func_key, hg_core_rpc_info);
+        hg_thread_spin_unlock(&hg_core_class->func_map_lock);
-        hg_thread_spin_unlock(&private_class->func_map_lock);
         if (!hash_ret) {
             HG_LOG_ERROR("Could not insert RPC ID into function map (already registered?)");
             ret = HG_INVALID_PARAM;
@@ -4087,8 +4326,6 @@
 hg_return_t
 HG_Core_deregister(hg_core_class_t *hg_core_class, hg_id_t id)
 {
-    struct hg_core_private_class *private_class =
-        (struct hg_core_private_class *) hg_core_class;
     hg_return_t ret = HG_SUCCESS;
     int hash_ret;
 
@@ -4098,10 +4335,10 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_core_class->func_map_lock);
+    hash_ret = hg_hash_table_remove(hg_core_class->func_map,
-    hg_thread_spin_lock(&private_class->func_map_lock);
-    hash_ret = hg_hash_table_remove(private_class->func_map,
         (hg_hash_table_key_t) &id);
+    hg_thread_spin_unlock(&hg_core_class->func_map_lock);
-    hg_thread_spin_unlock(&private_class->func_map_lock);
     if (!hash_ret) {
         HG_LOG_ERROR("Could not deregister RPC ID from function map");
         ret = HG_INVALID_PARAM;
@@ -4116,8 +4353,6 @@
 hg_return_t
 HG_Core_registered(hg_core_class_t *hg_core_class, hg_id_t id, hg_bool_t *flag)
 {
-    struct hg_core_private_class *private_class =
-        (struct hg_core_private_class *) hg_core_class;
     hg_return_t ret = HG_SUCCESS;
 
     if (!hg_core_class) {
@@ -4131,10 +4366,10 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_core_class->func_map_lock);
+    *flag = (hg_bool_t) (hg_hash_table_lookup(hg_core_class->func_map,
-    hg_thread_spin_lock(&private_class->func_map_lock);
-    *flag = (hg_bool_t) (hg_hash_table_lookup(private_class->func_map,
             (hg_hash_table_key_t) &id) != HG_HASH_TABLE_NULL);
+    hg_thread_spin_unlock(&hg_core_class->func_map_lock);
-    hg_thread_spin_unlock(&private_class->func_map_lock);
 
 done:
     return ret;
@@ -4145,8 +4380,6 @@
 HG_Core_register_data(hg_core_class_t *hg_core_class, hg_id_t id, void *data,
     void (*free_callback)(void *))
 {
-    struct hg_core_private_class *private_class =
-        (struct hg_core_private_class *) hg_core_class;
     struct hg_core_rpc_info *hg_core_rpc_info = NULL;
     hg_return_t ret = HG_SUCCESS;
 
@@ -4156,10 +4389,10 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_core_class->func_map_lock);
+    hg_core_rpc_info = (struct hg_core_rpc_info *) hg_hash_table_lookup(hg_core_class->func_map,
+            (hg_hash_table_key_t) &id);
+    hg_thread_spin_unlock(&hg_core_class->func_map_lock);
-    hg_thread_spin_lock(&private_class->func_map_lock);
-    hg_core_rpc_info = (struct hg_core_rpc_info *) hg_hash_table_lookup(
-        private_class->func_map, (hg_hash_table_key_t) &id);
-    hg_thread_spin_unlock(&private_class->func_map_lock);
     if (!hg_core_rpc_info) {
         HG_LOG_ERROR("Could not find RPC ID in function map");
         ret = HG_NO_MATCH;
@@ -4179,8 +4412,6 @@
 void *
 HG_Core_registered_data(hg_core_class_t *hg_core_class, hg_id_t id)
 {
-    struct hg_core_private_class *private_class =
-        (struct hg_core_private_class *) hg_core_class;
     struct hg_core_rpc_info *hg_core_rpc_info = NULL;
     void *data = NULL;
 
@@ -4189,10 +4420,10 @@
         goto done;
     }
 
+    hg_thread_spin_lock(&hg_core_class->func_map_lock);
+    hg_core_rpc_info = (struct hg_core_rpc_info *) hg_hash_table_lookup(hg_core_class->func_map,
+            (hg_hash_table_key_t) &id);
+    hg_thread_spin_unlock(&hg_core_class->func_map_lock);
-    hg_thread_spin_lock(&private_class->func_map_lock);
-    hg_core_rpc_info = (struct hg_core_rpc_info *) hg_hash_table_lookup(
-        private_class->func_map, (hg_hash_table_key_t) &id);
-    hg_thread_spin_unlock(&private_class->func_map_lock);
     if (!hg_core_rpc_info) {
         HG_LOG_ERROR("Could not find RPC ID in function map");
         goto done;
@@ -4206,8 +4437,8 @@
 
 /*---------------------------------------------------------------------------*/
 hg_return_t
+HG_Core_addr_lookup(hg_core_context_t *context, hg_core_cb_t callback, void *arg,
+    const char *name, hg_core_op_id_t *op_id)
-HG_Core_addr_lookup(hg_core_context_t *context, hg_core_cb_t callback,
-    void *arg, const char *name, hg_core_op_id_t *op_id)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -4227,8 +4458,7 @@
         goto done;
     }
 
+    ret = hg_core_addr_lookup(context, callback, arg, name, op_id);
-    ret = hg_core_addr_lookup((struct hg_core_private_context *) context,
-        callback, arg, name, op_id);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not lookup address");
         goto done;
@@ -4239,28 +4469,33 @@
 }
 
 /*---------------------------------------------------------------------------*/
+hg_core_addr_t
+HG_Core_addr_create(hg_core_class_t *core_class)
+{
+    if (core_class == NULL) {
+        HG_LOG_ERROR("NULL HG core class");
+        return HG_CORE_ADDR_NULL;
+    }
+
+    return hg_core_addr_create(core_class, core_class->na_class);
+
+}
+
+/*---------------------------------------------------------------------------*/
 hg_return_t
+HG_Core_addr_free(hg_core_class_t *hg_core_class, hg_core_addr_t addr)
-HG_Core_addr_create(hg_core_class_t *hg_core_class, hg_core_addr_t *addr)
 {
     hg_return_t ret = HG_SUCCESS;
 
+    if (!hg_core_class) {
-    if (hg_core_class == NULL) {
         HG_LOG_ERROR("NULL HG core class");
         ret = HG_INVALID_PARAM;
         goto done;
     }
-    if (!addr) {
-        HG_LOG_ERROR("NULL pointer to address");
-        ret = HG_INVALID_PARAM;
-        goto done;
-    }
 
+    ret = hg_core_addr_free(hg_core_class, addr);
+    if (ret != HG_SUCCESS) {
+        HG_LOG_ERROR("Could not free address");
-    *addr = (hg_core_addr_t) hg_core_addr_create(
-        (struct hg_core_private_class *) hg_core_class,
-        hg_core_class->na_class);
-    if (*addr == HG_CORE_ADDR_NULL) {
-        HG_LOG_ERROR("Could not create address");
-        ret = HG_NOMEM_ERROR;
         goto done;
     }
 
@@ -4269,26 +4504,47 @@
 }
 
 /*---------------------------------------------------------------------------*/
+void
+HG_Core_addr_set_na(hg_core_addr_t core_addr, na_addr_t na_addr)
+{
+    if (core_addr == HG_CORE_ADDR_NULL)
+        return;
+
+    core_addr->na_addr = na_addr;
+}
+
+/*---------------------------------------------------------------------------*/
+na_addr_t
+HG_Core_addr_get_na(hg_core_addr_t addr)
-hg_return_t
-HG_Core_addr_free(hg_core_class_t *hg_core_class, hg_core_addr_t addr)
 {
+    na_addr_t ret = NA_ADDR_NULL;
-    hg_return_t ret = HG_SUCCESS;
 
+    if (addr == HG_CORE_ADDR_NULL) {
+        HG_LOG_ERROR("NULL addr");
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        ret = HG_INVALID_PARAM;
         goto done;
     }
 
+    ret = addr->na_addr;
+
+done:
+     return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_class_t *
+HG_Core_addr_get_na_class(hg_core_addr_t addr)
+{
+    na_class_t *ret = NULL;
+
+    if (addr == HG_CORE_ADDR_NULL) {
+        HG_LOG_ERROR("NULL addr");
-    ret = hg_core_addr_free((struct hg_core_private_class *) hg_core_class,
-        (struct hg_core_private_addr *) addr);
-    if (ret != HG_SUCCESS) {
-        HG_LOG_ERROR("Could not free address");
         goto done;
     }
 
+    ret = addr->na_class;
+
 done:
+     return ret;
-    return ret;
 }
 
 /*---------------------------------------------------------------------------*/
@@ -4308,8 +4564,7 @@
         goto done;
     }
 
+    ret = hg_core_addr_self(hg_core_class, addr);
-    ret = hg_core_addr_self((struct hg_core_private_class *) hg_core_class,
-        (struct hg_core_private_addr **) addr);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not get self address");
         goto done;
@@ -4321,8 +4576,7 @@
 
 /*---------------------------------------------------------------------------*/
 hg_return_t
+HG_Core_addr_dup(hg_core_class_t *hg_core_class, hg_core_addr_t addr, hg_core_addr_t *new_addr)
-HG_Core_addr_dup(hg_core_class_t *hg_core_class, hg_core_addr_t addr,
-    hg_core_addr_t *new_addr)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -4342,9 +4596,7 @@
         goto done;
     }
 
+    ret = hg_core_addr_dup(hg_core_class, addr, new_addr);
-    ret = hg_core_addr_dup((struct hg_core_private_class *) hg_core_class,
-        (struct hg_core_private_addr *) addr,
-        (struct hg_core_private_addr **) new_addr);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not duplicate address");
         goto done;
@@ -4356,8 +4608,8 @@
 
 /*---------------------------------------------------------------------------*/
 hg_return_t
+HG_Core_addr_to_string(hg_core_class_t *hg_core_class, char *buf, hg_size_t *buf_size,
+    hg_core_addr_t addr)
-HG_Core_addr_to_string(hg_core_class_t *hg_core_class, char *buf,
-    hg_size_t *buf_size, hg_core_addr_t addr)
 {
     hg_return_t ret = HG_SUCCESS;
 
@@ -4367,8 +4619,7 @@
         goto done;
     }
 
+    ret = hg_core_addr_to_string(hg_core_class, buf, buf_size, addr);
-    ret = hg_core_addr_to_string((struct hg_core_private_class *) hg_core_class,
-        buf, buf_size, (struct hg_core_private_addr *) addr);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not convert address to string");
         goto done;
@@ -4383,11 +4634,10 @@
 HG_Core_create(hg_core_context_t *context, hg_core_addr_t addr, hg_id_t id,
     hg_core_handle_t *handle)
 {
+    struct hg_core_handle *hg_core_handle = NULL;
+#ifdef HG_HAS_SM_ROUTING
+    struct hg_core_addr *hg_core_addr = addr;
+#endif
-    struct hg_core_private_context *private_context =
-        (struct hg_core_private_context *) context;
-    struct hg_core_private_handle *hg_core_handle = NULL;
-    struct hg_core_private_addr *private_addr =
-        (struct hg_core_private_addr *) addr;
     hg_bool_t use_sm = HG_FALSE;
     hg_return_t ret = HG_SUCCESS;
 
@@ -4403,13 +4653,12 @@
     }
 
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_addr && (hg_core_addr->na_class == context->hg_core_class->na_sm_class))
-    if (private_addr
-        && (private_addr->core_addr.na_class == context->core_class->na_sm_class))
         use_sm = HG_TRUE;
 #endif
 
     /* Create new handle */
+    hg_core_handle = hg_core_create(context, use_sm);
-    hg_core_handle = hg_core_create(private_context, use_sm);
     if (!hg_core_handle) {
         HG_LOG_ERROR("Could not create HG core handle");
         ret = HG_NOMEM_ERROR;
@@ -4417,7 +4666,7 @@
     }
 
     /* Set addr / RPC ID */
+    ret = hg_core_set_rpc(hg_core_handle, addr, id);
-    ret = hg_core_set_rpc(hg_core_handle, private_addr, id);
     if (ret != HG_SUCCESS) {
         if (ret != HG_NO_MATCH) /* silence error if invalid ID is used */
             HG_LOG_ERROR("Could not set rpc to handle");
@@ -4426,9 +4675,9 @@
 
     /* Execute class callback on handle, this allows upper layers to
      * allocate private data on handle creation */
+    if (context->handle_create) {
+        ret = context->handle_create(hg_core_handle,
+            context->handle_create_arg);
-    if (private_context->handle_create) {
-        ret = private_context->handle_create((hg_core_handle_t) hg_core_handle,
-            private_context->handle_create_arg);
         if (ret != HG_SUCCESS) {
             HG_LOG_ERROR("Error in HG core handle create callback");
             goto done;
@@ -4448,8 +4697,7 @@
 hg_return_t
 HG_Core_destroy(hg_core_handle_t handle)
 {
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
     hg_return_t ret = HG_SUCCESS;
 
     if (!hg_core_handle) {
@@ -4459,8 +4707,7 @@
     }
 
     /* Repost handle if we were listening, otherwise destroy it */
+    if (hg_core_handle->repost && !hg_core_handle->hg_info.context->finalizing) {
-    if (hg_core_handle->repost
-        && !HG_CORE_HANDLE_CONTEXT(hg_core_handle)->finalizing) {
         /* Repost handle */
         ret = hg_core_reset_post(hg_core_handle);
         if (ret != HG_SUCCESS) {
@@ -4478,10 +4725,10 @@
 hg_return_t
 HG_Core_reset(hg_core_handle_t handle, hg_core_addr_t addr, hg_id_t id)
 {
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+#ifdef HG_HAS_SM_ROUTING
+    struct hg_core_addr *hg_core_addr = addr;
+#endif
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
-    struct hg_core_private_addr *hg_core_addr =
-        (struct hg_core_private_addr *) addr;
     hg_return_t ret = HG_SUCCESS;
 
     if (!handle) {
@@ -4491,8 +4738,7 @@
     }
 
 #ifdef HG_HAS_SM_ROUTING
+    if (hg_core_addr && (hg_core_addr->na_class != hg_core_handle->na_class)) {
-    if (hg_core_addr
-        && (hg_core_addr->core_addr.na_class != hg_core_handle->na_class)) {
         HG_LOG_ERROR("Cannot reset handle to a different address NA class");
         ret = HG_INVALID_PARAM;
         goto done;
@@ -4503,15 +4749,14 @@
      * TODO could add the ability to defer the reset operation */
     if (hg_atomic_get32(&hg_core_handle->in_use)) {
         HG_LOG_ERROR("Cannot reset HG core handle, handle is still in use, "
+            "refcount: %d", hg_atomic_get32(&hg_core_handle->ref_count));
-            "refcount: %d",
-            hg_atomic_get32(&hg_core_handle->ref_count));
         ret = HG_PROTOCOL_ERROR;
         goto done;
     }
     hg_core_reset(hg_core_handle, HG_FALSE);
 
     /* Set addr / RPC ID */
+    ret = hg_core_set_rpc(hg_core_handle, addr, id);
-    ret = hg_core_set_rpc(hg_core_handle, hg_core_addr, id);
     if (ret != HG_SUCCESS) {
         goto done;
     }
@@ -4524,32 +4769,163 @@
 hg_return_t
 HG_Core_ref_incr(hg_core_handle_t handle)
 {
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_core_handle) {
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
         HG_LOG_ERROR("NULL pointer to HG core handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
-        return HG_INVALID_PARAM;
     }
+
-#endif
     hg_atomic_incr32(&hg_core_handle->ref_count);
 
+done:
+    return ret;
-    return HG_SUCCESS;
 }
 
 /*---------------------------------------------------------------------------*/
 hg_int32_t
 HG_Core_ref_get(hg_core_handle_t handle)
 {
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    hg_int32_t ret = -1;
+
+    if (!hg_core_handle) {
+        HG_LOG_ERROR("NULL pointer to HG core handle");
+        goto done;
+    }
+
+    ret = (hg_int32_t) hg_atomic_get32(&hg_core_handle->ref_count);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Core_set_data(hg_core_handle_t handle, void *data,
+    void (*free_callback)(void *))
+{
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_core_handle) {
+        HG_LOG_ERROR("NULL pointer to HG core handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    hg_core_handle->data = data;
+    hg_core_handle->data_free_callback = free_callback;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+void *
+HG_Core_get_data(hg_core_handle_t handle)
+{
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    void *ret = NULL;
+
+    if (!hg_core_handle) {
+        HG_LOG_ERROR("NULL pointer to HG core handle");
+        goto done;
+    }
+
+    ret = hg_core_handle->data;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+const struct hg_core_info *
+HG_Core_get_info(hg_core_handle_t handle)
+{
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    struct hg_core_info *ret = NULL;
+
+    if (!hg_core_handle) {
+        HG_LOG_ERROR("NULL handle");
+        goto done;
+    }
+
+    ret = &hg_core_handle->hg_info;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Core_set_target_id(hg_core_handle_t handle, hg_uint8_t id)
+{
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    hg_return_t ret = HG_SUCCESS;
+
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
-#ifdef HG_HAS_VERBOSE_ERROR
     if (!handle) {
+        HG_LOG_ERROR("NULL HG core handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    hg_core_handle->hg_info.context_id = id;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Core_get_input(hg_core_handle_t handle, void **in_buf, hg_size_t *in_buf_size)
+{
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_core_handle) {
+        HG_LOG_ERROR("NULL handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    if (!in_buf || !in_buf_size) {
+        HG_LOG_ERROR("NULL pointer");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    hg_core_get_input(hg_core_handle, in_buf, in_buf_size);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+hg_return_t
+HG_Core_get_output(hg_core_handle_t handle, void **out_buf, hg_size_t *out_buf_size)
+{
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
+    hg_return_t ret = HG_SUCCESS;
+
+    if (!hg_core_handle) {
+        HG_LOG_ERROR("NULL handle");
+        ret = HG_INVALID_PARAM;
+        goto done;
+    }
+
+    if (!out_buf || !out_buf_size) {
+        HG_LOG_ERROR("NULL pointer");
+        ret = HG_INVALID_PARAM;
+        goto done;
-        HG_LOG_ERROR("NULL pointer to HG core handle");
-        return -1;
     }
+
+    hg_core_get_output(hg_core_handle, out_buf, out_buf_size);
+
+done:
+    return ret;
-#endif
-    return (hg_int32_t) hg_atomic_get32(&hg_core_handle->ref_count);
 }
 
 /*---------------------------------------------------------------------------*/
@@ -4557,8 +4933,7 @@
 HG_Core_forward(hg_core_handle_t handle, hg_core_cb_t callback, void *arg,
     hg_uint8_t flags, hg_size_t payload_size)
 {
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
     hg_size_t header_size;
     hg_return_t ret = HG_SUCCESS;
 
@@ -4567,12 +4942,12 @@
         ret = HG_INVALID_PARAM;
         goto done;
     }
+    if (hg_core_handle->hg_info.addr == HG_CORE_ADDR_NULL) {
-    if (hg_core_handle->core_handle.info.addr == HG_CORE_ADDR_NULL) {
         HG_LOG_ERROR("NULL target addr");
         ret = HG_INVALID_PARAM;
         goto done;
     }
+    if (!hg_core_handle->hg_info.id) {
-    if (!hg_core_handle->core_handle.info.id) {
         HG_LOG_ERROR("NULL RPC ID");
         ret = HG_INVALID_PARAM;
         goto done;
@@ -4589,8 +4964,7 @@
         /* Not safe to reset
          * TODO could add the ability to defer the reset operation */
         HG_LOG_ERROR("Not safe to use HG core handle, handle is still in use, "
+            "refcount: %d", hg_atomic_get32(&hg_core_handle->ref_count));
-            "refcount: %d", hg_atomic_get32(
-                &hg_core_handle->ref_count));
         ret = HG_PROTOCOL_ERROR;
         goto done;
     }
@@ -4606,11 +4980,11 @@
 
     /* Set header size */
     header_size = hg_core_header_request_get_size() +
+        hg_core_handle->na_in_header_offset;
-        hg_core_handle->core_handle.na_in_header_offset;
 
     /* Set the actual size of the msg that needs to be transmitted */
     hg_core_handle->in_buf_used = header_size + payload_size;
+    if (hg_core_handle->in_buf_used > hg_core_handle->in_buf_size) {
-    if (hg_core_handle->in_buf_used > hg_core_handle->core_handle.in_buf_size) {
         HG_LOG_ERROR("Exceeding input buffer size");
         ret = HG_SIZE_ERROR;
         /* Handle is no longer in use */
@@ -4630,17 +5004,16 @@
     hg_core_handle->request_arg = arg;
 
     /* Set header */
+    hg_core_handle->in_header.msg.request.id = hg_core_handle->hg_info.id;
-    hg_core_handle->in_header.msg.request.id =
-        hg_core_handle->core_handle.info.id;
     hg_core_handle->in_header.msg.request.flags = flags;
     /* Set the cookie as origin context ID, so that when the cookie is unpacked
      * by the target and assigned to HG info context_id, the NA layer knows
      * which context ID it needs to send the response to. */
     hg_core_handle->in_header.msg.request.cookie =
+        hg_core_handle->hg_info.context->id;
-        hg_core_handle->core_handle.info.context->id;
 
     /* Encode request header */
+    ret = hg_core_proc_header_request(hg_core_handle,
-    ret = hg_core_proc_header_request(&hg_core_handle->core_handle,
         &hg_core_handle->in_header, HG_ENCODE);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not encode header");
@@ -4675,8 +5048,7 @@
 HG_Core_respond(hg_core_handle_t handle, hg_core_cb_t callback, void *arg,
     hg_uint8_t flags, hg_size_t payload_size)
 {
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
-    struct hg_core_private_handle *hg_core_handle =
-        (struct hg_core_private_handle *) handle;
     hg_size_t header_size;
     hg_return_t ret = HG_SUCCESS;
 
@@ -4686,8 +5058,8 @@
         goto done;
     }
 #ifndef HG_HAS_SELF_FORWARD
+    if (NA_Addr_is_self(hg_core_handle->hg_info.addr->na_class,
+        hg_core_handle->hg_info.addr->na_addr)) {
-    if (NA_Addr_is_self(hg_core_handle->core_handle.info.addr->na_class,
-        hg_core_handle->core_handle.info.addr->na_addr)) {
         HG_LOG_ERROR("Not enabled, please enable HG_USE_SELF_FORWARD");
         ret = HG_INVALID_PARAM;
         goto done;
@@ -4702,12 +5074,11 @@
 
     /* Set header size */
     header_size = hg_core_header_response_get_size() +
+        hg_core_handle->na_out_header_offset;
-        hg_core_handle->core_handle.na_out_header_offset;
 
     /* Set the actual size of the msg that needs to be transmitted */
     hg_core_handle->out_buf_used = header_size + payload_size;
+    if (hg_core_handle->out_buf_used > hg_core_handle->out_buf_size) {
-    if (hg_core_handle->out_buf_used
-        > hg_core_handle->core_handle.out_buf_size) {
         HG_LOG_ERROR("Exceeding output buffer size");
         ret = HG_SIZE_ERROR;
         goto done;
@@ -4724,7 +5095,7 @@
     hg_core_handle->out_header.msg.response.cookie = hg_core_handle->cookie;
 
     /* Encode response header */
+    ret = hg_core_proc_header_response(hg_core_handle,
-    ret = hg_core_proc_header_response(&hg_core_handle->core_handle,
         &hg_core_handle->out_header, HG_ENCODE);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not encode header");
@@ -4747,8 +5118,6 @@
 hg_return_t
 HG_Core_progress(hg_core_context_t *context, unsigned int timeout)
 {
-    struct hg_core_private_context *private_context =
-        (struct hg_core_private_context *) context;
     hg_return_t ret = HG_SUCCESS;
 
     if (!context) {
@@ -4758,7 +5127,7 @@
     }
 
     /* Make progress on the HG layer */
+    ret = context->progress(context, timeout);
-    ret = private_context->progress(private_context, timeout);
     if (ret != HG_SUCCESS && ret != HG_TIMEOUT) {
         HG_LOG_ERROR("Could not make progress");
         goto done;
@@ -4781,8 +5150,7 @@
         goto done;
     }
 
+    ret = hg_core_trigger(context, timeout, max_count, actual_count);
-    ret = hg_core_trigger((struct hg_core_private_context *) context, timeout,
-        max_count, actual_count);
     if (ret != HG_SUCCESS && ret != HG_TIMEOUT) {
         HG_LOG_ERROR("Could not trigger callbacks");
         goto done;
@@ -4796,15 +5164,16 @@
 hg_return_t
 HG_Core_cancel(hg_core_handle_t handle)
 {
+    struct hg_core_handle *hg_core_handle = (struct hg_core_handle *) handle;
     hg_return_t ret = HG_SUCCESS;
 
+    if (!hg_core_handle) {
-    if (!handle) {
         HG_LOG_ERROR("NULL handle");
         ret = HG_INVALID_PARAM;
         goto done;
     }
 
+    ret = hg_core_cancel(hg_core_handle);
-    ret = hg_core_cancel((struct hg_core_private_handle *) handle);
     if (ret != HG_SUCCESS) {
         HG_LOG_ERROR("Could not cancel handle");
         goto done;
--- b/src/mercury_core.h
+++ a/src/mercury_core.h
@@ -12,10 +12,6 @@
 #define MERCURY_CORE_H
 
 #include "mercury_core_types.h"
-#include "mercury_core_header.h"
-#include "mercury_error.h"
-
-#include "na.h"
 
 /*************************************/
 /* Public Type and Struct Definition */
@@ -29,7 +25,7 @@
 
 /* HG info struct */
 struct hg_core_info {
+    hg_core_class_t *hg_core_class; /* HG core class */
-    hg_core_class_t *core_class;    /* HG core class */
     hg_core_context_t *context;     /* HG core context */
     hg_core_addr_t addr;            /* HG address at target/origin */
     hg_uint8_t context_id;          /* Context ID at target/origin */
@@ -176,7 +172,7 @@
  *
  * \return the name of the class, or NULL if not a valid class
  */
+HG_EXPORT const char *
-static HG_INLINE const char *
 HG_Core_class_get_name(
         const hg_core_class_t *hg_core_class
         );
@@ -188,7 +184,7 @@
  *
  * \return the protocol of the class, or NULL if not a valid class
  */
+HG_EXPORT const char *
-static HG_INLINE const char *
 HG_Core_class_get_protocol(
         const hg_core_class_t *hg_core_class
         );
@@ -200,7 +196,7 @@
  *
  * \return HG_TRUE if listening or HG_FALSE if not, or not a valid class
  */
+HG_EXPORT hg_bool_t
-static HG_INLINE hg_bool_t
 HG_Core_class_is_listening(
         const hg_core_class_t *hg_core_class
         );
@@ -212,7 +208,7 @@
  *
  * \return Pointer to NA class or NULL if not a valid class
  */
+HG_EXPORT na_class_t *
-static HG_INLINE na_class_t *
 HG_Core_class_get_na(
         const hg_core_class_t *hg_core_class
         );
@@ -225,7 +221,7 @@
  *
  * \return Pointer to NA SM class or NULL if not a valid class
  */
+HG_EXPORT na_class_t *
-static HG_INLINE na_class_t *
 HG_Core_class_get_na_sm(
         const hg_core_class_t *hg_core_class
         );
@@ -239,7 +235,7 @@
  * \return the maximum size, or 0 if hg_core_class is not a valid class or
  * XDR is being used
  */
+HG_EXPORT hg_size_t
-static HG_INLINE hg_size_t
 HG_Core_class_get_input_eager_size(
         const hg_core_class_t *hg_core_class
         );
@@ -252,7 +248,7 @@
  * \return the maximum size, or 0 if hg_core_class is not a valid class or XDR is
  * being used
  */
+HG_EXPORT hg_size_t
-static HG_INLINE hg_size_t
 HG_Core_class_get_output_eager_size(
         const hg_core_class_t *hg_core_class
         );
@@ -267,7 +263,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Core_class_set_data(
         hg_core_class_t *hg_core_class,
         void *data,
@@ -281,7 +277,7 @@
  *
  * \return Pointer to user data or NULL if not set or any error has occurred
  */
+HG_EXPORT void *
-static HG_INLINE void *
 HG_Core_class_get_data(
         const hg_core_class_t *hg_core_class
         );
@@ -334,7 +330,7 @@
  *
  * \return the associated class
  */
+HG_EXPORT hg_core_class_t *
-static HG_INLINE hg_core_class_t *
 HG_Core_context_get_class(
         const hg_core_context_t *context
         );
@@ -346,7 +342,7 @@
  *
  * \return the associated context
  */
+HG_EXPORT na_context_t *
-static HG_INLINE na_context_t *
 HG_Core_context_get_na(
         const hg_core_context_t *context
         );
@@ -359,7 +355,7 @@
  *
  * \return the associated context
  */
+HG_EXPORT na_context_t *
-static HG_INLINE na_context_t *
 HG_Core_context_get_na_sm(
         const hg_core_context_t *context
         );
@@ -372,7 +368,7 @@
  *
  * \return Non-negative integer (max value of 255) or 0 if no ID has been set
  */
+HG_EXPORT hg_uint8_t
-static HG_INLINE hg_uint8_t
 HG_Core_context_get_id(
         const hg_core_context_t *context
         );
@@ -387,7 +383,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Core_context_set_data(
         hg_core_context_t *context,
         void *data,
@@ -401,7 +397,7 @@
  *
  * \return Pointer to user data or NULL if not set or any error has occurred
  */
+HG_EXPORT void *
-static HG_INLINE void *
 HG_Core_context_get_data(
         const hg_core_context_t *context
         );
@@ -555,14 +551,12 @@
  * Create a HG core address.
  *
  * \param hg_core_class [IN]    pointer to HG core class
- * \param new_addr [OUT]        pointer to abstract address
  *
+ * \return created abstract HG core address or HG_CORE_ADDR_NULL if failed.
- * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_core_addr_t
-HG_EXPORT hg_return_t
 HG_Core_addr_create(
+        hg_core_class_t *hg_core_class
-        hg_core_class_t *hg_core_class,
-        hg_core_addr_t *addr
         );
 
 /**
@@ -584,10 +578,8 @@
  *
  * \param core_addr [IN]        abstract address that not set NA address before
  * \param na_addr [IN]          abstract NA addr
- *
- * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT void
-static HG_INLINE hg_return_t
 HG_Core_addr_set_na(
         hg_core_addr_t core_addr,
         na_addr_t na_addr
@@ -600,7 +592,7 @@
  *
  * \return abstract NA addr or NA_ADDR_NULL if not a valid HG address
  */
+HG_EXPORT na_addr_t
-static HG_INLINE na_addr_t
 HG_Core_addr_get_na(
         hg_core_addr_t addr
         );
@@ -612,7 +604,7 @@
  *
  * \return Pointer to NA class or NULL if not a valid HG address
  */
+na_class_t *
-static HG_INLINE na_class_t *
 HG_Core_addr_get_na_class(
         hg_core_addr_t addr
         );
@@ -759,7 +751,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+hg_return_t
-static HG_INLINE hg_return_t
 HG_Core_set_data(
         hg_core_handle_t handle,
         void *data,
@@ -774,7 +766,7 @@
  *
  * \return Pointer to user data or NULL if not set or any error has occurred
  */
+void *
-static HG_INLINE void *
 HG_Core_get_data(
         hg_core_handle_t handle
         );
@@ -788,25 +780,12 @@
  *
  * \return Pointer to info or NULL in case of failure
  */
+HG_EXPORT const struct hg_core_info *
-static HG_INLINE const struct hg_core_info *
 HG_Core_get_info(
         hg_core_handle_t handle
         );
 
 /**
- * Allows upper layers to retrieve cached RPC data from an existing HG handle.
- * Only valid if HG_Core_register_data() has been previously called.
- *
- * \param handle [IN]           HG handle
- *
- * \return Pointer to user data or NULL if not set or any error has occurred
- */
-static HG_INLINE const void *
-HG_Core_get_rpc_data(
-        hg_core_handle_t handle
-        );
-
-/**
  * Set target context ID that will receive and process the RPC request
  * (ID is defined on target context creation, see HG_Core_context_create_id()).
  *
@@ -815,7 +794,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Core_set_target_id(
         hg_core_handle_t handle,
         hg_uint8_t id
@@ -831,7 +810,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Core_get_input(
         hg_core_handle_t handle,
         void **in_buf,
@@ -848,7 +827,7 @@
  *
  * \return HG_SUCCESS or corresponding HG error code
  */
+HG_EXPORT hg_return_t
-static HG_INLINE hg_return_t
 HG_Core_get_output(
         hg_core_handle_t handle,
         void **out_buf,
@@ -952,449 +931,6 @@
         hg_core_handle_t handle
         );
 
-/************************************/
-/* Local Type and Struct Definition */
-/************************************/
-
-/* HG core class */
-struct hg_core_class {
-    na_class_t *na_class;               /* NA class */
-#ifdef HG_HAS_SM_ROUTING
-    na_class_t *na_sm_class;            /* NA SM class */
-#endif
-    void *data;                         /* User data */
-    void (*data_free_callback)(void *); /* User data free callback */
-};
-
-/* HG core context */
-struct hg_core_context {
-    struct hg_core_class *core_class;   /* HG core class */
-    na_context_t *na_context;           /* NA context */
-#ifdef HG_HAS_SM_ROUTING
-    na_context_t *na_sm_context;        /* NA SM context */
-#endif
-    hg_uint8_t id;                      /* Context ID */
-    void *data;                         /* User data */
-    void (*data_free_callback)(void *); /* User data free callback */
-};
-
-/* HG core addr */
-struct hg_core_addr {
-    na_class_t *na_class;               /* NA class from NA address */
-    na_addr_t na_addr;                  /* NA address */
-#ifdef HG_HAS_SM_ROUTING
-    na_addr_t na_sm_addr;               /* NA SM address */
-#endif
-};
-
-/* HG core RPC registration info */
-struct hg_core_rpc_info {
-    hg_core_rpc_cb_t rpc_cb;            /* RPC callback */
-    void *data;                         /* User data */
-    void (*free_callback)(void *);      /* User data free callback */
-};
-
-/* HG core handle */
-struct hg_core_handle {
-    struct hg_core_info info;           /* HG info */
-    struct hg_core_rpc_info *rpc_info;  /* Associated RPC registration info */
-    void *in_buf;                       /* Input buffer */
-    void *out_buf;                      /* Output buffer */
-    na_size_t in_buf_size;              /* Input buffer size */
-    na_size_t out_buf_size;             /* Output buffer size */
-    na_size_t na_in_header_offset;      /* Input NA header offset */
-    na_size_t na_out_header_offset;     /* Output NA header offset */
-    void *data;                         /* User data */
-    void (*data_free_callback)(void *); /* User data free callback */
-};
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE const char *
-HG_Core_class_get_name(const hg_core_class_t *hg_core_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        return NULL;
-    }
-#endif
-    return NA_Get_class_name(hg_core_class->na_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE const char *
-HG_Core_class_get_protocol(const hg_core_class_t *hg_core_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        return NULL;
-    }
-#endif
-    return NA_Get_class_protocol(hg_core_class->na_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_bool_t
-HG_Core_class_is_listening(const hg_core_class_t *hg_core_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        return HG_FALSE;
-    }
-#endif
-    return NA_Is_listening(hg_core_class->na_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE na_class_t *
-HG_Core_class_get_na(const hg_core_class_t *hg_core_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        return NULL;
-    }
-#endif
-    return hg_core_class->na_class;
-}
-
-/*---------------------------------------------------------------------------*/
-#ifdef HG_HAS_SM_ROUTING
-static HG_INLINE na_class_t *
-HG_Core_class_get_na_sm(const hg_core_class_t *hg_core_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        return NULL;
-    }
-#endif
-    return hg_core_class->na_sm_class;
-}
-#endif
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_size_t
-HG_Core_class_get_input_eager_size(const hg_core_class_t *hg_core_class)
-{
-    hg_size_t unexp, header;
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (hg_core_class == NULL) {
-        HG_LOG_ERROR("NULL HG core class");
-        return 0;
-    }
-#endif
-    unexp  = NA_Msg_get_max_unexpected_size(hg_core_class->na_class);
-    header = hg_core_header_request_get_size() +
-        NA_Msg_get_unexpected_header_size(hg_core_class->na_class);
-
-    return (unexp > header) ? unexp - header : 0;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_size_t
-HG_Core_class_get_output_eager_size(const hg_core_class_t *hg_core_class)
-{
-    hg_size_t exp, header;
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (hg_core_class == NULL) {
-        HG_LOG_ERROR("NULL HG core class");
-        return 0;
-    }
-#endif
-    exp    = NA_Msg_get_max_expected_size(hg_core_class->na_class);
-    header = hg_core_header_response_get_size() +
-        NA_Msg_get_expected_header_size(hg_core_class->na_class);
-
-    return (exp > header) ? exp - header : 0;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Core_class_set_data(hg_core_class_t *hg_core_class, void *data,
-    void (*free_callback)(void *))
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    hg_core_class->data = data;
-    hg_core_class->data_free_callback = free_callback;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE void *
-HG_Core_class_get_data(const hg_core_class_t *hg_core_class)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!hg_core_class) {
-        HG_LOG_ERROR("NULL HG core class");
-        return NULL;
-    }
-#endif
-    return hg_core_class->data;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_core_class_t *
-HG_Core_context_get_class(const hg_core_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG core context");
-        return NULL;
-    }
-#endif
-    return context->core_class;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE na_context_t *
-HG_Core_context_get_na(const hg_core_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG core context");
-        return NULL;
-    }
-#endif
-    return context->na_context;
-}
-
-/*---------------------------------------------------------------------------*/
-#ifdef HG_HAS_SM_ROUTING
-static HG_INLINE na_context_t *
-HG_Core_context_get_na_sm(const hg_core_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG core context");
-        return NULL;
-    }
-#endif
-    return context->na_sm_context;
-}
-#endif
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_uint8_t
-HG_Core_context_get_id(const hg_core_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG core context");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    return context->id;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Core_context_set_data(hg_core_context_t *context, void *data,
-    void (*free_callback)(void *))
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG core context");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    context->data = data;
-    context->data_free_callback = free_callback;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE void *
-HG_Core_context_get_data(const hg_core_context_t *context)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!context) {
-        HG_LOG_ERROR("NULL HG core context");
-        return NULL;
-    }
-#endif
-    return context->data;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Core_addr_set_na(hg_core_addr_t core_addr, na_addr_t na_addr)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (core_addr == HG_CORE_ADDR_NULL) {
-        HG_LOG_ERROR("NULL HG core address");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    core_addr->na_addr = na_addr;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE na_addr_t
-HG_Core_addr_get_na(hg_core_addr_t addr)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (addr == HG_CORE_ADDR_NULL) {
-        HG_LOG_ERROR("NULL addr");
-        return NA_ADDR_NULL;
-    }
-#endif
-    return addr->na_addr;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE na_class_t *
-HG_Core_addr_get_na_class(hg_core_addr_t addr)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (addr == HG_CORE_ADDR_NULL) {
-        HG_LOG_ERROR("NULL addr");
-        return NULL;
-    }
-#endif
-    return addr->na_class;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Core_set_data(hg_core_handle_t handle, void *data,
-    void (*free_callback)(void *))
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL pointer to HG core handle");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    handle->data = data;
-    handle->data_free_callback = free_callback;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE void *
-HG_Core_get_data(hg_core_handle_t handle)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL pointer to HG core handle");
-        return NULL;
-    }
-#endif
-    return handle->data;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE const struct hg_core_info *
-HG_Core_get_info(hg_core_handle_t handle)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL pointer to HG core handle");
-        return NULL;
-    }
-#endif
-    return &handle->info;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE const void *
-HG_Core_get_rpc_data(hg_core_handle_t handle)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL pointer to HG core handle");
-        return NULL;
-    }
-#endif
-    return (handle->rpc_info) ? handle->rpc_info->data : NULL;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Core_set_target_id(hg_core_handle_t handle, hg_uint8_t id)
-{
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL HG core handle");
-        return HG_INVALID_PARAM;
-    }
-#endif
-    handle->info.context_id = id;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_INLINE hg_return_t
-HG_Core_get_input(hg_core_handle_t handle, void **in_buf,
-    hg_size_t *in_buf_size)
-{
-    hg_size_t header_offset;
-
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL handle");
-        return HG_INVALID_PARAM;
-    }
-
-    if (!in_buf || !in_buf_size) {
-        HG_LOG_ERROR("NULL pointer");
-        return HG_INVALID_PARAM;
-    }
-#endif
-
-    header_offset = hg_core_header_request_get_size() +
-        handle->na_in_header_offset;
-
-    /* Space must be left for request header */
-    *in_buf = (char *) handle->in_buf + header_offset;
-    *in_buf_size = handle->in_buf_size - header_offset;
-
-    return HG_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-hg_return_t
-HG_Core_get_output(hg_core_handle_t handle, void **out_buf,
-    hg_size_t *out_buf_size)
-{
-    hg_size_t header_offset;
-
-#ifdef HG_HAS_VERBOSE_ERROR
-    if (!handle) {
-        HG_LOG_ERROR("NULL handle");
-        return HG_INVALID_PARAM;
-    }
-
-    if (!out_buf || !out_buf_size) {
-        HG_LOG_ERROR("NULL pointer");
-        return HG_INVALID_PARAM;
-    }
-#endif
-
-    header_offset = hg_core_header_response_get_size() +
-        handle->na_out_header_offset;
-
-    /* Space must be left for response header */
-    *out_buf = (char *) handle->out_buf + header_offset;
-    *out_buf_size = handle->out_buf_size - header_offset;
-
-    return HG_SUCCESS;
-}
-
 #ifdef __cplusplus
 }
 #endif
--- b/src/mercury_core_header.c
+++ a/src/mercury_core_header.c
@@ -12,10 +12,6 @@
 #include "mercury_proc_buf.h"
 #include "mercury_error.h"
 
-#ifdef HG_HAS_CHECKSUMS
-# include <mchecksum.h>
-#endif
-
 #ifdef _WIN32
 # include <winsock2.h>
 #else
--- b/src/mercury_core_header.h
+++ a/src/mercury_core_header.h
@@ -13,6 +13,10 @@
 
 #include "mercury_core_types.h"
 
+#ifdef HG_HAS_CHECKSUMS
+# include <mchecksum.h>
+#endif
+
 /*************************************/
 /* Public Type and Struct Definition */
 /*************************************/
@@ -62,7 +66,7 @@
         struct hg_core_header_response response;
     } msg;
 #ifdef HG_HAS_CHECKSUMS
+    mchecksum_object_t checksum;        /* Checksum of header */
-    void *checksum;        /* Checksum of header */
 #endif
 };
 
@@ -192,6 +196,7 @@
         struct hg_core_header *hg_core_header
         );
 
+
 /**
  * Process private information for sending/receiving RPC request.
  *
--- b/src/mercury_core_types.h
+++ a/src/mercury_core_types.h
@@ -12,7 +12,7 @@
 #define MERCURY_CORE_TYPES_H
 
 #include "mercury_config.h"
+#include "na.h"
-#include "na_types.h"
 
 /*************************************/
 /* Public Type and Struct Definition */
--- b/src/mercury_private.h
+++ a/src/mercury_private.h
@@ -31,7 +31,7 @@
     hg_op_type_t op_type;
     union {
         struct hg_core_op_id *hg_core_op_id;
+        struct hg_core_handle *hg_core_handle;
-        hg_core_handle_t hg_core_handle;
         struct hg_bulk_op_id *hg_bulk_op_id;
     } op_id;
     HG_QUEUE_ENTRY(hg_completion_entry) entry;
--- b/src/na/CMakeLists.txt
+++ a/src/na/CMakeLists.txt
@@ -325,10 +325,9 @@
 # Specify project header files to be installed
 #-----------------------------------------------------------------------------
 set(NA_HEADERS
-  ${CMAKE_CURRENT_BINARY_DIR}/na_config.h
   ${CMAKE_CURRENT_SOURCE_DIR}/na.h
   ${CMAKE_CURRENT_SOURCE_DIR}/na_error.h
+  ${CMAKE_CURRENT_BINARY_DIR}/na_config.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/na_types.h
 )
 
 if(NA_HAS_MPI)
--- b/src/na/na.c
+++ a/src/na/na.c
@@ -8,10 +8,16 @@
  * found at the root of the source code distribution tree.
  */
 
+#include "na_private.h"
+#include "na_error.h"
-#include "na_plugin.h"
 
+#include "mercury_queue.h"
+#include "mercury_thread_mutex.h"
+#include "mercury_thread_condition.h"
 #include "mercury_time.h"
+#include "mercury_atomic.h"
 #include "mercury_mem.h"
+#include "mercury_atomic_queue.h"
 
 #include <stdlib.h>
 #include <string.h>
@@ -41,23 +47,26 @@
 
 struct na_private_class {
     struct na_class na_class;                   /* Must remain as first field */
+    char * protocol_name;                       /* Name of protocol */
+    na_bool_t listen;                           /* Listen for connections */
+    na_progress_mode_t progress_mode;           /* NA progress mode */
 };
 
 /* Private context / do not expose private members to plugins */
 struct na_private_context {
     struct na_context context;                  /* Must remain as first field */
     na_class_t *na_class;                       /* Pointer to NA class */
+    struct hg_atomic_queue *completion_queue;   /* Default completion queue */
+    HG_QUEUE_HEAD(na_cb_completion_data) backfill_queue; /* Backfill completion queue */
+    hg_atomic_int32_t backfill_queue_count;     /* Number of entries in backfill queue */
+    hg_thread_mutex_t completion_queue_mutex;   /* Completion queue mutex */
+    hg_thread_cond_t  completion_queue_cond;    /* Completion queue cond */
+    hg_atomic_int32_t trigger_waiting;          /* Polling/waiting in trigger */
 #ifdef NA_HAS_MULTI_PROGRESS
     hg_thread_mutex_t progress_mutex;           /* Progress mutex */
     hg_thread_cond_t  progress_cond;            /* Progress cond */
     hg_atomic_int32_t progressing;              /* Progressing count */
 #endif
-    struct hg_atomic_queue *completion_queue;   /* Default completion queue */
-    hg_thread_mutex_t completion_queue_mutex;   /* Completion queue mutex */
-    hg_thread_cond_t  completion_queue_cond;    /* Completion queue cond */
-    HG_QUEUE_HEAD(na_cb_completion_data) backfill_queue; /* Backfill completion queue */
-    hg_atomic_int32_t backfill_queue_count;     /* Number of entries in backfill queue */
-    hg_atomic_int32_t trigger_waiting;          /* Polling/waiting in trigger */
 };
 
 /********************/
@@ -86,22 +95,37 @@
 /*******************/
 /* Local Variables */
 /*******************/
+#ifdef NA_HAS_SM
+extern na_class_t na_sm_class_g;
+#endif
+#ifdef NA_HAS_BMI
+extern na_class_t na_bmi_class_g;
+#endif
+#ifdef NA_HAS_MPI
+extern na_class_t na_mpi_class_g;
+#endif
+#ifdef NA_HAS_CCI
+extern na_class_t na_cci_class_g;
+#endif
+#ifdef NA_HAS_OFI
+extern na_class_t na_ofi_class_g;
+#endif
 
+static const na_class_t *na_class_table[] = {
-static const struct na_class_ops *na_class_table[] = {
 #ifdef NA_HAS_SM
+    &na_sm_class_g, /* Keep NA SM first for protocol selection */
-    &na_sm_class_ops_g, /* Keep NA SM first for protocol selection */
 #endif
 #ifdef NA_HAS_BMI
+    &na_bmi_class_g,
-    &na_bmi_class_ops_g,
 #endif
 #ifdef NA_HAS_MPI
+    &na_mpi_class_g,
-    &na_mpi_class_ops_g,
 #endif
 #ifdef NA_HAS_CCI
+    &na_cci_class_g,
-    &na_cci_class_ops_g,
 #endif
 #ifdef NA_HAS_OFI
+    &na_ofi_class_g,
-    &na_ofi_class_ops_g,
 #endif
     NULL
 };
@@ -277,7 +301,7 @@
     }
     na_info->na_init_info = na_init_info;
     if (na_init_info)
+        na_private_class->progress_mode = na_init_info->progress_mode;
-        na_private_class->na_class.progress_mode = na_init_info->progress_mode;
 
 #ifdef NA_DEBUG
     na_info_print(na_info);
@@ -344,30 +368,30 @@
         goto done;
     }
 
+    na_private_class->na_class = *na_class_table[plugin_index];
+    if (!na_private_class->na_class.initialize) {
-    na_private_class->na_class.ops = na_class_table[plugin_index];
-    if (!na_private_class->na_class.ops->initialize) {
         NA_LOG_ERROR("initialize plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
+    ret = na_private_class->na_class.initialize(&na_private_class->na_class,
+        na_info, listen);
-    ret = na_private_class->na_class.ops->initialize(
-        &na_private_class->na_class, na_info, listen);
     if (ret != NA_SUCCESS) {
         NA_LOG_ERROR("Could not initialize plugin");
         goto done;
     }
+    na_private_class->protocol_name = strdup(na_info->protocol_name);
+    if (!na_private_class->protocol_name) {
-    na_private_class->na_class.protocol_name = strdup(na_info->protocol_name);
-    if (!na_private_class->na_class.protocol_name) {
         NA_LOG_ERROR("Could not duplicate protocol name");
         ret = NA_NOMEM_ERROR;
         goto done;
     }
+    na_private_class->listen = listen;
-    na_private_class->na_class.listen = listen;
 
 done:
     if (ret != NA_SUCCESS) {
         if (na_private_class) {
+            free(na_private_class->protocol_name);
-            free(na_private_class->na_class.protocol_name);
         }
         free(na_private_class);
         na_private_class = NULL;
@@ -385,15 +409,15 @@
     na_return_t ret = NA_SUCCESS;
 
     if (!na_private_class) goto done;
+    if (!na_class->finalize) {
-    if (!na_class->ops->finalize) {
         NA_LOG_ERROR("finalize plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_private_class->na_class.finalize(&na_private_class->na_class);
-    ret = na_class->ops->finalize(&na_private_class->na_class);
 
+    free(na_private_class->protocol_name);
-    free(na_private_class->na_class.protocol_name);
     free(na_private_class);
 
 done:
@@ -417,6 +441,61 @@
 }
 
 /*---------------------------------------------------------------------------*/
+const char *
+NA_Get_class_name(const na_class_t *na_class)
+{
+    const char *ret = NULL;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+
+    ret = na_class->class_name;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+const char *
+NA_Get_class_protocol(const na_class_t *na_class)
+{
+    const char *ret = NULL;
+    const struct na_private_class *na_private_class =
+        (const struct na_private_class *) na_class;
+
+    if (!na_private_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+
+    ret = na_private_class->protocol_name;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_bool_t
+NA_Is_listening(const na_class_t *na_class)
+{
+    const struct na_private_class *na_private_class =
+        (const struct na_private_class *) na_class;
+    na_bool_t ret = NA_FALSE;
+
+    if (!na_private_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+
+    ret = na_private_class->listen;
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
 na_context_t *
 NA_Context_create(na_class_t *na_class)
 {
@@ -445,8 +524,8 @@
     }
     na_private_context->na_class = na_class;
 
+    if (na_class->context_create) {
+        ret = na_class->context_create(na_class,
-    if (na_class->ops->context_create) {
-        ret = na_class->ops->context_create(na_class,
             &na_private_context->context.plugin_context, id);
         if (ret != NA_SUCCESS) {
             goto done;
@@ -522,8 +601,8 @@
     hg_thread_cond_destroy(&na_private_context->completion_queue_cond);
 
     /* Destroy NA plugin context */
+    if (na_class->context_destroy) {
+        ret = na_class->context_destroy(na_class,
-    if (na_class->ops->context_destroy) {
-        ret = na_class->ops->context_destroy(na_class,
             na_private_context->context.plugin_context);
         if (ret != NA_SUCCESS) {
             goto done;
@@ -552,12 +631,12 @@
         NA_LOG_ERROR("NULL NA class");
         goto done;
     }
+    if (!na_class->op_create) {
-    if (!na_class->ops->op_create) {
         /* Not provided */
         goto done;
     }
 
+    ret = na_class->op_create(na_class);
-    ret = na_class->ops->op_create(na_class);
 
 done:
     return ret;
@@ -578,12 +657,12 @@
         /* Nothing to do */
         goto done;
     }
+    if (!na_class->op_destroy) {
-    if (!na_class->ops->op_destroy) {
         /* Not provided */
         goto done;
     }
 
+    ret = na_class->op_destroy(na_class, op_id);
-    ret = na_class->ops->op_destroy(na_class, op_id);
 
 done:
     return ret;
@@ -613,7 +692,7 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->addr_lookup) {
-    if (!na_class->ops->addr_lookup) {
         NA_LOG_ERROR("addr_lookup plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
@@ -634,8 +713,8 @@
     else
         short_name = name_string;
 
+    ret = na_class->addr_lookup(na_class, context, callback, arg, short_name,
+        op_id);
-    ret = na_class->ops->addr_lookup(na_class, context, callback, arg,
-        short_name, op_id);
     if (ret != NA_SUCCESS) {
         goto done;
     }
@@ -661,13 +740,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->addr_self) {
-    if (!na_class->ops->addr_self) {
         NA_LOG_ERROR("addr_self plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->addr_self(na_class, addr);
-    ret = na_class->ops->addr_self(na_class, addr);
 
 done:
     return ret;
@@ -694,13 +773,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->addr_dup) {
-    if (!na_class->ops->addr_dup) {
         NA_LOG_ERROR("addr_dup plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->addr_dup(na_class, addr, new_addr);
-    ret = na_class->ops->addr_dup(na_class, addr, new_addr);
 
 done:
     return ret;
@@ -720,13 +799,34 @@
     if (addr == NA_ADDR_NULL)
         /* Nothing to do */
         goto done;
+    if (!na_class->addr_free) {
-    if (!na_class->ops->addr_free) {
         NA_LOG_ERROR("addr_free plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->addr_free(na_class, addr);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_bool_t
+NA_Addr_is_self(na_class_t *na_class, na_addr_t addr)
+{
+    na_bool_t ret = NA_FALSE;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+    if (!na_class->addr_is_self) {
+        NA_LOG_ERROR("addr_is_self plugin callback is not defined");
+        goto done;
+    }
+
+    ret = na_class->addr_is_self(na_class, addr);
-    ret = na_class->ops->addr_free(na_class, addr);
 
 done:
     return ret;
@@ -757,7 +857,7 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->addr_to_string) {
-    if (!na_class->ops->addr_to_string) {
         NA_LOG_ERROR("addr_to_string plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
@@ -765,14 +865,14 @@
 
     /* Automatically prepend string by plugin name with class delimiter,
      * except for MPI plugin (special case, because of generated string) */
+    if (strcmp(na_class->class_name, "mpi") == 0) {
-    if (strcmp(na_class->ops->class_name, "mpi") == 0) {
         buf_size_used = 0;
         plugin_buf_size = *buf_size;
     } else {
+        buf_size_used = strlen(na_class->class_name) + 1;
-        buf_size_used = strlen(na_class->ops->class_name) + 1;
         if (buf_ptr) {
             if (*buf_size > buf_size_used) {
+                strcpy(buf_ptr, na_class->class_name);
-                strcpy(buf_ptr, na_class->ops->class_name);
                 strcat(buf_ptr, NA_CLASS_DELIMITER);
                 buf_ptr += buf_size_used;
                 plugin_buf_size = *buf_size - buf_size_used;
@@ -786,8 +886,7 @@
         }
     }
 
+    ret = na_class->addr_to_string(na_class, buf_ptr, &plugin_buf_size, addr);
-    ret = na_class->ops->addr_to_string(na_class, buf_ptr, &plugin_buf_size,
-        addr);
 
     *buf_size = buf_size_used + plugin_buf_size;
 
@@ -796,6 +895,31 @@
 }
 
 /*---------------------------------------------------------------------------*/
+na_size_t
+NA_Addr_get_serialize_size(na_class_t *na_class, na_addr_t addr)
+{
+    na_size_t ret = 0;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+    if (addr == NA_ADDR_NULL) {
+        NA_LOG_ERROR("NULL addr");
+        goto done;
+    }
+    if (!na_class->addr_get_serialize_size) {
+        NA_LOG_ERROR("addr_get_serialize_size plugin callback is not defined");
+        goto done;
+    }
+
+    ret = na_class->addr_get_serialize_size(na_class, addr);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
 na_return_t
 NA_Addr_serialize(na_class_t *na_class, void *buf, na_size_t buf_size,
     na_addr_t addr)
@@ -822,13 +946,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->addr_serialize) {
-    if (!na_class->ops->addr_serialize) {
         NA_LOG_ERROR("addr_serialize plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->addr_serialize(na_class, buf, buf_size, addr);
-    ret = na_class->ops->addr_serialize(na_class, buf, buf_size, addr);
 
 done:
     return ret;
@@ -861,13 +985,112 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->addr_deserialize) {
-    if (!na_class->ops->addr_deserialize) {
         NA_LOG_ERROR("addr_deserialize plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->addr_deserialize(na_class, addr, buf, buf_size);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_size_t
+NA_Msg_get_max_unexpected_size(const na_class_t *na_class)
+{
+    na_size_t ret = 0;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+    if (!na_class->msg_get_max_unexpected_size) {
+        NA_LOG_ERROR("msg_get_max_unexpected_size plugin callback is not defined");
+        goto done;
+    }
+
+    ret = na_class->msg_get_max_unexpected_size(na_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_size_t
+NA_Msg_get_max_expected_size(const na_class_t *na_class)
+{
+    na_size_t ret = 0;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+    if (!na_class->msg_get_max_expected_size) {
+        NA_LOG_ERROR("msg_get_max_expected_size plugin callback is not defined");
+        goto done;
+    }
+
+    ret = na_class->msg_get_max_expected_size(na_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_size_t
+NA_Msg_get_unexpected_header_size(const na_class_t *na_class)
+{
+    na_size_t ret = 0;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+
+    if (na_class->msg_get_unexpected_header_size)
+        ret = na_class->msg_get_unexpected_header_size(na_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_size_t
+NA_Msg_get_expected_header_size(const na_class_t *na_class)
+{
+    na_size_t ret = 0;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+
+    if (na_class->msg_get_expected_header_size)
+        ret = na_class->msg_get_expected_header_size(na_class);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_tag_t
+NA_Msg_get_max_tag(const na_class_t *na_class)
+{
+    na_tag_t ret = 0;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+    if (!na_class->msg_get_max_tag) {
+        NA_LOG_ERROR("msg_get_max_tag plugin callback is not defined");
+        goto done;
+    }
+
+    ret = na_class->msg_get_max_tag(na_class);
-    ret = na_class->ops->addr_deserialize(na_class, addr, buf, buf_size);
 
 done:
     return ret;
@@ -892,8 +1115,8 @@
         goto done;
     }
 
+    if (na_class->msg_buf_alloc)
+        ret = na_class->msg_buf_alloc(na_class, buf_size, plugin_data);
-    if (na_class->ops->msg_buf_alloc)
-        ret = na_class->ops->msg_buf_alloc(na_class, buf_size, plugin_data);
     else {
         na_size_t page_size = (na_size_t) hg_mem_get_page_size();
 
@@ -927,8 +1150,8 @@
         goto done;
     }
 
+    if (na_class->msg_buf_free)
+        ret = na_class->msg_buf_free(na_class, buf, plugin_data);
-    if (na_class->ops->msg_buf_free)
-        ret = na_class->ops->msg_buf_free(na_class, buf, plugin_data);
     else {
         if (plugin_data != (void *)1) {
             NA_LOG_ERROR("Invalid plugin data value");
@@ -964,8 +1187,96 @@
         goto done;
     }
 
+    if (na_class->msg_init_unexpected)
+        ret = na_class->msg_init_unexpected(na_class, buf, buf_size);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_return_t
+NA_Msg_send_unexpected(na_class_t *na_class, na_context_t *context,
+    na_cb_t callback, void *arg, const void *buf, na_size_t buf_size,
+    void *plugin_data, na_addr_t dest_addr, na_uint8_t dest_id, na_tag_t tag,
+    na_op_id_t *op_id)
+{
+    na_return_t ret = NA_SUCCESS;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!context) {
+        NA_LOG_ERROR("NULL context");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf) {
+        NA_LOG_ERROR("NULL buffer");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf_size) {
+        NA_LOG_ERROR("NULL buffer size");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (dest_addr == NA_ADDR_NULL) {
+        NA_LOG_ERROR("NULL NA address");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!na_class->msg_send_unexpected) {
+        NA_LOG_ERROR("msg_send_unexpected plugin callback is not defined");
+        ret = NA_PROTOCOL_ERROR;
+        goto done;
+    }
+
+    ret = na_class->msg_send_unexpected(na_class, context, callback, arg, buf,
+        buf_size, plugin_data, dest_addr, dest_id, tag, op_id);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_return_t
+NA_Msg_recv_unexpected(na_class_t *na_class, na_context_t *context,
+    na_cb_t callback, void *arg, void *buf, na_size_t buf_size,
+    void *plugin_data, na_op_id_t *op_id)
+{
+    na_return_t ret = NA_SUCCESS;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!context) {
+        NA_LOG_ERROR("NULL context");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf) {
+        NA_LOG_ERROR("NULL buffer");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf_size) {
+        NA_LOG_ERROR("NULL buffer size");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!na_class->msg_recv_unexpected) {
+        NA_LOG_ERROR("msg_recv_unexpected plugin callback is not defined");
+        ret = NA_PROTOCOL_ERROR;
+        goto done;
+    }
+
+    ret = na_class->msg_recv_unexpected(na_class, context, callback, arg, buf,
+        buf_size, plugin_data, op_id);
-    if (na_class->ops->msg_init_unexpected)
-        ret = na_class->ops->msg_init_unexpected(na_class, buf, buf_size);
 
 done:
     return ret;
@@ -993,8 +1304,102 @@
         goto done;
     }
 
+    if (na_class->msg_init_expected)
+        ret = na_class->msg_init_expected(na_class, buf, buf_size);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_return_t
+NA_Msg_send_expected(na_class_t *na_class, na_context_t *context,
+    na_cb_t callback, void *arg, const void *buf, na_size_t buf_size,
+    void *plugin_data, na_addr_t dest_addr, na_uint8_t dest_id, na_tag_t tag,
+    na_op_id_t *op_id)
+{
+    na_return_t ret = NA_SUCCESS;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!context) {
+        NA_LOG_ERROR("NULL context");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf) {
+        NA_LOG_ERROR("NULL buffer");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf_size) {
+        NA_LOG_ERROR("NULL buffer size");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (dest_addr == NA_ADDR_NULL) {
+        NA_LOG_ERROR("NULL NA address");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!na_class->msg_send_expected) {
+        NA_LOG_ERROR("msg_send_expected plugin callback is not defined");
+        ret = NA_PROTOCOL_ERROR;
+        goto done;
+    }
+
+    ret = na_class->msg_send_expected(na_class, context, callback, arg, buf,
+        buf_size, plugin_data, dest_addr, dest_id, tag, op_id);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_return_t
+NA_Msg_recv_expected(na_class_t *na_class, na_context_t *context,
+    na_cb_t callback, void *arg, void *buf, na_size_t buf_size,
+    void *plugin_data, na_addr_t source_addr, na_uint8_t source_id,
+    na_tag_t tag, na_op_id_t *op_id)
+{
+    na_return_t ret = NA_SUCCESS;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!context) {
+        NA_LOG_ERROR("NULL context");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf) {
+        NA_LOG_ERROR("NULL buffer");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!buf_size) {
+        NA_LOG_ERROR("NULL buffer size");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (source_addr == NA_ADDR_NULL) {
+        NA_LOG_ERROR("NULL NA address");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!na_class->msg_recv_expected) {
+        NA_LOG_ERROR("msg_recv_expected plugin callback is not defined");
+        ret = NA_PROTOCOL_ERROR;
+        goto done;
+    }
+
+    ret = na_class->msg_recv_expected(na_class, context, callback, arg, buf,
+        buf_size, plugin_data, source_addr, source_id, tag, op_id);
-    if (na_class->ops->msg_init_expected)
-        ret = na_class->ops->msg_init_expected(na_class, buf, buf_size);
 
 done:
     return ret;
@@ -1022,13 +1427,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->mem_handle_create) {
-    if (!na_class->ops->mem_handle_create) {
         NA_LOG_ERROR("mem_handle_create plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->mem_handle_create(na_class, buf, buf_size, flags,
-    ret = na_class->ops->mem_handle_create(na_class, buf, buf_size, flags,
         mem_handle);
 
 done:
@@ -1058,13 +1463,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->mem_handle_create_segments) {
-    if (!na_class->ops->mem_handle_create_segments) {
         NA_LOG_ERROR("mem_handle_create_segments plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->mem_handle_create_segments(na_class, segments,
-    ret = na_class->ops->mem_handle_create_segments(na_class, segments,
         segment_count, flags, mem_handle);
 
 done:
@@ -1087,13 +1492,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->mem_handle_free) {
-    if (!na_class->ops->mem_handle_free) {
         NA_LOG_ERROR("mem_handle_free plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->mem_handle_free(na_class, mem_handle);
-    ret = na_class->ops->mem_handle_free(na_class, mem_handle);
 
 done:
     return ret;
@@ -1116,9 +1521,9 @@
         goto done;
     }
 
+    if (na_class->mem_register) {
-    if (na_class->ops->mem_register) {
         /* Optional */
+        ret = na_class->mem_register(na_class, mem_handle);
-        ret = na_class->ops->mem_register(na_class, mem_handle);
     }
 
 done:
@@ -1142,9 +1547,9 @@
         goto done;
     }
 
+    if (na_class->mem_deregister) {
-    if (na_class->ops->mem_deregister) {
         /* Optional */
+        ret = na_class->mem_deregister(na_class, mem_handle);
-        ret = na_class->ops->mem_deregister(na_class, mem_handle);
     }
 
 done:
@@ -1168,9 +1573,9 @@
         goto done;
     }
 
+    if (na_class->mem_publish) {
-    if (na_class->ops->mem_publish) {
         /* Optional */
+        ret = na_class->mem_publish(na_class, mem_handle);
-        ret = na_class->ops->mem_publish(na_class, mem_handle);
     }
 
 done:
@@ -1194,11 +1599,39 @@
         goto done;
     }
 
+    if (na_class->mem_unpublish) {
-    if (na_class->ops->mem_unpublish) {
         /* Optional */
+        ret = na_class->mem_unpublish(na_class, mem_handle);
+    }
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_size_t
+NA_Mem_handle_get_serialize_size(na_class_t *na_class,
+    na_mem_handle_t mem_handle)
+{
+    na_size_t ret = 0;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+    if (mem_handle == NA_MEM_HANDLE_NULL) {
+        NA_LOG_ERROR("NULL memory handle");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    /* mem_handle parameter is optional */
+    if (!na_class->mem_handle_get_serialize_size) {
+        NA_LOG_ERROR("mem_handle_get_serialize_size plugin callback is not defined");
+        goto done;
-        ret = na_class->ops->mem_unpublish(na_class, mem_handle);
     }
 
+    ret = na_class->mem_handle_get_serialize_size(na_class, mem_handle);
+
 done:
     return ret;
 }
@@ -1230,14 +1663,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->mem_handle_serialize) {
-    if (!na_class->ops->mem_handle_serialize) {
         NA_LOG_ERROR("mem_handle_serialize plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->mem_handle_serialize(na_class, buf, buf_size, mem_handle);
-    ret = na_class->ops->mem_handle_serialize(na_class, buf, buf_size,
-        mem_handle);
 
 done:
     return ret;
@@ -1270,14 +1702,145 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->mem_handle_deserialize) {
-    if (!na_class->ops->mem_handle_deserialize) {
         NA_LOG_ERROR("mem_handle_deserialize plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->mem_handle_deserialize(na_class, mem_handle, buf, buf_size);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_return_t
+NA_Put(na_class_t *na_class, na_context_t *context, na_cb_t callback, void *arg,
+    na_mem_handle_t local_mem_handle, na_offset_t local_offset,
+    na_mem_handle_t remote_mem_handle, na_offset_t remote_offset,
+    na_size_t data_size, na_addr_t remote_addr, na_uint8_t remote_id,
+    na_op_id_t *op_id)
+{
+    na_return_t ret = NA_SUCCESS;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!context) {
+        NA_LOG_ERROR("NULL context");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (local_mem_handle == NA_MEM_HANDLE_NULL) {
+        NA_LOG_ERROR("NULL memory handle");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (remote_mem_handle == NA_MEM_HANDLE_NULL) {
+        NA_LOG_ERROR("NULL memory handle");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!data_size) {
+        NA_LOG_ERROR("NULL data size");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (remote_addr == NA_ADDR_NULL) {
+        NA_LOG_ERROR("NULL addr");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!na_class->put) {
+        NA_LOG_ERROR("put plugin callback is not defined");
+        ret = NA_PROTOCOL_ERROR;
+        goto done;
+    }
+
+    ret = na_class->put(na_class, context, callback, arg, local_mem_handle,
+        local_offset, remote_mem_handle, remote_offset, data_size,
+        remote_addr, remote_id, op_id);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+na_return_t
+NA_Get(na_class_t *na_class, na_context_t *context, na_cb_t callback, void *arg,
+    na_mem_handle_t local_mem_handle, na_offset_t local_offset,
+    na_mem_handle_t remote_mem_handle, na_offset_t remote_offset,
+    na_size_t data_size, na_addr_t remote_addr, na_uint8_t remote_id,
+    na_op_id_t *op_id)
+{
+    na_return_t ret = NA_SUCCESS;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!context) {
+        NA_LOG_ERROR("NULL context");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (local_mem_handle == NA_MEM_HANDLE_NULL) {
+        NA_LOG_ERROR("NULL memory handle");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (remote_mem_handle == NA_MEM_HANDLE_NULL) {
+        NA_LOG_ERROR("NULL memory handle");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!data_size) {
+        NA_LOG_ERROR("NULL data size");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (remote_addr == NA_ADDR_NULL) {
+        NA_LOG_ERROR("NULL addr");
+        ret = NA_INVALID_PARAM;
+        goto done;
+    }
+    if (!na_class->get) {
+        NA_LOG_ERROR("get plugin callback is not defined");
+        ret = NA_PROTOCOL_ERROR;
+        goto done;
+    }
+
+    ret = na_class->get(na_class, context, callback, arg, local_mem_handle,
+        local_offset, remote_mem_handle, remote_offset, data_size,
+        remote_addr, remote_id, op_id);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+int
+NA_Poll_get_fd(na_class_t *na_class, na_context_t *context)
+{
+    int ret = -1;
+
+    if (!na_class) {
+        NA_LOG_ERROR("NULL NA class");
+        goto done;
+    }
+    if (!context) {
+        NA_LOG_ERROR("NULL context");
+        goto done;
+    }
+    if (!na_class->na_poll_get_fd) {
+        goto done;
+    }
+
+    ret = na_class->na_poll_get_fd(na_class, context);
-    ret = na_class->ops->mem_handle_deserialize(na_class, mem_handle, buf,
-        buf_size);
 
 done:
     return ret;
@@ -1287,9 +1850,11 @@
 na_bool_t
 NA_Poll_try_wait(na_class_t *na_class, na_context_t *context)
 {
+    struct na_private_class *na_private_class =
+        (struct na_private_class *) na_class;
     struct na_private_context *na_private_context =
         (struct na_private_context *) context;
+
-#ifdef NA_HAS_VERBOSE_ERROR
     if (!na_class) {
         NA_LOG_ERROR("NULL NA class");
         return NA_FALSE;
@@ -1298,9 +1863,9 @@
         NA_LOG_ERROR("NULL context");
         return NA_FALSE;
     }
+
-#endif
     /* Do not try to wait if NA_NO_BLOCK is set */
+    if (na_private_class->progress_mode == NA_NO_BLOCK)
-    if (na_class->progress_mode == NA_NO_BLOCK)
         return NA_FALSE;
 
     /* Something is in one of the completion queues */
@@ -1310,8 +1875,8 @@
     }
 
     /* Check plugin try wait */
+    if (na_class->na_poll_try_wait)
+        return na_class->na_poll_try_wait(na_class, context);
-    if (na_class->ops->na_poll_try_wait)
-        return na_class->ops->na_poll_try_wait(na_class, context);
 
     return NA_TRUE;
 }
@@ -1340,14 +1905,14 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->progress) {
-    if (!na_class->ops->progress) {
         NA_LOG_ERROR("progress plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Do not block if NA_NO_BLOCK option is passed */
+    if (na_private_class->progress_mode == NA_NO_BLOCK) {
-    if (na_private_class->na_class.progress_mode == NA_NO_BLOCK) {
         remaining = 0;
     } else {
         remaining = timeout / 1000.0; /* Convert timeout in ms into seconds */
@@ -1399,8 +1964,8 @@
 #endif
 
     /* Something is in one of the completion queues */
+    if (!hg_atomic_queue_is_empty(na_private_context->completion_queue) ||
+        hg_atomic_get32(&na_private_context->backfill_queue_count)) {
-    if (!hg_atomic_queue_is_empty(na_private_context->completion_queue)
-        || hg_atomic_get32(&na_private_context->backfill_queue_count)) {
         ret = NA_SUCCESS; /* Progressed */
 #ifdef NA_HAS_MULTI_PROGRESS
         goto unlock;
@@ -1410,7 +1975,7 @@
     }
 
     /* Try to make progress for remaining time */
+    ret = na_class->progress(na_class, context,
-    ret = na_class->ops->progress(na_class, context,
         (unsigned int) (remaining * 1000.0));
 
 #ifdef NA_HAS_MULTI_PROGRESS
@@ -1452,7 +2017,7 @@
 
     /* Do not block if NA_NO_BLOCK option is passed */
     na_private_class = (struct na_private_class *) na_private_context->na_class;
+    if (na_private_class->progress_mode == NA_NO_BLOCK) {
-    if (na_private_class->na_class.progress_mode == NA_NO_BLOCK) {
         timeout = 0;
         remaining = 0;
     } else {
@@ -1462,17 +2027,16 @@
     while (count < max_count) {
         struct na_cb_completion_data *completion_data = NULL;
 
+        completion_data =
+            hg_atomic_queue_pop_mc(na_private_context->completion_queue);
-        completion_data = hg_atomic_queue_pop_mc(
-            na_private_context->completion_queue);
         if (!completion_data) {
             /* Check backfill queue */
             if (hg_atomic_get32(&na_private_context->backfill_queue_count)) {
                 hg_thread_mutex_lock(
                     &na_private_context->completion_queue_mutex);
+                completion_data =
+                    HG_QUEUE_FIRST(&na_private_context->backfill_queue);
+                HG_QUEUE_POP_HEAD(&na_private_context->backfill_queue, entry);
-                completion_data = HG_QUEUE_FIRST(
-                    &na_private_context->backfill_queue);
-                HG_QUEUE_POP_HEAD(&na_private_context->backfill_queue,
-                    entry);
                 hg_atomic_decr32(&na_private_context->backfill_queue_count);
                 hg_thread_mutex_unlock(
                     &na_private_context->completion_queue_mutex);
@@ -1503,8 +2067,8 @@
                         &na_private_context->backfill_queue_count)) {
                     if (hg_thread_cond_timedwait(
                         &na_private_context->completion_queue_cond,
+                        &na_private_context->completion_queue_mutex, timeout)
+                        != HG_UTIL_SUCCESS) {
-                        &na_private_context->completion_queue_mutex,
-                        timeout) != HG_UTIL_SUCCESS) {
                         /* Timeout occurred so leave */
                         ret = NA_TIMEOUT;
                         break;
@@ -1577,13 +2141,13 @@
         ret = NA_INVALID_PARAM;
         goto done;
     }
+    if (!na_class->cancel) {
-    if (!na_class->ops->cancel) {
         NA_LOG_ERROR("cancel plugin callback is not defined");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    ret = na_class->cancel(na_class, context, op_id);
-    ret = na_class->ops->cancel(na_class, context, op_id);
 
 done:
     return ret;
--- b/src/na/na.h
+++ a/src/na/na.h
@@ -11,20 +11,116 @@
 #ifndef NA_H
 #define NA_H
 
+#include "na_config.h"
+
+#include <limits.h>
-#include "na_types.h"
-#include "na_error.h"
 
 /*************************************/
 /* Public Type and Struct Definition */
 /*************************************/
 
+typedef struct na_class na_class_t;     /* Opaque NA class */
+typedef struct na_context na_context_t; /* Opaque NA execution context */
+typedef void *na_addr_t;                /* Abstract NA address */
+typedef na_uint64_t na_size_t;          /* Size */
+typedef na_uint32_t na_tag_t;           /* Tag */
+typedef void *na_op_id_t;               /* Abstract operation id */
+
+typedef void *na_mem_handle_t;          /* Abstract memory handle */
+typedef na_uint64_t na_offset_t;        /* Offset */
+
+/* Progress mode */
+typedef enum na_progress_mode {
+    NA_DEFAULT,     /*!< blocking progress, depending on timeout value */
+    NA_NO_BLOCK     /*!< no blocking progress, independent of timeout value */
+} na_progress_mode_t;
+
+/* Init info */
+struct na_init_info {
+    na_progress_mode_t progress_mode;   /* Progress mode */
+    na_uint8_t max_contexts;            /* Max contexts */
+    const char *auth_key;               /* Authorization key */
+};
+
+/* Segment */
+struct na_segment {
+    na_ptr_t address;   /* Address of the segment */
+    na_size_t size;     /* Size of the segment in bytes */
+};
+
+/* Error return codes:
+ * Functions return 0 for success or NA_XXX_ERROR for failure */
+typedef enum na_return {
+    NA_SUCCESS,             /*!< operation succeeded */
+    NA_TIMEOUT,             /*!< reached timeout */
+    NA_INVALID_PARAM,       /*!< invalid parameter */
+    NA_SIZE_ERROR,          /*!< message size error */
+    NA_ALIGNMENT_ERROR,     /*!< alignment error */
+    NA_PERMISSION_ERROR,    /*!< read/write permission error */
+    NA_NOMEM_ERROR,         /*!< no memory error */
+    NA_PROTOCOL_ERROR,      /*!< unknown error reported from the protocol layer */
+    NA_CANCELED,            /*!< operation was canceled */
+    NA_ADDRINUSE_ERROR      /*!< address already in use */
+} na_return_t;
+
+/* Callback operation type */
+typedef enum na_cb_type {
+    NA_CB_LOOKUP,           /*!< lookup callback */
+    NA_CB_SEND_UNEXPECTED,  /*!< unexpected send callback */
+    NA_CB_RECV_UNEXPECTED,  /*!< unexpected recv callback */
+    NA_CB_SEND_EXPECTED,    /*!< expected send callback */
+    NA_CB_RECV_EXPECTED,    /*!< expected recv callback */
+    NA_CB_PUT,              /*!< put callback */
+    NA_CB_GET               /*!< get callback */
+} na_cb_type_t;
+
+/* Callback info structs */
+struct na_cb_info_lookup {
+    na_addr_t addr;
+};
+
+struct na_cb_info_recv_unexpected {
+    na_size_t actual_buf_size;
+    na_addr_t source;
+    na_tag_t  tag;
+};
+
+/* Callback info struct */
+struct na_cb_info {
+    void *arg;          /* User data */
+    na_return_t ret;    /* Return value */
+    na_cb_type_t type;  /* Callback type */
+    union {             /* Union of callback info structures */
+        struct na_cb_info_lookup lookup;
+        struct na_cb_info_recv_unexpected recv_unexpected;
+    } info;
+};
+
+/* Callback type */
+typedef int (*na_cb_t)(const struct na_cb_info *callback_info);
-/* See na_types.h */
 
 /*****************/
 /* Public Macros */
 /*****************/
 
+/* Constant values */
+#define NA_ADDR_NULL       ((na_addr_t)0)
+#define NA_OP_ID_NULL      ((na_op_id_t)0)
+#define NA_OP_ID_IGNORE    ((na_op_id_t *)1)
+#define NA_MEM_HANDLE_NULL ((na_mem_handle_t)0)
+
+/* Max timeout */
+#define NA_MAX_IDLE_TIME (3600*1000)
+
+/* Tag upper bound
+ * \remark This is not the user tag limit but only the limit imposed by the type */
+#define NA_TAG_UB UINT_MAX
+
+/* The memory attributes associated with the memory handle
+ * can be defined as read only, write only or read/write */
+#define NA_MEM_READ_ONLY   0x01
+#define NA_MEM_WRITE_ONLY  0x02
+#define NA_MEM_READWRITE   0x03
-/* See na_types.h */
 
 /*********************/
 /* Public Prototypes */
@@ -101,7 +197,7 @@
  *
  * \return Pointer to NA class name or NULL in case of failure
  */
+NA_EXPORT const char *
-static NA_INLINE const char *
 NA_Get_class_name(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -113,7 +209,7 @@
  *
  * \return Pointer to NA class protocol or NULL in case of failure
  */
+NA_EXPORT const char *
-static NA_INLINE const char *
 NA_Get_class_protocol(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -125,7 +221,7 @@
  *
  * \return NA_TRUE if listening or NA_FALSE if not
  */
+NA_EXPORT na_bool_t
-static NA_INLINE na_bool_t
 NA_Is_listening(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -285,7 +381,7 @@
  *
  * \return NA_TRUE if self or NA_FALSE if not
  */
+NA_EXPORT na_bool_t
-static NA_INLINE na_bool_t
 NA_Addr_is_self(
         na_class_t *na_class,
         na_addr_t   addr
@@ -321,7 +417,7 @@
  *
  * \return Non-negative value
  */
+NA_EXPORT na_size_t
-static NA_INLINE na_size_t
 NA_Addr_get_serialize_size(
         na_class_t  *na_class,
         na_addr_t    addr
@@ -372,7 +468,7 @@
  *
  * \return Non-negative value
  */
+NA_EXPORT na_size_t
-static NA_INLINE na_size_t
 NA_Msg_get_max_unexpected_size(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -385,7 +481,7 @@
  *
  * \return Non-negative value
  */
+NA_EXPORT na_size_t
-static NA_INLINE na_size_t
 NA_Msg_get_max_expected_size(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -398,7 +494,7 @@
  *
  * \return Non-negative value
  */
+NA_EXPORT na_size_t
-static NA_INLINE na_size_t
 NA_Msg_get_unexpected_header_size(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -411,7 +507,7 @@
  *
  * \return Non-negative value
  */
+NA_EXPORT na_size_t
-static NA_INLINE na_size_t
 NA_Msg_get_expected_header_size(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -424,7 +520,7 @@
  *
  * \return Non-negative value
  */
+NA_EXPORT na_tag_t
-static NA_INLINE na_tag_t
 NA_Msg_get_max_tag(
         const na_class_t *na_class
         ) NA_WARN_UNUSED_RESULT;
@@ -516,7 +612,7 @@
  *
  * \return NA_SUCCESS or corresponding NA error code
  */
+NA_EXPORT na_return_t
-static NA_INLINE na_return_t
 NA_Msg_send_unexpected(
         na_class_t   *na_class,
         na_context_t *context,
@@ -556,7 +652,7 @@
  *
  * \return NA_SUCCESS or corresponding NA error code
  */
+NA_EXPORT na_return_t
-static NA_INLINE na_return_t
 NA_Msg_recv_unexpected(
         na_class_t   *na_class,
         na_context_t *context,
@@ -617,7 +713,7 @@
  *
  * \return NA_SUCCESS or corresponding NA error code
  */
+NA_EXPORT na_return_t
-static NA_INLINE na_return_t
 NA_Msg_send_expected(
         na_class_t   *na_class,
         na_context_t *context,
@@ -659,7 +755,7 @@
  *
  * \return NA_SUCCESS or corresponding NA error code
  */
+NA_EXPORT na_return_t
-static NA_INLINE na_return_t
 NA_Msg_recv_expected(
         na_class_t   *na_class,
         na_context_t *context,
@@ -810,7 +906,7 @@
  *
  * \return Non-negative value
  */
+NA_EXPORT na_size_t
-static NA_INLINE na_size_t
 NA_Mem_handle_get_serialize_size(
         na_class_t      *na_class,
         na_mem_handle_t  mem_handle
@@ -885,7 +981,7 @@
  *
  * \return NA_SUCCESS or corresponding NA error code
  */
+NA_EXPORT na_return_t
-static NA_INLINE na_return_t
 NA_Put(
         na_class_t      *na_class,
         na_context_t    *context,
@@ -925,7 +1021,7 @@
  *
  * \return NA_SUCCESS or corresponding NA error code
  */
+NA_EXPORT na_return_t
-static NA_INLINE na_return_t
 NA_Get(
         na_class_t      *na_class,
         na_context_t    *context,
@@ -952,7 +1048,7 @@
  * \return Non-negative integer if supported, 0 if not implemented and negative
  * in case of error.
  */
+NA_EXPORT int
-static NA_INLINE int
 NA_Poll_get_fd(
         na_class_t      *na_class,
         na_context_t    *context
@@ -1043,766 +1139,6 @@
         na_return_t errnum
         ) NA_WARN_UNUSED_RESULT;
 
-/************************************/
-/* Local Type and Struct Definition */
-/************************************/
-
-/* NA info definition */
-struct na_info {
-    char *class_name;    /* Class name (e.g., bmi) */
-    char *protocol_name; /* Protocol (e.g., tcp, ib) */
-    char *host_name;     /* Host (may be NULL in anonymous mode) */
-    /* Additional init info (NULL if no info) */
-    const struct na_init_info *na_init_info;
-};
-
-/* NA class definition */
-struct na_class {
-    const struct na_class_ops *ops;             /* Class operations */
-    char *protocol_name;                        /* Name of protocol */
-    na_bool_t listen;                           /* Listen for connections */
-    na_progress_mode_t progress_mode;           /* NA progress mode */
-    void *plugin_class;                         /* Plugin private class */
-};
-
-/* NA context definition */
-struct na_context {
-    void *plugin_context;                       /* Plugin private context */
-};
-
-/* NA plugin callbacks */
-struct na_class_ops {
-    const char *class_name;
-    na_bool_t
-    (*check_protocol)(
-            const char *protocol_name
-            );
-    na_return_t
-    (*initialize)(
-            na_class_t *na_class,
-            const struct na_info *na_info,
-            na_bool_t listen
-            );
-    na_return_t
-    (*finalize)(
-            na_class_t *na_class
-            );
-    void
-    (*cleanup)(
-            void
-            );
-    na_return_t
-    (*context_create)(
-            na_class_t *na_class,
-            void **plugin_context,
-            na_uint8_t id
-            );
-    na_return_t
-    (*context_destroy)(
-            na_class_t *na_class,
-            void *plugin_context
-            );
-    na_op_id_t
-    (*op_create)(
-            na_class_t *na_class
-            );
-    na_return_t
-    (*op_destroy)(
-            na_class_t *na_class,
-            na_op_id_t op_id
-            );
-    na_return_t
-    (*addr_lookup)(
-            na_class_t   *na_class,
-            na_context_t *context,
-            na_cb_t       callback,
-            void         *arg,
-            const char   *name,
-            na_op_id_t   *op_id
-            );
-    na_return_t
-    (*addr_free)(
-            na_class_t *na_class,
-            na_addr_t   addr
-            );
-    na_return_t
-    (*addr_self)(
-            na_class_t *na_class,
-            na_addr_t  *addr
-            );
-    na_return_t
-    (*addr_dup)(
-            na_class_t *na_class,
-            na_addr_t   addr,
-            na_addr_t  *new_addr
-            );
-    na_bool_t
-    (*addr_is_self)(
-            na_class_t *na_class,
-            na_addr_t   addr
-            );
-    na_return_t
-    (*addr_to_string)(
-            na_class_t *na_class,
-            char       *buf,
-            na_size_t  *buf_size,
-            na_addr_t   addr
-            );
-    na_size_t
-    (*addr_get_serialize_size)(
-            na_class_t      *na_class,
-            na_addr_t        addr
-            );
-    na_return_t
-    (*addr_serialize)(
-            na_class_t      *na_class,
-            void            *buf,
-            na_size_t        buf_size,
-            na_addr_t        addr
-    );
-    na_return_t
-    (*addr_deserialize)(
-            na_class_t      *na_class,
-            na_addr_t       *addr,
-            const void      *buf,
-            na_size_t        buf_size
-    );
-    na_size_t
-    (*msg_get_max_unexpected_size)(
-            const na_class_t *na_class
-            );
-    na_size_t
-    (*msg_get_max_expected_size)(
-            const na_class_t *na_class
-            );
-    na_size_t
-    (*msg_get_unexpected_header_size)(
-            const na_class_t *na_class
-            );
-    na_size_t
-    (*msg_get_expected_header_size)(
-            const na_class_t *na_class
-            );
-    na_tag_t
-    (*msg_get_max_tag)(
-            const na_class_t *na_class
-            );
-    void *
-    (*msg_buf_alloc)(
-            na_class_t *na_class,
-            na_size_t buf_size,
-            void **plugin_data
-            );
-    na_return_t
-    (*msg_buf_free)(
-            na_class_t *na_class,
-            void *buf,
-            void *plugin_data
-            );
-    na_return_t
-    (*msg_init_unexpected)(
-            na_class_t *na_class,
-            void *buf,
-            na_size_t buf_size
-            );
-    na_return_t
-    (*msg_send_unexpected)(
-            na_class_t   *na_class,
-            na_context_t *context,
-            na_cb_t       callback,
-            void         *arg,
-            const void   *buf,
-            na_size_t     buf_size,
-            void         *plugin_data,
-            na_addr_t     dest_addr,
-            na_uint8_t    dest_id,
-            na_tag_t      tag,
-            na_op_id_t   *op_id
-            );
-    na_return_t
-    (*msg_recv_unexpected)(
-            na_class_t   *na_class,
-            na_context_t *context,
-            na_cb_t       callback,
-            void         *arg,
-            void         *buf,
-            na_size_t     buf_size,
-            void         *plugin_data,
-            na_op_id_t   *op_id
-            );
-    na_return_t
-    (*msg_init_expected)(
-            na_class_t *na_class,
-            void *buf,
-            na_size_t buf_size
-            );
-    na_return_t
-    (*msg_send_expected)(
-            na_class_t   *na_class,
-            na_context_t *context,
-            na_cb_t       callback,
-            void         *arg,
-            const void   *buf,
-            na_size_t     buf_size,
-            void         *plugin_data,
-            na_addr_t     dest_addr,
-            na_uint8_t    dest_id,
-            na_tag_t      tag,
-            na_op_id_t   *op_id
-            );
-    na_return_t
-    (*msg_recv_expected)(
-            na_class_t   *na_class,
-            na_context_t *context,
-            na_cb_t       callback,
-            void         *arg,
-            void         *buf,
-            na_size_t     buf_size,
-            void         *plugin_data,
-            na_addr_t     source_addr,
-            na_uint8_t    source_id,
-            na_tag_t      tag,
-            na_op_id_t   *op_id
-            );
-    na_return_t
-    (*mem_handle_create)(
-            na_class_t      *na_class,
-            void            *buf,
-            na_size_t        buf_size,
-            unsigned long    flags,
-            na_mem_handle_t *mem_handle
-            );
-    na_return_t
-    (*mem_handle_create_segments)(
-            na_class_t        *na_class,
-            struct na_segment *segments,
-            na_size_t          segment_count,
-            unsigned long      flags,
-            na_mem_handle_t   *mem_handle
-            );
-    na_return_t
-    (*mem_handle_free)(
-            na_class_t      *na_class,
-            na_mem_handle_t  mem_handle
-            );
-    na_return_t
-    (*mem_register)(
-            na_class_t      *na_class,
-            na_mem_handle_t  mem_handle
-            );
-    na_return_t
-    (*mem_deregister)(
-            na_class_t      *na_class,
-            na_mem_handle_t  mem_handle
-            );
-    na_return_t
-    (*mem_publish)(
-            na_class_t      *na_class,
-            na_mem_handle_t  mem_handle
-            );
-    na_return_t
-    (*mem_unpublish)(
-            na_class_t      *na_class,
-            na_mem_handle_t  mem_handle
-            );
-    na_size_t
-    (*mem_handle_get_serialize_size)(
-            na_class_t      *na_class,
-            na_mem_handle_t  mem_handle
-            );
-    na_return_t
-    (*mem_handle_serialize)(
-            na_class_t      *na_class,
-            void            *buf,
-            na_size_t        buf_size,
-            na_mem_handle_t  mem_handle
-            );
-    na_return_t
-    (*mem_handle_deserialize)(
-            na_class_t      *na_class,
-            na_mem_handle_t *mem_handle,
-            const void      *buf,
-            na_size_t        buf_size
-            );
-    na_return_t
-    (*put)(
-            na_class_t      *na_class,
-            na_context_t    *context,
-            na_cb_t          callback,
-            void            *arg,
-            na_mem_handle_t  local_mem_handle,
-            na_offset_t      local_offset,
-            na_mem_handle_t  remote_mem_handle,
-            na_offset_t      remote_offset,
-            na_size_t        length,
-            na_addr_t        remote_addr,
-            na_uint8_t       remote_id,
-            na_op_id_t      *op_id
-            );
-    na_return_t
-    (*get)(
-            na_class_t      *na_class,
-            na_context_t    *context,
-            na_cb_t          callback,
-            void            *arg,
-            na_mem_handle_t  local_mem_handle,
-            na_offset_t      local_offset,
-            na_mem_handle_t  remote_mem_handle,
-            na_offset_t      remote_offset,
-            na_size_t        length,
-            na_addr_t        remote_addr,
-            na_uint8_t       remote_id,
-            na_op_id_t      *op_id
-            );
-    int
-    (*na_poll_get_fd)(
-            na_class_t      *na_class,
-            na_context_t    *context
-            );
-    na_bool_t
-    (*na_poll_try_wait)(
-            na_class_t      *na_class,
-            na_context_t    *context
-            );
-    na_return_t
-    (*progress)(
-            na_class_t   *na_class,
-            na_context_t *context,
-            unsigned int  timeout
-            );
-    na_return_t
-    (*cancel)(
-            na_class_t   *na_class,
-            na_context_t *context,
-            na_op_id_t    op_id
-            );
-};
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE const char *
-NA_Get_class_name(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NULL;
-    }
-#endif
-    return na_class->ops->class_name;
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE const char *
-NA_Get_class_protocol(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NULL;
-    }
-#endif
-    return na_class->protocol_name;
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_bool_t
-NA_Is_listening(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_FALSE;
-    }
-#endif
-    return na_class->listen;
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_bool_t
-NA_Addr_is_self(na_class_t *na_class, na_addr_t addr)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_FALSE;
-    }
-    if (!na_class->ops->addr_is_self) {
-        NA_LOG_ERROR("addr_is_self plugin callback is not defined");
-        return NA_FALSE;
-    }
-#endif
-    return na_class->ops->addr_is_self(na_class, addr);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_size_t
-NA_Addr_get_serialize_size(na_class_t *na_class, na_addr_t addr)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return 0;
-    }
-    if (addr == NA_ADDR_NULL) {
-        NA_LOG_ERROR("NULL addr");
-        return 0;
-    }
-    if (!na_class->ops->addr_get_serialize_size) {
-        NA_LOG_ERROR("addr_get_serialize_size plugin callback is not defined");
-        return 0;
-    }
-#endif
-    return na_class->ops->addr_get_serialize_size(na_class, addr);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_size_t
-NA_Msg_get_max_unexpected_size(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return 0;
-    }
-    if (!na_class->ops->msg_get_max_unexpected_size) {
-        NA_LOG_ERROR("msg_get_max_unexpected_size plugin callback is not defined");
-        return 0;
-    }
-#endif
-    return na_class->ops->msg_get_max_unexpected_size(na_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_size_t
-NA_Msg_get_max_expected_size(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return 0;
-    }
-    if (!na_class->ops->msg_get_max_expected_size) {
-        NA_LOG_ERROR("msg_get_max_expected_size plugin callback is not defined");
-        return 0;
-    }
-#endif
-    return na_class->ops->msg_get_max_expected_size(na_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_size_t
-NA_Msg_get_unexpected_header_size(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return 0;
-    }
-#endif
-    return (na_class->ops->msg_get_unexpected_header_size) ?
-        na_class->ops->msg_get_unexpected_header_size(na_class) : 0;
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_size_t
-NA_Msg_get_expected_header_size(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return 0;
-    }
-#endif
-    return (na_class->ops->msg_get_expected_header_size) ?
-        na_class->ops->msg_get_expected_header_size(na_class) : 0;
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_tag_t
-NA_Msg_get_max_tag(const na_class_t *na_class)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return 0;
-    }
-    if (!na_class->ops->msg_get_max_tag) {
-        NA_LOG_ERROR("msg_get_max_tag plugin callback is not defined");
-        return 0;
-    }
-#endif
-    return na_class->ops->msg_get_max_tag(na_class);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_return_t
-NA_Msg_send_unexpected(na_class_t *na_class, na_context_t *context,
-    na_cb_t callback, void *arg, const void *buf, na_size_t buf_size,
-    void *plugin_data, na_addr_t dest_addr, na_uint8_t dest_id, na_tag_t tag,
-    na_op_id_t *op_id)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_INVALID_PARAM;
-    }
-    if (!context) {
-        NA_LOG_ERROR("NULL context");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf) {
-        NA_LOG_ERROR("NULL buffer");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf_size) {
-        NA_LOG_ERROR("NULL buffer size");
-        return NA_INVALID_PARAM;
-    }
-    if (dest_addr == NA_ADDR_NULL) {
-        NA_LOG_ERROR("NULL NA address");
-        return NA_INVALID_PARAM;
-    }
-    if (!na_class->ops->msg_send_unexpected) {
-        NA_LOG_ERROR("msg_send_unexpected plugin callback is not defined");
-        return NA_PROTOCOL_ERROR;
-    }
-#endif
-    return na_class->ops->msg_send_unexpected(na_class, context, callback,
-        arg, buf, buf_size, plugin_data, dest_addr, dest_id, tag, op_id);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_return_t
-NA_Msg_recv_unexpected(na_class_t *na_class, na_context_t *context,
-    na_cb_t callback, void *arg, void *buf, na_size_t buf_size,
-    void *plugin_data, na_op_id_t *op_id)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_INVALID_PARAM;
-    }
-    if (!context) {
-        NA_LOG_ERROR("NULL context");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf) {
-        NA_LOG_ERROR("NULL buffer");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf_size) {
-        NA_LOG_ERROR("NULL buffer size");
-        return NA_INVALID_PARAM;
-    }
-    if (!na_class->ops->msg_recv_unexpected) {
-        NA_LOG_ERROR("msg_recv_unexpected plugin callback is not defined");
-        return NA_PROTOCOL_ERROR;
-    }
-#endif
-    return na_class->ops->msg_recv_unexpected(na_class, context, callback,
-        arg, buf, buf_size, plugin_data, op_id);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_return_t
-NA_Msg_send_expected(na_class_t *na_class, na_context_t *context,
-    na_cb_t callback, void *arg, const void *buf, na_size_t buf_size,
-    void *plugin_data, na_addr_t dest_addr, na_uint8_t dest_id, na_tag_t tag,
-    na_op_id_t *op_id)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_INVALID_PARAM;
-    }
-    if (!context) {
-        NA_LOG_ERROR("NULL context");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf) {
-        NA_LOG_ERROR("NULL buffer");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf_size) {
-        NA_LOG_ERROR("NULL buffer size");
-        return NA_INVALID_PARAM;
-    }
-    if (dest_addr == NA_ADDR_NULL) {
-        NA_LOG_ERROR("NULL NA address");
-        return NA_INVALID_PARAM;
-    }
-    if (!na_class->ops->msg_send_expected) {
-        NA_LOG_ERROR("msg_send_expected plugin callback is not defined");
-        return NA_PROTOCOL_ERROR;
-    }
-#endif
-    return na_class->ops->msg_send_expected(na_class, context, callback,
-        arg, buf, buf_size, plugin_data, dest_addr, dest_id, tag, op_id);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_return_t
-NA_Msg_recv_expected(na_class_t *na_class, na_context_t *context,
-    na_cb_t callback, void *arg, void *buf, na_size_t buf_size,
-    void *plugin_data, na_addr_t source_addr, na_uint8_t source_id,
-    na_tag_t tag, na_op_id_t *op_id)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_INVALID_PARAM;
-    }
-    if (!context) {
-        NA_LOG_ERROR("NULL context");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf) {
-        NA_LOG_ERROR("NULL buffer");
-        return NA_INVALID_PARAM;
-    }
-    if (!buf_size) {
-        NA_LOG_ERROR("NULL buffer size");
-        return NA_INVALID_PARAM;
-    }
-    if (source_addr == NA_ADDR_NULL) {
-        NA_LOG_ERROR("NULL NA address");
-        return NA_INVALID_PARAM;
-    }
-    if (!na_class->ops->msg_recv_expected) {
-        NA_LOG_ERROR("msg_recv_expected plugin callback is not defined");
-        return NA_PROTOCOL_ERROR;
-    }
-#endif
-    return na_class->ops->msg_recv_expected(na_class, context, callback,
-        arg, buf, buf_size, plugin_data, source_addr, source_id, tag, op_id);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_size_t
-NA_Mem_handle_get_serialize_size(na_class_t *na_class,
-    na_mem_handle_t mem_handle)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return 0;
-    }
-    if (mem_handle == NA_MEM_HANDLE_NULL) {
-        NA_LOG_ERROR("NULL memory handle");
-        return 0;
-    }
-    if (!na_class->ops->mem_handle_get_serialize_size) {
-        NA_LOG_ERROR("mem_handle_get_serialize_size plugin callback is not defined");
-        return 0;
-    }
-#endif
-    return na_class->ops->mem_handle_get_serialize_size(na_class, mem_handle);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_return_t
-NA_Put(na_class_t *na_class, na_context_t *context, na_cb_t callback, void *arg,
-    na_mem_handle_t local_mem_handle, na_offset_t local_offset,
-    na_mem_handle_t remote_mem_handle, na_offset_t remote_offset,
-    na_size_t data_size, na_addr_t remote_addr, na_uint8_t remote_id,
-    na_op_id_t *op_id)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_INVALID_PARAM;
-    }
-    if (!context) {
-        NA_LOG_ERROR("NULL context");
-        return NA_INVALID_PARAM;
-    }
-    if (local_mem_handle == NA_MEM_HANDLE_NULL) {
-        NA_LOG_ERROR("NULL memory handle");
-        return NA_INVALID_PARAM;
-    }
-    if (remote_mem_handle == NA_MEM_HANDLE_NULL) {
-        NA_LOG_ERROR("NULL memory handle");
-        return NA_INVALID_PARAM;
-    }
-    if (!data_size) {
-        NA_LOG_ERROR("NULL data size");
-        return NA_INVALID_PARAM;
-    }
-    if (remote_addr == NA_ADDR_NULL) {
-        NA_LOG_ERROR("NULL addr");
-        return NA_INVALID_PARAM;
-    }
-    if (!na_class->ops->put) {
-        NA_LOG_ERROR("put plugin callback is not defined");
-        return NA_PROTOCOL_ERROR;
-    }
-#endif
-    return na_class->ops->put(na_class, context, callback, arg,
-        local_mem_handle, local_offset, remote_mem_handle, remote_offset,
-        data_size, remote_addr, remote_id, op_id);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE na_return_t
-NA_Get(na_class_t *na_class, na_context_t *context, na_cb_t callback, void *arg,
-    na_mem_handle_t local_mem_handle, na_offset_t local_offset,
-    na_mem_handle_t remote_mem_handle, na_offset_t remote_offset,
-    na_size_t data_size, na_addr_t remote_addr, na_uint8_t remote_id,
-    na_op_id_t *op_id)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return NA_INVALID_PARAM;
-    }
-    if (!context) {
-        NA_LOG_ERROR("NULL context");
-        return NA_INVALID_PARAM;
-    }
-    if (local_mem_handle == NA_MEM_HANDLE_NULL) {
-        NA_LOG_ERROR("NULL memory handle");
-        return NA_INVALID_PARAM;
-    }
-    if (remote_mem_handle == NA_MEM_HANDLE_NULL) {
-        NA_LOG_ERROR("NULL memory handle");
-        return NA_INVALID_PARAM;
-    }
-    if (!data_size) {
-        NA_LOG_ERROR("NULL data size");
-        return NA_INVALID_PARAM;
-    }
-    if (remote_addr == NA_ADDR_NULL) {
-        NA_LOG_ERROR("NULL addr");
-        return NA_INVALID_PARAM;
-    }
-    if (!na_class->ops->get) {
-        NA_LOG_ERROR("get plugin callback is not defined");
-        return NA_PROTOCOL_ERROR;
-    }
-#endif
-    return na_class->ops->get(na_class, context, callback, arg,
-        local_mem_handle, local_offset, remote_mem_handle, remote_offset,
-        data_size, remote_addr, remote_id, op_id);
-}
-
-/*---------------------------------------------------------------------------*/
-static NA_INLINE int
-NA_Poll_get_fd(na_class_t *na_class, na_context_t *context)
-{
-#ifdef NA_HAS_VERBOSE_ERROR
-    if (!na_class) {
-        NA_LOG_ERROR("NULL NA class");
-        return -1;
-    }
-    if (!context) {
-        NA_LOG_ERROR("NULL context");
-        return -1;
-    }
-#endif
-    return (na_class->ops->na_poll_get_fd) ?
-        na_class->ops->na_poll_get_fd(na_class, context) : -1;
-}
-
 #ifdef __cplusplus
 }
 #endif
--- b/src/na/na_bmi.c
+++ a/src/na/na_bmi.c
@@ -8,9 +8,13 @@
  * found at the root of the source code distribution tree.
  */
 
+#include "na_private.h"
+#include "na_error.h"
-#include "na_plugin.h"
 
+#include "mercury_queue.h"
+#include "mercury_thread_mutex.h"
 #include "mercury_time.h"
+#include "mercury_atomic.h"
 
 #include <bmi.h>
 
@@ -42,8 +46,8 @@
 #define NA_BMI_RMA_TAG (NA_BMI_RMA_REQUEST_TAG + 1)
 #define NA_BMI_MAX_RMA_TAG (NA_TAG_UB >> 1)
 
+#define NA_BMI_PRIVATE_DATA(na_class) \
+    ((struct na_bmi_private_data *)(na_class->private_data))
-#define NA_BMI_CLASS(na_class) \
-    ((struct na_bmi_class *)(na_class->plugin_class))
 
 #define NA_BMI_CANCEL_R (1 << 0)
 #define NA_BMI_CANCEL_C (1 << 1)
@@ -152,7 +156,7 @@
     HG_QUEUE_ENTRY(na_bmi_op_id) entry;
 };
 
+struct na_bmi_private_data {
-struct na_bmi_class {
     char *listen_addr;                               /* Listen addr */
     int port;                                        /* Port used */
     char *protocol_name;                             /* Protocol used for this class */
@@ -502,7 +506,8 @@
 /* Local Variables */
 /*******************/
 
+const na_class_t na_bmi_class_g = {
+        NULL,                                 /* private_data */
-NA_PLUGIN_OPS(bmi) = {
         "bmi",                                /* name */
         na_bmi_check_protocol,                /* check_protocol */
         na_bmi_initialize,                    /* initialize */
@@ -563,12 +568,12 @@
     bmi_msg_tag_t tag;
 
     /* Compare and swap tag if reached max tag */
+    if (hg_atomic_cas32(&NA_BMI_PRIVATE_DATA(na_class)->rma_tag,
-    if (hg_atomic_cas32(&NA_BMI_CLASS(na_class)->rma_tag,
             NA_BMI_MAX_RMA_TAG, NA_BMI_RMA_TAG)) {
         tag = NA_BMI_RMA_TAG;
     } else {
         /* Increment tag */
+        tag = hg_atomic_incr32(&NA_BMI_PRIVATE_DATA(na_class)->rma_tag);
-        tag = hg_atomic_incr32(&NA_BMI_CLASS(na_class)->rma_tag);
     }
 
     /* NOTE: the "step" argument is used to classify which step of an
@@ -647,17 +652,17 @@
     int port = 0;
 
     /* Allocate private data */
+    na_class->private_data = malloc(sizeof(struct na_bmi_private_data));
+    if (!na_class->private_data) {
-    na_class->plugin_class = malloc(sizeof(struct na_bmi_class));
-    if (!na_class->plugin_class) {
         NA_LOG_ERROR("Could not allocate NA private data class");
         ret = NA_NOMEM_ERROR;
         goto done;
     }
+    memset(na_class->private_data, 0, sizeof(struct na_bmi_private_data));
+    NA_BMI_PRIVATE_DATA(na_class)->protocol_name =
-    memset(na_class->plugin_class, 0, sizeof(struct na_bmi_class));
-    NA_BMI_CLASS(na_class)->protocol_name =
         strdup(na_info->protocol_name);
+    HG_QUEUE_INIT(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue);
+    HG_QUEUE_INIT(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue);
-    HG_QUEUE_INIT(&NA_BMI_CLASS(na_class)->unexpected_msg_queue);
-    HG_QUEUE_INIT(&NA_BMI_CLASS(na_class)->unexpected_op_queue);
 
     if (listen) {
         int desc_len = 0;
@@ -723,22 +728,24 @@
         ret = NA_SUCCESS;
 
     /* Keep listen_addr and port */
+    NA_BMI_PRIVATE_DATA(na_class)->listen_addr = (listen) ?
-    NA_BMI_CLASS(na_class)->listen_addr = (listen) ?
             strdup(listen_addr_p) : NULL;
+    NA_BMI_PRIVATE_DATA(na_class)->port = port;
-    NA_BMI_CLASS(na_class)->port = port;
 
     /* Initialize mutex/cond */
+    hg_thread_mutex_init(&NA_BMI_PRIVATE_DATA(na_class)->test_unexpected_mutex);
+    hg_thread_mutex_init(
+        &NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
+    hg_thread_mutex_init(
+        &NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_init(&NA_BMI_CLASS(na_class)->test_unexpected_mutex);
-    hg_thread_mutex_init(&NA_BMI_CLASS(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_init(&NA_BMI_CLASS(na_class)->unexpected_op_queue_mutex);
 
     /* Initialize atomic op */
+    hg_atomic_set32(&NA_BMI_PRIVATE_DATA(na_class)->rma_tag, NA_BMI_RMA_TAG);
-    hg_atomic_set32(&NA_BMI_CLASS(na_class)->rma_tag, NA_BMI_RMA_TAG);
 
 done:
     if (ret != NA_SUCCESS) {
+        free(NA_BMI_PRIVATE_DATA(na_class)->listen_addr);
+        free(na_class->private_data);
-        free(NA_BMI_CLASS(na_class)->listen_addr);
-        free(na_class->plugin_class);
     }
     return ret;
 }
@@ -750,18 +757,20 @@
     na_return_t ret = NA_SUCCESS;
     int bmi_ret;
 
+    if (!na_class->private_data) {
-    if (!na_class->plugin_class) {
         goto done;
     }
 
     /* Check that unexpected op queue is empty */
+    if (!HG_QUEUE_IS_EMPTY(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue)) {
-    if (!HG_QUEUE_IS_EMPTY(&NA_BMI_CLASS(na_class)->unexpected_op_queue)) {
         NA_LOG_ERROR("Unexpected op queue should be empty");
         ret = NA_PROTOCOL_ERROR;
     }
 
     /* Check that unexpected message queue is empty */
+    if (!HG_QUEUE_IS_EMPTY(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue)) {
-    if (!HG_QUEUE_IS_EMPTY(&NA_BMI_CLASS(na_class)->unexpected_msg_queue)) {
         NA_LOG_ERROR("Unexpected msg queue should be empty");
         ret = NA_PROTOCOL_ERROR;
     }
@@ -774,14 +783,16 @@
     }
 
     /* Destroy mutex/cond */
-    hg_thread_mutex_destroy(&NA_BMI_CLASS(na_class)->test_unexpected_mutex);
     hg_thread_mutex_destroy(
+            &NA_BMI_PRIVATE_DATA(na_class)->test_unexpected_mutex);
+    hg_thread_mutex_destroy(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
+    hg_thread_mutex_destroy(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-        &NA_BMI_CLASS(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_destroy(&NA_BMI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    free(NA_BMI_PRIVATE_DATA(na_class)->listen_addr);
+    free(NA_BMI_PRIVATE_DATA(na_class)->protocol_name);
+    free(na_class->private_data);
-    free(NA_BMI_CLASS(na_class)->listen_addr);
-    free(NA_BMI_CLASS(na_class)->protocol_name);
-    free(na_class->plugin_class);
 
 done:
     return ret;
@@ -1029,7 +1040,7 @@
     na_bmi_addr = (struct na_bmi_addr *) addr;
 
     if (na_bmi_addr->self) {
+        bmi_rev_addr = NA_BMI_PRIVATE_DATA(na_class)->listen_addr;
-        bmi_rev_addr = NA_BMI_CLASS(na_class)->listen_addr;
         if (!bmi_rev_addr) {
             NA_LOG_ERROR("Cannot convert addr to string if not listening");
             ret = NA_PROTOCOL_ERROR;
@@ -1043,8 +1054,8 @@
 
             /* Work around address returned in different format */
             desc_len = snprintf(full_rev_addr, NA_BMI_MAX_ADDR_NAME, "%s://%s:%d",
+                NA_BMI_PRIVATE_DATA(na_class)->protocol_name, bmi_rev_addr,
+                NA_BMI_PRIVATE_DATA(na_class)->port);
-                NA_BMI_CLASS(na_class)->protocol_name, bmi_rev_addr,
-                NA_BMI_CLASS(na_class)->port);
             if (desc_len > NA_BMI_MAX_ADDR_NAME) {
                 NA_LOG_ERROR("Exceeding max addr name");
                 ret = NA_SIZE_ERROR;
@@ -1249,12 +1260,14 @@
         goto done;
     }
 
+    hg_thread_mutex_lock(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_lock(&NA_BMI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
+    HG_QUEUE_PUSH_TAIL(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue,
-    HG_QUEUE_PUSH_TAIL(&NA_BMI_CLASS(na_class)->unexpected_msg_queue,
         unexpected_info, entry);
 
+    hg_thread_mutex_unlock(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_unlock(&NA_BMI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
 done:
     return ret;
@@ -1266,13 +1279,14 @@
 {
     struct na_bmi_unexpected_info *unexpected_info;
 
+    hg_thread_mutex_lock(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_lock(&NA_BMI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
+    unexpected_info = HG_QUEUE_FIRST(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue);
+    HG_QUEUE_POP_HEAD(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue, entry);
-    unexpected_info = HG_QUEUE_FIRST(
-        &NA_BMI_CLASS(na_class)->unexpected_msg_queue);
-    HG_QUEUE_POP_HEAD(&NA_BMI_CLASS(na_class)->unexpected_msg_queue, entry);
 
+    hg_thread_mutex_unlock(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_unlock(&NA_BMI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
     return unexpected_info;
 }
@@ -1290,12 +1304,13 @@
         goto done;
     }
 
+    hg_thread_mutex_lock(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_lock(&NA_BMI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    HG_QUEUE_PUSH_TAIL(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue,
-    HG_QUEUE_PUSH_TAIL(&NA_BMI_CLASS(na_class)->unexpected_op_queue,
         na_bmi_op_id, entry);
 
+    hg_thread_mutex_unlock(
+            &NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_unlock(&NA_BMI_CLASS(na_class)->unexpected_op_queue_mutex);
 
 done:
     return ret;
@@ -1307,12 +1322,16 @@
 {
     struct na_bmi_op_id *na_bmi_op_id;
 
+    hg_thread_mutex_lock(
+        &NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_lock(&NA_BMI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    na_bmi_op_id = HG_QUEUE_FIRST(
+        &NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue);
+    HG_QUEUE_POP_HEAD(&NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue,
+        entry);
-    na_bmi_op_id = HG_QUEUE_FIRST(&NA_BMI_CLASS(na_class)->unexpected_op_queue);
-    HG_QUEUE_POP_HEAD(&NA_BMI_CLASS(na_class)->unexpected_op_queue, entry);
 
+    hg_thread_mutex_unlock(
+        &NA_BMI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_unlock(&NA_BMI_CLASS(na_class)->unexpected_op_queue_mutex);
 
     return na_bmi_op_id;
 }
@@ -1893,13 +1912,14 @@
     int bmi_ret;
 
     /* Prevent multiple threads from calling BMI_testunexpected concurrently */
+    hg_thread_mutex_lock(&NA_BMI_PRIVATE_DATA(na_class)->test_unexpected_mutex);
-    hg_thread_mutex_lock(&NA_BMI_CLASS(na_class)->test_unexpected_mutex);
 
     /* Test unexpected message */
     bmi_ret = BMI_testunexpected(1, &outcount, &test_unexpected_info,
             (int) timeout);
 
+    hg_thread_mutex_unlock(
+            &NA_BMI_PRIVATE_DATA(na_class)->test_unexpected_mutex);
-    hg_thread_mutex_unlock(&NA_BMI_CLASS(na_class)->test_unexpected_mutex);
 
     if (bmi_ret < 0) {
         NA_LOG_ERROR("BMI_testunexpected failed");
--- b/src/na/na_cci.c
+++ a/src/na/na_cci.c
@@ -8,10 +8,14 @@
  * root of the source code distribution tree.
  */
 
+#include "na_private.h"
+#include "na_error.h"
-#include "na_plugin.h"
 
+#include "mercury_queue.h"
+#include "mercury_list.h"
+#include "mercury_thread_mutex.h"
 #include "mercury_time.h"
+#include "mercury_atomic.h"
-#include "mercury_list.h"
 
 #include <cci.h>
 
@@ -41,10 +45,10 @@
 typedef struct na_cci_addr na_cci_addr_t;
 typedef struct na_cci_op_id na_cci_op_id_t;
 typedef struct na_cci_mem_handle na_cci_mem_handle_t;
+typedef struct na_cci_private_data na_cci_private_data_t;
-typedef struct na_cci_class na_cci_class_t;
 
+#define NA_CCI_PRIVATE_DATA(na_class) \
+    ((struct na_cci_private_data *)(na_class->private_data))
-#define NA_CCI_CLASS(na_class) \
-    ((struct na_cci_class *)(na_class->plugin_class))
 
 /* na_cci_addr */
 struct na_cci_addr {
@@ -144,7 +148,7 @@
     struct na_cb_completion_data completion_data;
 };
 
+struct na_cci_private_data {
-struct na_cci_class {
     cci_endpoint_t *endpoint;
     HG_QUEUE_HEAD(na_cci_op_id) early; /* Unexpected rxs not yet posted */
     hg_thread_mutex_t test_unexpected_mutex; /* Mutex */
@@ -360,7 +364,8 @@
 /* Local Variables */
 /*******************/
 
+const na_class_t na_cci_class_g = {
+    NULL,                                   /* private_data */
-NA_PLUGIN_OPS(cci) = {
     "cci",                                  /* name */
     na_cci_check_protocol,                  /* check_protocol */
     na_cci_initialize,                      /* initialize */
@@ -618,13 +623,13 @@
         goto out;
     }
 
+    na_class->private_data = malloc(sizeof(struct na_cci_private_data));
+    if (!na_class->private_data) {
-    na_class->plugin_class = malloc(sizeof(struct na_cci_class));
-    if (!na_class->plugin_class) {
         NA_LOG_ERROR("Could not allocate NA private data class");
         ret = NA_NOMEM_ERROR;
         goto out;
     }
+    memset(na_class->private_data, 0, sizeof(struct na_cci_private_data));
-    memset(na_class->plugin_class, 0, sizeof(struct na_cci_class));
     if (na_info->na_init_info
         && na_info->na_init_info->progress_mode == NA_NO_BLOCK)
         fd_p = NULL;
@@ -640,8 +645,8 @@
         ret = NA_PROTOCOL_ERROR;
         goto out;
     }
+    NA_CCI_PRIVATE_DATA(na_class)->endpoint = endpoint;
+    NA_CCI_PRIVATE_DATA(na_class)->fd = fd;
-    NA_CCI_CLASS(na_class)->endpoint = endpoint;
-    NA_CCI_CLASS(na_class)->fd = fd;
 
     rc = cci_get_opt(endpoint, CCI_OPT_ENDPT_URI, &uri);
     if (rc) {
@@ -651,7 +656,7 @@
         goto out;
     }
 
+    NA_CCI_PRIVATE_DATA(na_class)->uri = strdup(uri);
-    NA_CCI_CLASS(na_class)->uri = strdup(uri);
     free(uri);
 
     ret = na_cci_init(na_class);
@@ -668,18 +673,18 @@
 {
     na_return_t ret = NA_SUCCESS;
 
+    HG_QUEUE_INIT(&NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue);
+    HG_QUEUE_INIT(&NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue);
+    HG_LIST_INIT(&NA_CCI_PRIVATE_DATA(na_class)->accept_conn_list);
-    HG_QUEUE_INIT(&NA_CCI_CLASS(na_class)->unexpected_msg_queue);
-    HG_QUEUE_INIT(&NA_CCI_CLASS(na_class)->unexpected_op_queue);
-    HG_LIST_INIT(&NA_CCI_CLASS(na_class)->accept_conn_list);
 
     /* Initialize mutex/cond */
+    hg_thread_mutex_init(&NA_CCI_PRIVATE_DATA(na_class)->test_unexpected_mutex);
-    hg_thread_mutex_init(&NA_CCI_CLASS(na_class)->test_unexpected_mutex);
     hg_thread_mutex_init(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-        &NA_CCI_CLASS(na_class)->unexpected_msg_queue_mutex);
     hg_thread_mutex_init(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-        &NA_CCI_CLASS(na_class)->unexpected_op_queue_mutex);
     hg_thread_mutex_init(
+        &NA_CCI_PRIVATE_DATA(na_class)->accept_conn_list_mutex);
-        &NA_CCI_CLASS(na_class)->accept_conn_list_mutex);
 
     if (ret != NA_SUCCESS) {
         na_cci_finalize(na_class);
@@ -691,7 +696,7 @@
 static na_return_t
 na_cci_finalize(na_class_t * na_class)
 {
+    na_cci_private_data_t *priv = na_class->private_data;
-    na_cci_class_t *priv = na_class->plugin_class;
     na_return_t ret = NA_SUCCESS;
     int rc;
 
@@ -736,7 +741,7 @@
     hg_thread_mutex_destroy(&priv->unexpected_op_queue_mutex);
     hg_thread_mutex_destroy(&priv->accept_conn_list_mutex);
 
+    free(na_class->private_data);
-    free(na_class->plugin_class);
 
     return ret;
 }
@@ -778,8 +783,8 @@
 na_cci_addr_lookup(na_class_t * na_class, na_context_t * context,
     na_cb_t callback, void *arg, const char *name, na_op_id_t * op_id)
 {
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
+    char *uri = NA_CCI_PRIVATE_DATA(na_class)->uri;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
-    char *uri = NA_CCI_CLASS(na_class)->uri;
     struct na_cci_op_id *na_cci_op_id = NULL;
     na_cci_addr_t *na_cci_addr = NULL;
     na_return_t ret = NA_SUCCESS;
@@ -863,7 +868,7 @@
         goto out;
     }
     na_cci_addr->cci_addr = 0;
+    na_cci_addr->uri = strdup(NA_CCI_PRIVATE_DATA(na_class)->uri);
-    na_cci_addr->uri = strdup(NA_CCI_CLASS(na_class)->uri);
     na_cci_addr->unexpected = NA_FALSE;
     na_cci_addr->self = NA_TRUE;
     na_cci_addr->na_cci_op_id = NULL;
@@ -1000,7 +1005,7 @@
 static na_size_t
 na_cci_msg_get_max_unexpected_size(const na_class_t *na_class)
 {
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
     cci_msg_t msg;
     na_size_t max_unexpected_size = e->device->max_send_size - sizeof(msg.size);
 
@@ -1011,7 +1016,7 @@
 static na_size_t
 na_cci_msg_get_max_expected_size(const na_class_t *na_class)
 {
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
     cci_msg_t msg;
     na_size_t max_expected_size = e->device->max_send_size - sizeof(msg.size);
 
@@ -1085,7 +1090,7 @@
     /* Post the CCI unexpected send request */
     rc = cci_sendv(na_cci_addr->cci_addr, iov, 2, na_cci_op_id, 0);
     if (rc) {
+        cci_endpoint_t *endpoint = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-        cci_endpoint_t *endpoint = NA_CCI_CLASS(na_class)->endpoint;
         NA_LOG_ERROR("cci_sendv() failed with %s", cci_strerror(endpoint, rc));
         ret = NA_PROTOCOL_ERROR;
         goto out;
@@ -1184,13 +1189,13 @@
         goto out;
     }
     hg_thread_mutex_lock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-        &NA_CCI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
+    HG_QUEUE_PUSH_TAIL(&NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue,
-    HG_QUEUE_PUSH_TAIL(&NA_CCI_CLASS(na_class)->unexpected_msg_queue,
         rx, entry);
 
     hg_thread_mutex_unlock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-        &NA_CCI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
 out:
     return ret;
@@ -1202,12 +1207,15 @@
 {
     struct na_cci_info_recv_unexpected *rx;
 
+    hg_thread_mutex_lock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_lock(&NA_CCI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
+    rx = HG_QUEUE_FIRST(&NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue);
+    HG_QUEUE_POP_HEAD(&NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue,
+        entry);
-    rx = HG_QUEUE_FIRST(&NA_CCI_CLASS(na_class)->unexpected_msg_queue);
-    HG_QUEUE_POP_HEAD(&NA_CCI_CLASS(na_class)->unexpected_msg_queue, entry);
 
+    hg_thread_mutex_unlock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_msg_queue_mutex);
-    hg_thread_mutex_unlock(&NA_CCI_CLASS(na_class)->unexpected_msg_queue_mutex);
 
     return rx;
 }
@@ -1224,12 +1232,14 @@
         ret = NA_INVALID_PARAM;
         goto out;
     }
+    hg_thread_mutex_lock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_lock(&NA_CCI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    HG_QUEUE_PUSH_TAIL(&NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue,
-    HG_QUEUE_PUSH_TAIL(&NA_CCI_CLASS(na_class)->unexpected_op_queue,
         na_cci_op_id, entry);
 
+    hg_thread_mutex_unlock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_unlock(&NA_CCI_CLASS(na_class)->unexpected_op_queue_mutex);
 
 out:
     return ret;
@@ -1241,12 +1251,16 @@
 {
     na_cci_op_id_t *na_cci_op_id;
 
+    hg_thread_mutex_lock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_lock(&NA_CCI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    na_cci_op_id = HG_QUEUE_FIRST(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue);
+    HG_QUEUE_POP_HEAD(&NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue,
+        entry);
-    na_cci_op_id = HG_QUEUE_FIRST(&NA_CCI_CLASS(na_class)->unexpected_op_queue);
-    HG_QUEUE_POP_HEAD(&NA_CCI_CLASS(na_class)->unexpected_op_queue, entry);
 
+    hg_thread_mutex_unlock(
+        &NA_CCI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_unlock(&NA_CCI_CLASS(na_class)->unexpected_op_queue_mutex);
 
     return na_cci_op_id;
 }
@@ -1309,7 +1323,7 @@
     /* Post the CCI send request */
     rc = cci_sendv(na_cci_addr->cci_addr, iov, 2, na_cci_op_id, 0);
     if (rc) {
+        cci_endpoint_t *endpoint = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-        cci_endpoint_t *endpoint = NA_CCI_CLASS(na_class)->endpoint;
         NA_LOG_ERROR("cci_sendv() failed with %s", cci_strerror(endpoint, rc));
         ret = NA_PROTOCOL_ERROR;
         goto out;
@@ -1453,7 +1467,7 @@
 na_cci_mem_register(na_class_t *na_class, na_mem_handle_t mem_handle)
 {
     na_cci_mem_handle_t *na_cci_mem_handle = mem_handle;
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
     cci_rma_handle_t *h = NULL;
     int rc = 0, flags = 0;
     na_return_t ret = NA_SUCCESS;
@@ -1493,7 +1507,7 @@
 na_cci_mem_deregister(na_class_t *na_class, na_mem_handle_t mem_handle)
 {
     na_cci_mem_handle_t *na_cci_mem_handle = mem_handle;
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
     int rc = 0;
     na_return_t ret = NA_SUCCESS;
 
@@ -1598,7 +1612,7 @@
     na_cci_op_id_t *na_cci_op_id = NULL;
     na_return_t ret = NA_SUCCESS;
     int rc;
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
     cci_connection_t *c = na_cci_addr->cci_addr;
     cci_rma_handle_t *local = &cci_local_mem_handle->h;
     cci_rma_handle_t *remote = &cci_remote_mem_handle->h;
@@ -1676,7 +1690,7 @@
     na_cci_op_id_t *na_cci_op_id = NULL;
     na_return_t ret = NA_SUCCESS;
     int rc;
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
     cci_connection_t *c = na_cci_addr->cci_addr;
     cci_rma_handle_t *local = &cci_local_mem_handle->h;
     cci_rma_handle_t *remote = &cci_remote_mem_handle->h;
@@ -1738,7 +1752,7 @@
 static int
 na_cci_poll_get_fd(na_class_t *na_class, na_context_t NA_UNUSED *context)
 {
+    return NA_CCI_PRIVATE_DATA(na_class)->fd;
-    return NA_CCI_CLASS(na_class)->fd;
 }
 
 /*---------------------------------------------------------------------------*/
@@ -2010,11 +2024,11 @@
 
     /* Add address to accepted connection list */
     hg_thread_mutex_lock(
+        &NA_CCI_PRIVATE_DATA(na_class)->accept_conn_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_CCI_PRIVATE_DATA(na_class)->accept_conn_list,
-        &NA_CCI_CLASS(na_class)->accept_conn_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_CCI_CLASS(na_class)->accept_conn_list,
         na_cci_addr, entry);
     hg_thread_mutex_unlock(
+        &NA_CCI_PRIVATE_DATA(na_class)->accept_conn_list_mutex);
-        &NA_CCI_CLASS(na_class)->accept_conn_list_mutex);
 
     return;
 }
@@ -2026,7 +2040,7 @@
 {
     double remaining = timeout / 1000.0; /* Convert timeout in ms into seconds */
     na_return_t ret = NA_TIMEOUT;
+    cci_endpoint_t *e = NA_CCI_PRIVATE_DATA(na_class)->endpoint;
-    cci_endpoint_t *e = NA_CCI_CLASS(na_class)->endpoint;
 
     do {
         int rc;
--- b/src/na/na_config.h.in
+++ a/src/na/na_config.h.in
@@ -13,7 +13,6 @@
 #ifndef NA_CONFIG_H
 #define NA_CONFIG_H
 
-/* Import/export declarations */
 #if defined(_WIN32)
     #define NA_ABI_IMPORT __declspec(dllimport)
     #define NA_ABI_EXPORT __declspec(dllexport)
@@ -53,10 +52,8 @@
 #cmakedefine NA_HAS_MULTI_PROGRESS
 #cmakedefine NA_HAS_VERBOSE_ERROR
 
-/* Define if build shared libraries */
 #cmakedefine NA_BUILD_SHARED_LIBS
 
-/* Define export declaration */
 #ifdef NA_BUILD_SHARED_LIBS
     #ifdef na_EXPORTS
       #define NA_EXPORT NA_ABI_EXPORT
@@ -67,7 +64,6 @@
     #define NA_EXPORT
 #endif
 
-/* Standard types */
 #ifdef _WIN32
     typedef signed   __int64 na_int64_t;
     typedef signed   __int32 na_int32_t;
@@ -79,7 +75,6 @@
     typedef unsigned __int8  na_uint8_t;
 #else
     #include <stdint.h>
-    #include <stddef.h>
     typedef int64_t  na_int64_t;
     typedef int32_t  na_int32_t;
     typedef int16_t  na_int16_t;
@@ -89,26 +84,22 @@
     typedef uint16_t na_uint16_t;
     typedef uint8_t  na_uint8_t;
 #endif
+typedef na_uint64_t  na_ptr_t;
 typedef na_uint8_t   na_bool_t;
+#define NA_TRUE     1
+#define NA_FALSE    0
-typedef na_uint64_t  na_ptr_t;
 
-/* Inline declarations */
 #ifdef _WIN32
    #define NA_INLINE __inline
 #else
    #define NA_INLINE __inline__
 #endif
 
-/* Unused return values */
 #if defined(__GNUC__)
     #define NA_WARN_UNUSED_RESULT __attribute__((warn_unused_result))
 #else
     #define NA_WARN_UNUSED_RESULT
 #endif
 
-/* Return codes */
-#define NA_TRUE     1
-#define NA_FALSE    0
-
 #endif /* NA_CONFIG_H */
 
--- b/src/na/na_mpi.c
+++ a/src/na/na_mpi.c
@@ -9,10 +9,16 @@
  */
 
 #include "na_mpi.h"
+#include "na_private.h"
+#include "na_error.h"
-#include "na_plugin.h"
 
 #include "mercury_list.h"
+#include "mercury_queue.h"
+#include "mercury_thread.h"
+#include "mercury_thread_mutex.h"
+#include "mercury_thread_condition.h"
 #include "mercury_time.h"
+#include "mercury_atomic.h"
 
 #include <stdio.h>
 #include <stdlib.h>
@@ -42,8 +48,8 @@
 #define NA_MPI_RMA_TAG (NA_MPI_RMA_REQUEST_TAG + 1)
 #define NA_MPI_MAX_RMA_TAG (MPI_MAX_TAG >> 1)
 
+#define NA_MPI_PRIVATE_DATA(na_class) \
+    ((struct na_mpi_private_data *)(na_class->private_data))
-#define NA_MPI_CLASS(na_class) \
-    ((struct na_mpi_class *)(na_class->plugin_class))
 
 #ifdef _WIN32
 #  define strtok_r strtok_s
@@ -156,7 +162,7 @@
     struct na_cb_completion_data completion_data;
 };
 
+struct na_mpi_private_data {
-struct na_mpi_class {
     na_bool_t listening;                    /* Used in server mode */
     na_bool_t mpi_ext_initialized;          /* MPI externally initialized */
     na_bool_t use_static_inter_comm;         /* Use static inter-communicator */
@@ -531,7 +537,8 @@
 /* Local Variables */
 /*******************/
 
+const na_class_t na_mpi_class_g = {
+        NULL,                                 /* private_data */
-NA_PLUGIN_OPS(mpi) = {
         "mpi",                                /* name */
         na_mpi_check_protocol,                /* check_protocol */
         na_mpi_initialize,                    /* initialize */
@@ -618,10 +625,10 @@
     int mpi_ret;
     na_return_t ret = NA_SUCCESS;
 
+    memset(NA_MPI_PRIVATE_DATA(na_class)->port_name, '\0', MPI_MAX_PORT_NAME);
-    memset(NA_MPI_CLASS(na_class)->port_name, '\0', MPI_MAX_PORT_NAME);
     memset(mpi_port_name, '\0', MPI_MAX_PORT_NAME);
 
+    MPI_Comm_rank(NA_MPI_PRIVATE_DATA(na_class)->intra_comm, &my_rank);
-    MPI_Comm_rank(NA_MPI_CLASS(na_class)->intra_comm, &my_rank);
     if (my_rank == 0) {
         mpi_ret = MPI_Open_port(MPI_INFO_NULL, mpi_port_name);
         if (mpi_ret != MPI_SUCCESS) {
@@ -631,14 +638,14 @@
         }
     }
     mpi_ret = MPI_Bcast(mpi_port_name, MPI_MAX_PORT_NAME, MPI_BYTE, 0,
+            NA_MPI_PRIVATE_DATA(na_class)->intra_comm);
-            NA_MPI_CLASS(na_class)->intra_comm);
     if (mpi_ret != MPI_SUCCESS) {
         NA_LOG_ERROR("MPI_Bcast() failed");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
+    strcpy(NA_MPI_PRIVATE_DATA(na_class)->port_name, mpi_port_name);
-    strcpy(NA_MPI_CLASS(na_class)->port_name, mpi_port_name);
 
 done:
     return ret;
@@ -696,15 +703,15 @@
     na_return_t ret = NA_SUCCESS;
     int mpi_ret;
 
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->accept_mutex);
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->accept_mutex);
 
+    if (NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm) {
-    if (NA_MPI_CLASS(na_class)->use_static_inter_comm) {
         int global_size, intra_size;
 
         MPI_Comm_size(MPI_COMM_WORLD, &global_size);
+        MPI_Comm_size(NA_MPI_PRIVATE_DATA(na_class)->intra_comm, &intra_size);
-        MPI_Comm_size(NA_MPI_CLASS(na_class)->intra_comm, &intra_size);
         mpi_ret = MPI_Intercomm_create(
+                NA_MPI_PRIVATE_DATA(na_class)->intra_comm, 0, MPI_COMM_WORLD,
-                NA_MPI_CLASS(na_class)->intra_comm, 0, MPI_COMM_WORLD,
                 global_size - (global_size - intra_size), 0, &new_comm);
         if (mpi_ret != MPI_SUCCESS) {
             NA_LOG_ERROR("MPI_Intercomm_create failed");
@@ -712,8 +719,8 @@
             goto done;
         }
     } else {
+        mpi_ret = MPI_Comm_accept(NA_MPI_PRIVATE_DATA(na_class)->port_name,
+                MPI_INFO_NULL, 0, NA_MPI_PRIVATE_DATA(na_class)->intra_comm,
-        mpi_ret = MPI_Comm_accept(NA_MPI_CLASS(na_class)->port_name,
-                MPI_INFO_NULL, 0, NA_MPI_CLASS(na_class)->intra_comm,
                 &new_comm);
         if (mpi_ret != MPI_SUCCESS) {
             NA_LOG_ERROR("MPI_Comm_accept failed");
@@ -731,10 +738,10 @@
         goto done;
     }
 
+    NA_MPI_PRIVATE_DATA(na_class)->accepting = NA_FALSE;
+    hg_thread_cond_signal(&NA_MPI_PRIVATE_DATA(na_class)->accept_cond);
-    NA_MPI_CLASS(na_class)->accepting = NA_FALSE;
-    hg_thread_cond_signal(&NA_MPI_CLASS(na_class)->accept_cond);
 
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->accept_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->accept_mutex);
 
     na_mpi_addr = (struct na_mpi_addr *) malloc(sizeof(struct na_mpi_addr));
     if (!na_mpi_addr) {
@@ -747,14 +754,14 @@
     na_mpi_addr->rank = MPI_ANY_SOURCE;
     na_mpi_addr->unexpected = NA_FALSE;
     na_mpi_addr->dynamic = (na_bool_t)
+            (!NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm);
-            (!NA_MPI_CLASS(na_class)->use_static_inter_comm);
     memset(na_mpi_addr->port_name, '\0', MPI_MAX_PORT_NAME);
 
     /* Add comms to list of connected remotes */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->remote_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->remote_list,
         na_mpi_addr, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
 
 done:
     return ret;
@@ -795,12 +802,12 @@
 {
     na_return_t ret = NA_SUCCESS;
 
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
 
     /* Process list of communicators */
+    while (!HG_LIST_IS_EMPTY(&NA_MPI_PRIVATE_DATA(na_class)->remote_list)) {
-    while (!HG_LIST_IS_EMPTY(&NA_MPI_CLASS(na_class)->remote_list)) {
         struct na_mpi_addr *na_mpi_addr =
+            HG_LIST_FIRST(&NA_MPI_PRIVATE_DATA(na_class)->remote_list);
-            HG_LIST_FIRST(&NA_MPI_CLASS(na_class)->remote_list);
         HG_LIST_REMOVE(na_mpi_addr, entry);
 
         ret = na_mpi_disconnect(na_class, na_mpi_addr);
@@ -810,7 +817,7 @@
     }
 
  done:
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
     return ret;
 }
 
@@ -821,12 +828,14 @@
 {
     na_return_t ret = NA_SUCCESS;
 
+    hg_thread_mutex_lock(
+            &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    HG_QUEUE_PUSH_TAIL(&NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue,
-    HG_QUEUE_PUSH_TAIL(&NA_MPI_CLASS(na_class)->unexpected_op_queue,
         na_mpi_op_id, entry);
 
+    hg_thread_mutex_unlock(
+            &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->unexpected_op_queue_mutex);
 
     return ret;
 }
@@ -837,12 +846,16 @@
 {
     struct na_mpi_op_id *na_mpi_op_id;
 
+    hg_thread_mutex_lock(
+            &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    na_mpi_op_id = HG_QUEUE_FIRST(
+        &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue);
+    HG_QUEUE_POP_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue,
+        entry);
-    na_mpi_op_id = HG_QUEUE_FIRST(&NA_MPI_CLASS(na_class)->unexpected_op_queue);
-    HG_QUEUE_POP_HEAD(&NA_MPI_CLASS(na_class)->unexpected_op_queue, entry);
 
+    hg_thread_mutex_unlock(
+            &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->unexpected_op_queue_mutex);
 
     return na_mpi_op_id;
 }
@@ -854,12 +867,12 @@
     na_tag_t tag;
 
     /* Compare and swap tag if reached max tag */
+    if (hg_atomic_cas32(&NA_MPI_PRIVATE_DATA(na_class)->rma_tag,
-    if (hg_atomic_cas32(&NA_MPI_CLASS(na_class)->rma_tag,
             NA_MPI_MAX_RMA_TAG, NA_MPI_RMA_TAG)) {
         tag = (na_tag_t) NA_MPI_RMA_TAG;
     } else {
         /* Increment tag */
+        tag = (na_tag_t) hg_atomic_incr32(&NA_MPI_PRIVATE_DATA(na_class)->rma_tag);
-        tag = (na_tag_t) hg_atomic_incr32(&NA_MPI_CLASS(na_class)->rma_tag);
     }
 
     return tag;
@@ -881,14 +894,14 @@
     int my_rank;
     static char port_name[MPI_MAX_PORT_NAME + 16];
 
+    MPI_Comm_rank(NA_MPI_PRIVATE_DATA(na_class)->intra_comm, &my_rank);
-    MPI_Comm_rank(NA_MPI_CLASS(na_class)->intra_comm, &my_rank);
 
     /* Append rank info to port name */
+    if (NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm)
-    if (NA_MPI_CLASS(na_class)->use_static_inter_comm)
         sprintf(port_name, "rank#%d$", my_rank);
     else
         sprintf(port_name, "%s;rank#%d$",
+            NA_MPI_PRIVATE_DATA(na_class)->port_name, my_rank);
-            NA_MPI_CLASS(na_class)->port_name, my_rank);
 
     return port_name;
 }
@@ -998,16 +1011,16 @@
     int *attr_val, attr_flag;
     na_return_t ret = NA_SUCCESS;
 
+    na_class->private_data = malloc(sizeof(struct na_mpi_private_data));
+    if (!na_class->private_data) {
-    na_class->plugin_class = malloc(sizeof(struct na_mpi_class));
-    if (!na_class->plugin_class) {
         NA_LOG_ERROR("Could not allocate NA private data class");
         ret = NA_NOMEM_ERROR;
         goto done;
     }
+    NA_MPI_PRIVATE_DATA(na_class)->accept_thread = 0;
+    HG_LIST_INIT(&NA_MPI_PRIVATE_DATA(na_class)->remote_list);
+    HG_LIST_INIT(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list);
+    HG_QUEUE_INIT(&NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue);
-    NA_MPI_CLASS(na_class)->accept_thread = 0;
-    HG_LIST_INIT(&NA_MPI_CLASS(na_class)->remote_list);
-    HG_LIST_INIT(&NA_MPI_CLASS(na_class)->op_id_list);
-    HG_QUEUE_INIT(&NA_MPI_CLASS(na_class)->unexpected_op_queue);
 
     /* Check flags */
     if (strcmp(na_info->protocol_name, "static") == 0)
@@ -1025,10 +1038,10 @@
     }
 
     listening = (na_bool_t) (flags & MPI_INIT_SERVER);
+    NA_MPI_PRIVATE_DATA(na_class)->listening = listening;
-    NA_MPI_CLASS(na_class)->listening = listening;
 
     use_static_inter_comm = (na_bool_t) (flags & MPI_INIT_STATIC);
+    NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm = use_static_inter_comm;
-    NA_MPI_CLASS(na_class)->use_static_inter_comm = use_static_inter_comm;
 
     /* Initialize MPI */
     mpi_ret = MPI_Initialized(&mpi_ext_initialized);
@@ -1037,7 +1050,7 @@
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
+    NA_MPI_PRIVATE_DATA(na_class)->mpi_ext_initialized =
-    NA_MPI_CLASS(na_class)->mpi_ext_initialized =
             (na_bool_t) mpi_ext_initialized;
 
     if (!mpi_ext_initialized) {
@@ -1071,7 +1084,7 @@
         MPI_Comm comm = (na_mpi_init_comm_g != MPI_COMM_NULL) ?
                 na_mpi_init_comm_g : MPI_COMM_WORLD;
 
+        mpi_ret = MPI_Comm_dup(comm, &NA_MPI_PRIVATE_DATA(na_class)->intra_comm);
-        mpi_ret = MPI_Comm_dup(comm, &NA_MPI_CLASS(na_class)->intra_comm);
         if (mpi_ret != MPI_SUCCESS) {
             NA_LOG_ERROR("Could not duplicate communicator");
             ret = NA_PROTOCOL_ERROR;
@@ -1087,7 +1100,7 @@
 
         /* Assume that the application did not split MPI_COMM_WORLD already */
         mpi_ret = MPI_Comm_split(MPI_COMM_WORLD, color, global_rank,
+                &NA_MPI_PRIVATE_DATA(na_class)->intra_comm);
-                &NA_MPI_CLASS(na_class)->intra_comm);
         if (mpi_ret != MPI_SUCCESS) {
             NA_LOG_ERROR("Could not split communicator");
             ret = NA_PROTOCOL_ERROR;
@@ -1096,19 +1109,19 @@
     }
 
     /* Initialize mutex/cond */
+    hg_thread_mutex_init(&NA_MPI_PRIVATE_DATA(na_class)->accept_mutex);
+    hg_thread_cond_init(&NA_MPI_PRIVATE_DATA(na_class)->accept_cond);
+    hg_thread_mutex_init(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
+    hg_thread_mutex_init(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_init(&NA_MPI_CLASS(na_class)->accept_mutex);
-    hg_thread_cond_init(&NA_MPI_CLASS(na_class)->accept_cond);
-    hg_thread_mutex_init(&NA_MPI_CLASS(na_class)->remote_list_mutex);
-    hg_thread_mutex_init(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
     hg_thread_mutex_init(
+            &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-            &NA_MPI_CLASS(na_class)->unexpected_op_queue_mutex);
 
     /* Initialize atomic op */
+    hg_atomic_set32(&NA_MPI_PRIVATE_DATA(na_class)->rma_tag, NA_MPI_RMA_TAG);
-    hg_atomic_set32(&NA_MPI_CLASS(na_class)->rma_tag, NA_MPI_RMA_TAG);
 
     /* If server opens a port */
     if (listening) {
+        NA_MPI_PRIVATE_DATA(na_class)->accepting = NA_TRUE;
-        NA_MPI_CLASS(na_class)->accepting = NA_TRUE;
         if (!use_static_inter_comm && (ret = na_mpi_open_port(na_class)) != NA_SUCCESS) {
             NA_LOG_ERROR("Cannot open port");
             goto done;
@@ -1117,16 +1130,16 @@
         /* We need to create a thread here if we want to allow
          * connection / disconnection since MPI does not provide any
          * service for that and MPI_Comm_accept is blocking */
+        hg_thread_create(&NA_MPI_PRIVATE_DATA(na_class)->accept_thread,
-        hg_thread_create(&NA_MPI_CLASS(na_class)->accept_thread,
                 &na_mpi_accept_service,
                 (void *) na_class);
     } else {
+        NA_MPI_PRIVATE_DATA(na_class)->accepting = NA_FALSE;
-        NA_MPI_CLASS(na_class)->accepting = NA_FALSE;
     }
 
     /* MPI implementation typically provides a "max tag" far larger than
      * standard demands */
+    MPI_Comm_get_attr(NA_MPI_PRIVATE_DATA(na_class)->intra_comm, MPI_TAG_UB,
-    MPI_Comm_get_attr(NA_MPI_CLASS(na_class)->intra_comm, MPI_TAG_UB,
             &attr_val, &attr_flag);
     if (attr_flag) MPI_MAX_TAG = *attr_val;
 
@@ -1146,17 +1159,17 @@
     int mpi_ext_finalized = 0;
     int mpi_ret;
 
+    if (!na_class->private_data) {
-    if (!na_class->plugin_class) {
         goto done;
     }
 
+    if (NA_MPI_PRIVATE_DATA(na_class)->listening) {
-    if (NA_MPI_CLASS(na_class)->listening) {
         /* No more connection accepted after this point */
+        hg_thread_join(NA_MPI_PRIVATE_DATA(na_class)->accept_thread);
-        hg_thread_join(NA_MPI_CLASS(na_class)->accept_thread);
 
         /* If server opened a port */
+        if (!NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm) {
+            mpi_ret = MPI_Close_port(NA_MPI_PRIVATE_DATA(na_class)->port_name);
-        if (!NA_MPI_CLASS(na_class)->use_static_inter_comm) {
-            mpi_ret = MPI_Close_port(NA_MPI_CLASS(na_class)->port_name);
             if (mpi_ret != MPI_SUCCESS) {
                 NA_LOG_ERROR("Could not close port");
                 ret = NA_PROTOCOL_ERROR;
@@ -1169,13 +1182,13 @@
 
     /* Check that unexpected op queue is empty */
     if (!HG_QUEUE_IS_EMPTY(
+            &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue)) {
-            &NA_MPI_CLASS(na_class)->unexpected_op_queue)) {
         NA_LOG_ERROR("Unexpected op queue should be empty");
         ret = NA_PROTOCOL_ERROR;
     }
 
     /* Free the private dup'ed comm */
+    mpi_ret = MPI_Comm_free(&NA_MPI_PRIVATE_DATA(na_class)->intra_comm);
-    mpi_ret = MPI_Comm_free(&NA_MPI_CLASS(na_class)->intra_comm);
     if (mpi_ret != MPI_SUCCESS) {
         NA_LOG_ERROR("Could not free intra_comm");
         ret = NA_PROTOCOL_ERROR;
@@ -1190,7 +1203,7 @@
         goto done;
     }
 
+    if (!NA_MPI_PRIVATE_DATA(na_class)->mpi_ext_initialized &&
-    if (!NA_MPI_CLASS(na_class)->mpi_ext_initialized &&
             !mpi_ext_finalized) {
         mpi_ret = MPI_Finalize();
         if (mpi_ret != MPI_SUCCESS) {
@@ -1201,14 +1214,14 @@
     }
 
     /* Destroy mutex/cond */
+    hg_thread_mutex_destroy(&NA_MPI_PRIVATE_DATA(na_class)->accept_mutex);
+    hg_thread_cond_destroy(&NA_MPI_PRIVATE_DATA(na_class)->accept_cond);
+    hg_thread_mutex_destroy(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
+    hg_thread_mutex_destroy(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_destroy(&NA_MPI_CLASS(na_class)->accept_mutex);
-    hg_thread_cond_destroy(&NA_MPI_CLASS(na_class)->accept_cond);
-    hg_thread_mutex_destroy(&NA_MPI_CLASS(na_class)->remote_list_mutex);
-    hg_thread_mutex_destroy(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
     hg_thread_mutex_destroy(
+            &NA_MPI_PRIVATE_DATA(na_class)->unexpected_op_queue_mutex);
-            &NA_MPI_CLASS(na_class)->unexpected_op_queue_mutex);
 
+    free(na_class->private_data);
-    free(na_class->plugin_class);
 
  done:
     return ret;
@@ -1261,15 +1274,15 @@
 
     /* Try to connect, must prevent concurrent threads to
      * create new communicators */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->accept_mutex);
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->accept_mutex);
 
     /* TODO A listening process can only "connect" to one of his pairs ? */
+    if (NA_MPI_PRIVATE_DATA(na_class)->listening) {
+        while (NA_MPI_PRIVATE_DATA(na_class)->accepting) {
+            hg_thread_cond_wait(&NA_MPI_PRIVATE_DATA(na_class)->accept_cond,
+                    &NA_MPI_PRIVATE_DATA(na_class)->accept_mutex);
-    if (NA_MPI_CLASS(na_class)->listening) {
-        while (NA_MPI_CLASS(na_class)->accepting) {
-            hg_thread_cond_wait(&NA_MPI_CLASS(na_class)->accept_cond,
-                    &NA_MPI_CLASS(na_class)->accept_mutex);
         }
+        mpi_ret = MPI_Comm_dup(NA_MPI_PRIVATE_DATA(na_class)->intra_comm,
-        mpi_ret = MPI_Comm_dup(NA_MPI_CLASS(na_class)->intra_comm,
                 &na_mpi_addr->comm);
         if (mpi_ret != MPI_SUCCESS) {
             NA_LOG_ERROR("MPI_Comm_dup() failed");
@@ -1277,9 +1290,9 @@
             goto done;
         }
     } else {
+        if (NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm) {
-        if (NA_MPI_CLASS(na_class)->use_static_inter_comm) {
             mpi_ret = MPI_Intercomm_create(
+                    NA_MPI_PRIVATE_DATA(na_class)->intra_comm, 0,
-                    NA_MPI_CLASS(na_class)->intra_comm, 0,
                     MPI_COMM_WORLD, 0, 0, &na_mpi_addr->comm);
             if (mpi_ret != MPI_SUCCESS) {
                 NA_LOG_ERROR("MPI_Intercomm_create() failed");
@@ -1289,7 +1302,7 @@
         } else {
             na_mpi_addr->dynamic = NA_TRUE;
             mpi_ret = MPI_Comm_connect(na_mpi_addr->port_name, MPI_INFO_NULL, 0,
+                    NA_MPI_PRIVATE_DATA(na_class)->intra_comm,
-                    NA_MPI_CLASS(na_class)->intra_comm,
                     &na_mpi_addr->comm);
             if (mpi_ret != MPI_SUCCESS) {
                 NA_LOG_ERROR("MPI_Comm_connect() failed");
@@ -1308,13 +1321,13 @@
         goto done;
     }
 
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->accept_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->accept_mutex);
 
     /* Add addr to list of addresses */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->remote_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->remote_list,
         na_mpi_addr, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
 
     /* TODO MPI calls are blocking and so is na_mpi_addr_lookup,
      * i.e. we always complete here for now */
@@ -1354,9 +1367,9 @@
     na_mpi_addr->self = NA_TRUE;
     na_mpi_addr->dynamic = NA_FALSE;
     memset(na_mpi_addr->port_name, '\0', MPI_MAX_PORT_NAME);
+    if (!NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm
+            && NA_MPI_PRIVATE_DATA(na_class)->listening)
+        strcpy(na_mpi_addr->port_name, NA_MPI_PRIVATE_DATA(na_class)->port_name);
-    if (!NA_MPI_CLASS(na_class)->use_static_inter_comm
-            && NA_MPI_CLASS(na_class)->listening)
-        strcpy(na_mpi_addr->port_name, NA_MPI_CLASS(na_class)->port_name);
 
     *addr = (na_addr_t) na_mpi_addr;
 
@@ -1386,14 +1399,14 @@
         struct na_mpi_addr *var = NULL;
 
         /* Remove addr from list of addresses */
+        hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
+        HG_LIST_FOREACH(var, &NA_MPI_PRIVATE_DATA(na_class)->remote_list, entry) {
-        hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
-        HG_LIST_FOREACH(var, &NA_MPI_CLASS(na_class)->remote_list, entry) {
             if (var == na_mpi_addr) {
                 HG_LIST_REMOVE(var, entry);
                 break;
             }
         }
+        hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
-        hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
 
         /* Free addr */
         ret = na_mpi_disconnect(na_class, na_mpi_addr);
@@ -1425,7 +1438,7 @@
 
     mpi_addr = (struct na_mpi_addr *) addr;
 
+    if (NA_MPI_PRIVATE_DATA(na_class)->use_static_inter_comm) {
-    if (NA_MPI_CLASS(na_class)->use_static_inter_comm) {
         sprintf(port_name, "rank#%d$", mpi_addr->rank);
     } else {
         sprintf(port_name, "%s;rank#%d$", mpi_addr->port_name, mpi_addr->rank);
@@ -1514,10 +1527,10 @@
     }
 
     /* Append op_id to op_id list */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->op_id_list,
         na_mpi_op_id, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
 
 done:
     if (ret != NA_SUCCESS) {
@@ -1624,10 +1637,10 @@
     }
 
     /* Append op_id to op_id list assign op_id */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->op_id_list,
         na_mpi_op_id, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
 
 done:
     if (ret != NA_SUCCESS) {
@@ -1680,10 +1693,10 @@
     }
 
     /* Append op_id to op_id list */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->op_id_list,
         na_mpi_op_id, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
 
 done:
     if (ret != NA_SUCCESS) {
@@ -1903,10 +1916,10 @@
     }
 
     /* Append op_id to op_id list */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->op_id_list,
         na_mpi_op_id, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
 
 done:
     if (ret != NA_SUCCESS) {
@@ -2009,10 +2022,10 @@
     }
 
     /* Append op_id to op_id list */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->op_id_list,
         na_mpi_op_id, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
 
 done:
     if (ret != NA_SUCCESS) {
@@ -2077,9 +2090,9 @@
     int mpi_ret;
 
     /* Process list of communicators */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
 
+    HG_LIST_FOREACH(probe_addr, &NA_MPI_PRIVATE_DATA(na_class)->remote_list, entry) {
-    HG_LIST_FOREACH(probe_addr, &NA_MPI_CLASS(na_class)->remote_list, entry) {
         MPI_Status status1, status2;
         int flag = 0;
 
@@ -2124,7 +2137,7 @@
         }
     }
 
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->remote_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->remote_list_mutex);
 
 done:
     return ret;
@@ -2276,10 +2289,10 @@
     }
 
     /* Add op_id to list */
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
+    HG_LIST_INSERT_HEAD(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list,
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
-    HG_LIST_INSERT_HEAD(&NA_MPI_CLASS(na_class)->op_id_list,
         na_mpi_op_id, entry);
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
 
 done:
     if (ret != NA_SUCCESS) {
@@ -2297,9 +2310,9 @@
     struct na_mpi_op_id *na_mpi_op_id = NULL;
     na_return_t ret = NA_TIMEOUT;
 
+    hg_thread_mutex_lock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_lock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
 
+    na_mpi_op_id = HG_LIST_FIRST(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list);
-    na_mpi_op_id = HG_LIST_FIRST(&NA_MPI_CLASS(na_class)->op_id_list);
     while (na_mpi_op_id) {
         MPI_Request *request = NULL;
         na_bool_t internal = NA_FALSE; /* Only used to complete internal ops */
@@ -2415,7 +2428,7 @@
     }
 
 done:
+    hg_thread_mutex_unlock(&NA_MPI_PRIVATE_DATA(na_class)->op_id_list_mutex);
-    hg_thread_mutex_unlock(&NA_MPI_CLASS(na_class)->op_id_list_mutex);
     return ret;
 }
 
--- b/src/na/na_ofi.c
+++ a/src/na/na_ofi.c
@@ -46,13 +46,16 @@
  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+#include "na_private.h"
+#include "na_error.h"
-#include "na_plugin.h"
 
 #include "mercury_list.h"
+#include "mercury_thread_mutex.h"
 #include "mercury_thread_spin.h"
 #include "mercury_thread_rwlock.h"
 #include "mercury_hash_table.h"
 #include "mercury_time.h"
+#include "mercury_atomic.h"
 #include "mercury_mem.h"
 
 #include <rdma/fabric.h>
@@ -224,8 +227,8 @@
 #define NA_OFI_SEP_RX_CTX_BITS  (8)
 
 /* Private data access */
+#define NA_OFI_PRIVATE_DATA(na_class) \
+    ((struct na_ofi_private_data *)((na_class)->private_data))
-#define NA_OFI_CLASS(na_class) \
-    ((struct na_ofi_class *)((na_class)->plugin_class))
 #define NA_OFI_CONTEXT(na_context)    \
     ((struct na_ofi_context *)((na_context)->plugin_context))
 
@@ -404,7 +407,7 @@
 };
 
 /* Private data */
+struct na_ofi_private_data {
-struct na_ofi_class {
     struct na_ofi_domain *nop_domain; /* Point back to access domain */
     struct na_ofi_endpoint *nop_endpoint;
     na_bool_t nop_listen; /* flag of listening, true for server */
@@ -536,7 +539,7 @@
  * Open domain.
  */
 static na_return_t
+na_ofi_domain_open(struct na_ofi_private_data *priv,
-na_ofi_domain_open(struct na_ofi_class *priv,
     enum na_ofi_prov_type prov_type,
     const char *domain_name, const char *auth_key,
     struct na_ofi_domain **na_ofi_domain_p);
@@ -936,7 +939,8 @@
 /* Local Variables */
 /*******************/
 
+const na_class_t na_ofi_class_g = {
+    NULL,                                   /* private_data */
-NA_PLUGIN_OPS(ofi) = {
     "ofi",                                  /* name */
     na_ofi_check_protocol,                  /* check_protocol */
     na_ofi_initialize,                      /* initialize */
@@ -1029,7 +1033,7 @@
 static NA_INLINE na_bool_t
 na_ofi_with_sep(const na_class_t *na_class)
 {
+    struct na_ofi_endpoint *ep = NA_OFI_PRIVATE_DATA(na_class)->nop_endpoint;
-    struct na_ofi_endpoint *ep = NA_OFI_CLASS(na_class)->nop_endpoint;
 
     return ep->noe_sep;
 }
@@ -1038,7 +1042,7 @@
 static NA_INLINE na_bool_t
 na_ofi_with_msg_hdr(const na_class_t *na_class)
 {
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
 
     return (na_ofi_prov_addr_format[domain->nod_prov_type] == FI_SOCKADDR_IN);
 }
@@ -1270,7 +1274,7 @@
 na_ofi_addr_ht_lookup(na_class_t *na_class, na_uint32_t addr_format,
     const void *addr, na_size_t addrlen, fi_addr_t *fi_addr)
 {
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
     na_uint64_t addr_key;
     hg_hash_table_key_t ht_key = NULL;
     hg_hash_table_value_t ht_value = NULL;
@@ -1604,7 +1608,7 @@
 
 /*---------------------------------------------------------------------------*/
 static na_return_t
+na_ofi_domain_open(struct na_ofi_private_data *priv, 
-na_ofi_domain_open(struct na_ofi_class *priv,
     enum na_ofi_prov_type prov_type,
     const char *domain_name, const char *auth_key,
     struct na_ofi_domain **na_ofi_domain_p)
@@ -2241,7 +2245,7 @@
 static na_return_t
 na_ofi_get_ep_addr(na_class_t *na_class, struct na_ofi_addr **na_ofi_addr_ptr)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_domain *na_ofi_domain = priv->nop_domain;
     struct na_ofi_endpoint *na_ofi_endpoint = priv->nop_endpoint;
     struct na_ofi_addr *na_ofi_addr = NULL;
@@ -2306,7 +2310,7 @@
 static na_return_t
 na_ofi_get_uri(na_class_t *na_class, const void *addr, char **uri_ptr)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_domain *na_ofi_domain = priv->nop_domain;
     char addr_str[NA_OFI_MAX_URI_LEN] = {'\0'},
         fi_addr_str[NA_OFI_MAX_URI_LEN] = {'\0'},
@@ -2450,7 +2454,7 @@
 static NA_INLINE void *
 na_ofi_mem_alloc(na_class_t *na_class, na_size_t size, struct fid_mr **mr_hdl)
 {
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
     na_size_t page_size = (na_size_t) hg_mem_get_page_size();
     void *mem_ptr = NULL;
 
@@ -2510,16 +2514,16 @@
 
 retry:
     /* Check whether we can get a block from one of the pools */
+    hg_thread_spin_lock(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool_lock);
-    hg_thread_spin_lock(&NA_OFI_CLASS(na_class)->nop_buf_pool_lock);
     HG_QUEUE_FOREACH(na_ofi_mem_pool,
+        &NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool, entry) {
-        &NA_OFI_CLASS(na_class)->nop_buf_pool, entry) {
         hg_thread_spin_lock(&na_ofi_mem_pool->node_list_lock);
         found = !HG_QUEUE_IS_EMPTY(&na_ofi_mem_pool->node_list);
         hg_thread_spin_unlock(&na_ofi_mem_pool->node_list_lock);
         if (found)
             break;
     }
+    hg_thread_spin_unlock(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool_lock);
-    hg_thread_spin_unlock(&NA_OFI_CLASS(na_class)->nop_buf_pool_lock);
 
     /* If not, allocate and register a new pool */
     if (!found) {
@@ -2527,10 +2531,10 @@
             na_ofi_mem_pool_create(na_class,
                 na_ofi_msg_get_max_unexpected_size(na_class),
                 NA_OFI_MEM_BLOCK_COUNT);
+        hg_thread_spin_lock(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool_lock);
+        HG_QUEUE_PUSH_TAIL(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool,
-        hg_thread_spin_lock(&NA_OFI_CLASS(na_class)->nop_buf_pool_lock);
-        HG_QUEUE_PUSH_TAIL(&NA_OFI_CLASS(na_class)->nop_buf_pool,
             na_ofi_mem_pool, entry);
+        hg_thread_spin_unlock(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool_lock);
-        hg_thread_spin_unlock(&NA_OFI_CLASS(na_class)->nop_buf_pool_lock);
     }
 
     if (size > na_ofi_mem_pool->block_size) {
@@ -2563,9 +2567,9 @@
         container_of(mem_ptr, struct na_ofi_mem_node, block);
 
     /* Put the node back to the pool */
+    hg_thread_spin_lock(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool_lock);
-    hg_thread_spin_lock(&NA_OFI_CLASS(na_class)->nop_buf_pool_lock);
     HG_QUEUE_FOREACH(na_ofi_mem_pool,
+        &NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool, entry) {
-        &NA_OFI_CLASS(na_class)->nop_buf_pool, entry) {
         /* If MR handle is NULL, it does not really matter which pool we push
          * the node back to.
          */
@@ -2576,7 +2580,7 @@
             break;
         }
     }
+    hg_thread_spin_unlock(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool_lock);
-    hg_thread_spin_unlock(&NA_OFI_CLASS(na_class)->nop_buf_pool_lock);
 }
 
 /*---------------------------------------------------------------------------*/
@@ -2724,7 +2728,7 @@
              */
             goto out;
         case FI_EADDRNOTAVAIL: {
+            struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-            struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
             struct fid_av *av_hdl = priv->nop_domain->nod_av;
             void *err_addr = NULL;
             size_t err_addrlen;
@@ -3108,7 +3112,7 @@
 na_ofi_initialize(na_class_t *na_class, const struct na_info *na_info,
     na_bool_t listen)
 {
+    struct na_ofi_private_data *priv;
-    struct na_ofi_class *priv;
     void *src_addr = NULL;
     na_size_t src_addrlen = 0;
     char *resolve_name = NULL;
@@ -3241,15 +3245,15 @@
     }
 
     /* Create private data */
+    na_class->private_data = (struct na_ofi_private_data *) malloc(
+        sizeof(struct na_ofi_private_data));
+    if (!na_class->private_data) {
-    na_class->plugin_class = (struct na_ofi_class *) malloc(
-        sizeof(struct na_ofi_class));
-    if (!na_class->plugin_class) {
         NA_LOG_ERROR("Could not allocate NA private data class");
         ret = NA_NOMEM_ERROR;
         goto out;
     }
+    memset(na_class->private_data, 0, sizeof(struct na_ofi_private_data));
+    priv = NA_OFI_PRIVATE_DATA(na_class);
-    memset(na_class->plugin_class, 0, sizeof(struct na_ofi_class));
-    priv = NA_OFI_CLASS(na_class);
     priv->no_wait = no_wait;
     priv->nop_listen = listen;
     priv->nop_max_contexts = max_contexts;
@@ -3263,7 +3267,7 @@
     HG_QUEUE_INIT(&priv->nop_buf_pool);
 
     /* Create domain */
+    ret = na_ofi_domain_open(na_class->private_data, prov_type, domain_name,
-    ret = na_ofi_domain_open(na_class->plugin_class, prov_type, domain_name,
         auth_key, &priv->nop_domain);
     if (ret != NA_SUCCESS) {
         NA_LOG_ERROR("Could not open domain for %s, %s", na_ofi_prov_name[prov_type],
@@ -3289,9 +3293,9 @@
 out:
     if (ret != NA_SUCCESS) {
         free(src_addr);
+        if (na_class->private_data) {
-        if (na_class->plugin_class) {
             na_ofi_finalize(na_class);
+            na_class->private_data = NULL;
-            na_class->plugin_class = NULL;
         }
     }
     free(resolve_name);
@@ -3302,7 +3306,7 @@
 static na_return_t
 na_ofi_finalize(na_class_t *na_class)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     na_return_t ret = NA_SUCCESS;
 
     if (priv == NULL)
@@ -3327,7 +3331,7 @@
 
         na_ofi_mem_pool_destroy(na_ofi_mem_pool);
     }
+    hg_thread_spin_destroy(&NA_OFI_PRIVATE_DATA(na_class)->nop_buf_pool_lock);
-    hg_thread_spin_destroy(&NA_OFI_CLASS(na_class)->nop_buf_pool_lock);
 
     /* Close domain */
     if (priv->nop_domain) {
@@ -3342,7 +3346,7 @@
     /* Close mutex / free private data */
     hg_thread_mutex_destroy(&priv->nop_mutex);
     free(priv);
+    na_class->private_data = NULL;
-    na_class->plugin_class = NULL;
 
 out:
     return ret;
@@ -3352,7 +3356,7 @@
 static na_return_t
 na_ofi_context_create(na_class_t *na_class, void **context, na_uint8_t id)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_domain *domain = priv->nop_domain;
     struct na_ofi_endpoint *ep = priv->nop_endpoint;
     struct na_ofi_context *ctx = NULL;
@@ -3517,7 +3521,7 @@
 static na_return_t
 na_ofi_context_destroy(na_class_t *na_class, void *context)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_context *ctx = (struct na_ofi_context *) context;
     na_return_t ret = NA_SUCCESS;
     int rc;
@@ -3633,7 +3637,7 @@
 na_ofi_addr_lookup(na_class_t *na_class, na_context_t *context,
     na_cb_t callback, void *arg, const char *name, na_op_id_t *op_id)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_op_id *na_ofi_op_id = NULL;
     struct na_ofi_addr *na_ofi_addr = NULL;
     na_return_t ret = NA_SUCCESS;
@@ -3729,7 +3733,7 @@
 static NA_INLINE na_return_t
 na_ofi_addr_self(na_class_t *na_class, na_addr_t *addr)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_endpoint *ep = priv->nop_endpoint;
 
     na_ofi_addr_addref(ep->noe_addr); /* decref in na_ofi_addr_free() */
@@ -3837,7 +3841,7 @@
 na_ofi_addr_deserialize(na_class_t *na_class, na_addr_t *addr, const void *buf,
     na_size_t NA_UNUSED buf_size)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_addr *na_ofi_addr = NULL;
     na_return_t ret = NA_SUCCESS;
 
@@ -3886,7 +3890,7 @@
 {
     na_size_t max_unexpected_size = NA_OFI_UNEXPECTED_SIZE;
 #ifdef NA_OFI_HAS_EXT_GNI_H
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
 
     if (domain->nod_prov_type == NA_OFI_PROV_GNI) {
         struct fi_gni_ops_domain *gni_domain_ops;
@@ -3925,7 +3929,7 @@
     struct fi_ep_attr *ep_attr;
     na_size_t max_expected_size;
 
+    ep_attr = NA_OFI_PRIVATE_DATA(na_class)->nop_domain->nod_prov->ep_attr;
-    ep_attr = NA_OFI_CLASS(na_class)->nop_domain->nod_prov->ep_attr;
     max_expected_size = ep_attr->max_msg_size - ep_attr->msg_prefix_size;
 
     return max_expected_size;
@@ -4001,7 +4005,7 @@
      * the msg header to piggyback the source address for unexpected message.
      */
     if (na_ofi_with_msg_hdr(na_class)) {
+        struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-        struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
         struct na_ofi_sin_addr *na_ofi_sin_addr =
             (struct na_ofi_sin_addr *) priv->nop_endpoint->noe_addr->addr;
 
@@ -4340,7 +4344,7 @@
 na_ofi_mem_register(na_class_t *na_class, na_mem_handle_t mem_handle)
 {
     struct na_ofi_mem_handle *na_ofi_mem_handle = mem_handle;
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
     na_uint64_t access;
     int rc = 0;
     na_return_t ret = NA_SUCCESS;
@@ -4388,7 +4392,7 @@
 na_ofi_mem_deregister(na_class_t *na_class, na_mem_handle_t mem_handle)
 {
     struct na_ofi_mem_handle *na_ofi_mem_handle = mem_handle;
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
     int rc;
 
     /* nothing to do for scalable memory registration mode */
@@ -4483,7 +4487,7 @@
     na_size_t length, na_addr_t remote_addr, na_uint8_t remote_id,
     na_op_id_t *op_id)
 {
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
     struct na_ofi_context *ctx = NA_OFI_CONTEXT(context);
     struct fid_ep *ep_hdl = ctx->noc_tx;
     struct na_ofi_mem_handle *ofi_local_mem_handle =
@@ -4583,7 +4587,7 @@
     na_size_t length, na_addr_t remote_addr, na_uint8_t remote_id,
     na_op_id_t *op_id)
 {
+    struct na_ofi_domain *domain = NA_OFI_PRIVATE_DATA(na_class)->nop_domain;
-    struct na_ofi_domain *domain = NA_OFI_CLASS(na_class)->nop_domain;
     struct na_ofi_context *ctx = NA_OFI_CONTEXT(context);
     struct fid_ep *ep_hdl = ctx->noc_tx;
     struct na_ofi_mem_handle *ofi_local_mem_handle =
@@ -4665,7 +4669,7 @@
 static NA_INLINE int
 na_ofi_poll_get_fd(na_class_t *na_class, na_context_t *context)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_context *ctx = NA_OFI_CONTEXT(context);
     int fd = -1, rc;
 
@@ -4690,7 +4694,7 @@
 static NA_INLINE na_bool_t
 na_ofi_poll_try_wait(na_class_t *na_class, na_context_t *context)
 {
+    struct na_ofi_private_data *priv = NA_OFI_PRIVATE_DATA(na_class);
-    struct na_ofi_class *priv = NA_OFI_CLASS(na_class);
     struct na_ofi_context *ctx = NA_OFI_CONTEXT(context);
     struct fid *fids[1];
     int rc;
@@ -4871,7 +4875,7 @@
     }
 
     /* Work around segfault on fi_cq_signal() in some providers */
+    if (!(na_ofi_prov_flags[NA_OFI_PRIVATE_DATA(na_class)->nop_domain->nod_prov_type]
-    if (!(na_ofi_prov_flags[NA_OFI_CLASS(na_class)->nop_domain->nod_prov_type]
         & NA_OFI_SKIP_SIGNAL)) {
         /* signal the cq to make the wait FD can work */
         rc = fi_cq_signal(NA_OFI_CONTEXT(context)->noc_cq);
--- b/src/na/na_plugin.h
+++ /dev/null
@@ -1,126 +0,0 @@
-/*
- * Copyright (C) 2013-2018 Argonne National Laboratory, Department of Energy,
- *                    UChicago Argonne, LLC and The HDF Group.
- * All rights reserved.
- *
- * The full copyright notice, including terms governing use, modification,
- * and redistribution, is contained in the COPYING file that can be
- * found at the root of the source code distribution tree.
- */
-
-#ifndef NA_PLUGIN_H
-#define NA_PLUGIN_H
-
-#include "na.h"
-
-#include "mercury_atomic_queue.h"
-#include "mercury_queue.h"
-#include "mercury_thread_mutex.h"
-#include "mercury_thread_condition.h"
-
-/*************************************/
-/* Public Type and Struct Definition */
-/*************************************/
-
-/* Private callback type for NA plugins */
-typedef void (*na_plugin_cb_t)(void *arg);
-
-/* Completion data stored in completion queue */
-struct na_cb_completion_data {
-    na_cb_t callback;                   /* Pointer to function */
-    struct na_cb_info callback_info;    /* Callback info struct */
-    na_plugin_cb_t plugin_callback;     /* Callback which will be called after
-                                         * the user callback returns. */
-    void *plugin_callback_args;         /* Argument to plugin_callback */
-    HG_QUEUE_ENTRY(na_cb_completion_data) entry; /* Completion queue entry */
-};
-
-/*****************/
-/* Public Macros */
-/*****************/
-
-/* Remove warnings when plugin does not use callback arguments */
-#if defined(__cplusplus)
-# define NA_UNUSED
-#elif defined(__GNUC__) && (__GNUC__ >= 4)
-# define NA_UNUSED __attribute__((unused))
-#else
-# define NA_UNUSED
-#endif
-
-/**
- * container_of - cast a member of a structure out to the containing structure
- * \ptr:        the pointer to the member.
- * \type:       the type of the container struct this is embedded in.
- * \member:     the name of the member within the struct.
- *
- */
-#if !defined(container_of)
-# define container_of(ptr, type, member) \
-    ((type *) ((char *) ptr - offsetof(type, member)))
-#endif
-
-/**
- * Min/max macros
- */
-#ifndef MAX
-# define MAX(a, b) (((a) > (b)) ? (a) : (b))
-#endif
-#ifndef MIN
-# define MIN(a, b) (((a) < (b)) ? (a) : (b))
-#endif
-
-/**
- * Plugin ops definition
- */
-#define NA_PLUGIN_OPS(plugin_name) \
-    const struct na_class_ops na_ ##plugin_name ##_class_ops_g
-
-/*********************/
-/* Public Prototypes */
-/*********************/
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-/* Private routines for use inside NA plugins */
-
-/**
- * Add callback to context completion queue.
- *
- * \param context [IN/OUT]              pointer to context of execution
- * \param na_cb_completion_data [IN]    pointer to completion data
- *
- * \return NA_SUCCESS or corresponding NA error code (failure is not an option)
- */
-NA_EXPORT na_return_t
-na_cb_completion_add(
-        na_context_t                 *context,
-        struct na_cb_completion_data *na_cb_completion_data
-        );
-
-/*********************/
-/* Public Variables */
-/*********************/
-#ifdef NA_HAS_SM
-NA_EXPORT NA_PLUGIN_OPS(sm);
-#endif
-#ifdef NA_HAS_BMI
-NA_EXPORT NA_PLUGIN_OPS(bmi);
-#endif
-#ifdef NA_HAS_MPI
-NA_EXPORT NA_PLUGIN_OPS(mpi);
-#endif
-#ifdef NA_HAS_CCI
-NA_EXPORT NA_PLUGIN_OPS(cci);
-#endif
-#ifdef NA_HAS_OFI
-NA_EXPORT NA_PLUGIN_OPS(ofi);
-#endif
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* NA_PLUGIN_H */
--- /dev/null
+++ a/src/na/na_private.h
@@ -0,0 +1,425 @@
+/*
+ * Copyright (C) 2013-2018 Argonne National Laboratory, Department of Energy,
+ *                    UChicago Argonne, LLC and The HDF Group.
+ * All rights reserved.
+ *
+ * The full copyright notice, including terms governing use, modification,
+ * and redistribution, is contained in the COPYING file that can be
+ * found at the root of the source code distribution tree.
+ */
+
+#ifndef NA_PRIVATE_H
+#define NA_PRIVATE_H
+
+#include "na.h"
+#include "mercury_queue.h"
+
+#include <stddef.h>
+
+/*************************************/
+/* Public Type and Struct Definition */
+/*************************************/
+
+/* NA info definition */
+struct na_info {
+    char *class_name;    /* Class name (e.g., bmi) */
+    char *protocol_name; /* Protocol (e.g., tcp, ib) */
+    char *host_name;     /* Host (may be NULL in anonymous mode) */
+    /* Additional init info (NULL if no info) */
+    const struct na_init_info *na_init_info;
+};
+
+/* Private callback type for NA plugins */
+typedef void (*na_plugin_cb_t)(void *arg);
+
+/* NA execution context, plugins may use plugin context if protocol supports
+ * progress on separate contexts/queues/etc */
+struct na_context {
+    void *plugin_context;
+};
+
+/* Completion data stored in completion queue */
+struct na_cb_completion_data {
+    na_cb_t callback;                   /* Pointer to function */
+    struct na_cb_info callback_info;    /* Callback info struct */
+    na_plugin_cb_t plugin_callback;     /* Callback which will be called after
+                                         * the user callback returns. */
+    void *plugin_callback_args;         /* Argument to plugin_callback */
+    HG_QUEUE_ENTRY(na_cb_completion_data) entry; /* Completion queue entry */
+};
+
+/* NA class definition */
+struct na_class {
+    void *private_data;     /* Plugin private data */
+    const char *class_name; /* Class name */
+
+    /* plugin callbacks */
+    na_bool_t
+    (*check_protocol)(
+            const char *protocol_name
+            );
+    na_return_t
+    (*initialize)(
+            na_class_t *na_class,
+            const struct na_info *na_info,
+            na_bool_t listen
+            );
+    na_return_t
+    (*finalize)(
+            na_class_t *na_class
+            );
+    void
+    (*cleanup)(
+            void
+            );
+    na_return_t
+    (*context_create)(
+            na_class_t *na_class,
+            void **plugin_context,
+            na_uint8_t id
+            );
+    na_return_t
+    (*context_destroy)(
+            na_class_t *na_class,
+            void *plugin_context
+            );
+    na_op_id_t
+    (*op_create)(
+            na_class_t *na_class
+            );
+    na_return_t
+    (*op_destroy)(
+            na_class_t *na_class,
+            na_op_id_t op_id
+            );
+    na_return_t
+    (*addr_lookup)(
+            na_class_t   *na_class,
+            na_context_t *context,
+            na_cb_t       callback,
+            void         *arg,
+            const char   *name,
+            na_op_id_t   *op_id
+            );
+    na_return_t
+    (*addr_free)(
+            na_class_t *na_class,
+            na_addr_t   addr
+            );
+    na_return_t
+    (*addr_self)(
+            na_class_t *na_class,
+            na_addr_t  *addr
+            );
+    na_return_t
+    (*addr_dup)(
+            na_class_t *na_class,
+            na_addr_t   addr,
+            na_addr_t  *new_addr
+            );
+    na_bool_t
+    (*addr_is_self)(
+            na_class_t *na_class,
+            na_addr_t   addr
+            );
+    na_return_t
+    (*addr_to_string)(
+            na_class_t *na_class,
+            char       *buf,
+            na_size_t  *buf_size,
+            na_addr_t   addr
+            );
+    na_size_t
+    (*addr_get_serialize_size)(
+            na_class_t      *na_class,
+            na_addr_t        addr
+            );
+    na_return_t
+    (*addr_serialize)(
+            na_class_t      *na_class,
+            void            *buf,
+            na_size_t        buf_size,
+            na_addr_t        addr
+    );
+    na_return_t
+    (*addr_deserialize)(
+            na_class_t      *na_class,
+            na_addr_t       *addr,
+            const void      *buf,
+            na_size_t        buf_size
+    );
+    na_size_t
+    (*msg_get_max_unexpected_size)(
+            const na_class_t *na_class
+            );
+    na_size_t
+    (*msg_get_max_expected_size)(
+            const na_class_t *na_class
+            );
+    na_size_t
+    (*msg_get_unexpected_header_size)(
+            const na_class_t *na_class
+            );
+    na_size_t
+    (*msg_get_expected_header_size)(
+            const na_class_t *na_class
+            );
+    na_tag_t
+    (*msg_get_max_tag)(
+            const na_class_t *na_class
+            );
+    void *
+    (*msg_buf_alloc)(
+            na_class_t *na_class,
+            na_size_t buf_size,
+            void **plugin_data
+            );
+    na_return_t
+    (*msg_buf_free)(
+            na_class_t *na_class,
+            void *buf,
+            void *plugin_data
+            );
+    na_return_t
+    (*msg_init_unexpected)(
+            na_class_t *na_class,
+            void *buf,
+            na_size_t buf_size
+            );
+    na_return_t
+    (*msg_send_unexpected)(
+            na_class_t   *na_class,
+            na_context_t *context,
+            na_cb_t       callback,
+            void         *arg,
+            const void   *buf,
+            na_size_t     buf_size,
+            void         *plugin_data,
+            na_addr_t     dest_addr,
+            na_uint8_t    dest_id,
+            na_tag_t      tag,
+            na_op_id_t   *op_id
+            );
+    na_return_t
+    (*msg_recv_unexpected)(
+            na_class_t   *na_class,
+            na_context_t *context,
+            na_cb_t       callback,
+            void         *arg,
+            void         *buf,
+            na_size_t     buf_size,
+            void         *plugin_data,
+            na_op_id_t   *op_id
+            );
+    na_return_t
+    (*msg_init_expected)(
+            na_class_t *na_class,
+            void *buf,
+            na_size_t buf_size
+            );
+    na_return_t
+    (*msg_send_expected)(
+            na_class_t   *na_class,
+            na_context_t *context,
+            na_cb_t       callback,
+            void         *arg,
+            const void   *buf,
+            na_size_t     buf_size,
+            void         *plugin_data,
+            na_addr_t     dest_addr,
+            na_uint8_t    dest_id,
+            na_tag_t      tag,
+            na_op_id_t   *op_id
+            );
+    na_return_t
+    (*msg_recv_expected)(
+            na_class_t   *na_class,
+            na_context_t *context,
+            na_cb_t       callback,
+            void         *arg,
+            void         *buf,
+            na_size_t     buf_size,
+            void         *plugin_data,
+            na_addr_t     source_addr,
+            na_uint8_t    source_id,
+            na_tag_t      tag,
+            na_op_id_t   *op_id
+            );
+    na_return_t
+    (*mem_handle_create)(
+            na_class_t      *na_class,
+            void            *buf,
+            na_size_t        buf_size,
+            unsigned long    flags,
+            na_mem_handle_t *mem_handle
+            );
+    na_return_t
+    (*mem_handle_create_segments)(
+            na_class_t        *na_class,
+            struct na_segment *segments,
+            na_size_t          segment_count,
+            unsigned long      flags,
+            na_mem_handle_t   *mem_handle
+            );
+    na_return_t
+    (*mem_handle_free)(
+            na_class_t      *na_class,
+            na_mem_handle_t  mem_handle
+            );
+    na_return_t
+    (*mem_register)(
+            na_class_t      *na_class,
+            na_mem_handle_t  mem_handle
+            );
+    na_return_t
+    (*mem_deregister)(
+            na_class_t      *na_class,
+            na_mem_handle_t  mem_handle
+            );
+    na_return_t
+    (*mem_publish)(
+            na_class_t      *na_class,
+            na_mem_handle_t  mem_handle
+            );
+    na_return_t
+    (*mem_unpublish)(
+            na_class_t      *na_class,
+            na_mem_handle_t  mem_handle
+            );
+    na_size_t
+    (*mem_handle_get_serialize_size)(
+            na_class_t      *na_class,
+            na_mem_handle_t  mem_handle
+            );
+    na_return_t
+    (*mem_handle_serialize)(
+            na_class_t      *na_class,
+            void            *buf,
+            na_size_t        buf_size,
+            na_mem_handle_t  mem_handle
+            );
+    na_return_t
+    (*mem_handle_deserialize)(
+            na_class_t      *na_class,
+            na_mem_handle_t *mem_handle,
+            const void      *buf,
+            na_size_t        buf_size
+            );
+    na_return_t
+    (*put)(
+            na_class_t      *na_class,
+            na_context_t    *context,
+            na_cb_t          callback,
+            void            *arg,
+            na_mem_handle_t  local_mem_handle,
+            na_offset_t      local_offset,
+            na_mem_handle_t  remote_mem_handle,
+            na_offset_t      remote_offset,
+            na_size_t        length,
+            na_addr_t        remote_addr,
+            na_uint8_t       remote_id,
+            na_op_id_t      *op_id
+            );
+    na_return_t
+    (*get)(
+            na_class_t      *na_class,
+            na_context_t    *context,
+            na_cb_t          callback,
+            void            *arg,
+            na_mem_handle_t  local_mem_handle,
+            na_offset_t      local_offset,
+            na_mem_handle_t  remote_mem_handle,
+            na_offset_t      remote_offset,
+            na_size_t        length,
+            na_addr_t        remote_addr,
+            na_uint8_t       remote_id,
+            na_op_id_t      *op_id
+            );
+    int
+    (*na_poll_get_fd)(
+            na_class_t      *na_class,
+            na_context_t    *context
+            );
+    na_bool_t
+    (*na_poll_try_wait)(
+            na_class_t      *na_class,
+            na_context_t    *context
+            );
+    na_return_t
+    (*progress)(
+            na_class_t   *na_class,
+            na_context_t *context,
+            unsigned int  timeout
+            );
+    na_return_t
+    (*cancel)(
+            na_class_t   *na_class,
+            na_context_t *context,
+            na_op_id_t    op_id
+            );
+};
+
+/*****************/
+/* Public Macros */
+/*****************/
+
+/* Remove warnings when plugin does not use callback arguments */
+#if defined(__cplusplus)
+# define NA_UNUSED
+#elif defined(__GNUC__) && (__GNUC__ >= 4)
+# define NA_UNUSED __attribute__((unused))
+#else
+# define NA_UNUSED
+#endif
+
+/**
+ * container_of - cast a member of a structure out to the containing structure
+ * \ptr:        the pointer to the member.
+ * \type:       the type of the container struct this is embedded in.
+ * \member:     the name of the member within the struct.
+ *
+ */
+#if !defined(container_of)
+# define container_of(ptr, type, member) \
+    ((type *) ((char *) ptr - offsetof(type, member)))
+#endif
+
+/**
+ * Min/max macros
+ */
+#ifndef MAX
+# define MAX(a, b) (((a) > (b)) ? (a) : (b))
+#endif
+#ifndef MIN
+# define MIN(a, b) (((a) < (b)) ? (a) : (b))
+#endif
+
+/*********************/
+/* Public Prototypes */
+/*********************/
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Private routines for use inside NA plugins */
+
+/**
+ * Add callback to context completion queue.
+ *
+ * \param context [IN/OUT]              pointer to context of execution
+ * \param na_cb_completion_data [IN]    pointer to completion data
+ *
+ * \return NA_SUCCESS or corresponding NA error code (failure is not an option)
+ */
+NA_EXPORT na_return_t
+na_cb_completion_add(
+        na_context_t                 *context,
+        struct na_cb_completion_data *na_cb_completion_data
+        );
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NA_PRIVATE_H */
--- b/src/na/na_sm.c
+++ a/src/na/na_sm.c
@@ -11,10 +11,16 @@
 #if !defined(_WIN32) && !defined(_GNU_SOURCE)
 #define _GNU_SOURCE
 #endif
+#include "na_private.h"
+#include "na_error.h"
-#include "na_plugin.h"
 
+#include "mercury_queue.h"
+#include "mercury_thread_mutex.h"
 #include "mercury_thread_spin.h"
 #include "mercury_time.h"
+#include "mercury_atomic.h"
+#include "mercury_atomic_queue.h"
+#include "mercury_thread.h"
 #include "mercury_poll.h"
 #include "mercury_event.h"
 #include "mercury_mem.h"
@@ -66,8 +72,8 @@
 #define NA_SM_MAX_TAG           NA_TAG_UB
 
 /* Private data access */
+#define NA_SM_PRIVATE_DATA(na_class) \
+    ((struct na_sm_private_data *)(na_class->private_data))
-#define NA_SM_CLASS(na_class) \
-    ((struct na_sm_class *)(na_class->plugin_class))
 
 /* Min macro */
 #define NA_SM_MIN(a, b) \
@@ -251,7 +257,7 @@
 };
 
 /* Private data */
+struct na_sm_private_data {
-struct na_sm_class {
     struct na_sm_addr *self_addr;
     hg_poll_set_t *poll_set;
     HG_QUEUE_HEAD(na_sm_addr) accepted_addr_queue;
@@ -588,7 +594,7 @@
 /**
  * Release memory.
  */
+static void
-static NA_INLINE void
 na_sm_release(
     void *arg
     );
@@ -666,7 +672,7 @@
     );
 
 /* addr_is_self */
+static na_bool_t
-static NA_INLINE na_bool_t
 na_sm_addr_is_self(
     na_class_t *na_class,
     na_addr_t addr
@@ -682,19 +688,19 @@
     );
 
 /* msg_get_max_unexpected_size */
+static na_size_t
-static NA_INLINE na_size_t
 na_sm_msg_get_max_unexpected_size(
     const na_class_t *na_class
     );
 
 /* msg_get_max_expected_size */
+static na_size_t
-static NA_INLINE na_size_t
 na_sm_msg_get_max_expected_size(
     const na_class_t *na_class
     );
 
 /* msg_get_max_tag */
+static na_tag_t
-static NA_INLINE na_tag_t
 na_sm_msg_get_max_tag(
     const na_class_t *na_class
     );
@@ -790,7 +796,7 @@
     );
 
 /* mem_handle_get_serialize_size */
+static na_size_t
-static NA_INLINE na_size_t
 na_sm_mem_handle_get_serialize_size(
     na_class_t *na_class,
     na_mem_handle_t mem_handle
@@ -849,14 +855,14 @@
     );
 
 /* poll_get_fd */
+static int
-static NA_INLINE int
 na_sm_poll_get_fd(
     na_class_t      *na_class,
     na_context_t    *context
     );
 
 /* poll_try_wait */
+static na_bool_t
-static NA_INLINE na_bool_t
 na_sm_poll_try_wait(
     na_class_t      *na_class,
     na_context_t    *context
@@ -882,7 +888,8 @@
 /* Local Variables */
 /*******************/
 
+const na_class_t na_sm_class_g = {
+    NULL,                                   /* private_data */
-NA_PLUGIN_OPS(sm) = {
     "na",                                   /* name */
     na_sm_check_protocol,                   /* check_protocol */
     na_sm_initialize,                       /* initialize */
@@ -1294,7 +1301,7 @@
     na_sm_poll_data->addr = na_sm_addr;
     *na_sm_poll_data_ptr = na_sm_poll_data;
 
+    if (hg_poll_add(NA_SM_PRIVATE_DATA(na_class)->poll_set, fd, flags,
-    if (hg_poll_add(NA_SM_CLASS(na_class)->poll_set, fd, flags,
         na_sm_progress_cb, na_sm_poll_data) != HG_UTIL_SUCCESS) {
         NA_LOG_ERROR("hg_poll_add failed");
         ret = NA_PROTOCOL_ERROR;
@@ -1333,7 +1340,7 @@
             goto done;
     }
 
+    if (hg_poll_remove(NA_SM_PRIVATE_DATA(na_class)->poll_set,
-    if (hg_poll_remove(NA_SM_CLASS(na_class)->poll_set,
         fd) != HG_UTIL_SUCCESS) {
         NA_LOG_ERROR("hg_poll_remove failed");
         ret = NA_PROTOCOL_ERROR;
@@ -1397,9 +1404,9 @@
     na_return_t ret = NA_SUCCESS;
 
     /* Send local PID / ID */
+    iovec[0].iov_base = &NA_SM_PRIVATE_DATA(na_class)->self_addr->pid;
-    iovec[0].iov_base = &NA_SM_CLASS(na_class)->self_addr->pid;
     iovec[0].iov_len = sizeof(pid_t);
+    iovec[1].iov_base = &NA_SM_PRIVATE_DATA(na_class)->self_addr->id;
-    iovec[1].iov_base = &NA_SM_CLASS(na_class)->self_addr->id;
     iovec[1].iov_len = sizeof(unsigned int);
     msg.msg_iov = iovec;
     msg.msg_iovlen = 2;
@@ -1620,7 +1627,7 @@
     na_return_t ret = NA_SIZE_ERROR;
     unsigned int i = 0;
 
+    hg_thread_spin_lock(&NA_SM_PRIVATE_DATA(na_class)->copy_buf_lock);
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->copy_buf_lock);
 
     do {
         hg_util_int64_t available = hg_atomic_get64(
@@ -1650,7 +1657,7 @@
          * fails, we should be able to pick the next one available */
     } while (i < (NA_SM_NUM_BUFS - 1));
 
+    hg_thread_spin_unlock(&NA_SM_PRIVATE_DATA(na_class)->copy_buf_lock);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->copy_buf_lock);
     return ret;
 }
 
@@ -1665,7 +1672,7 @@
     hg_util_int64_t available;
 #endif
 
+    hg_thread_spin_lock(&NA_SM_PRIVATE_DATA(na_class)->copy_buf_lock);
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->copy_buf_lock);
 
     memcpy(buf, na_sm_copy_buf->buf[idx_reserved], buf_size);
 
@@ -1678,7 +1685,7 @@
         (available | bits)));
 #endif
 
+    hg_thread_spin_unlock(&NA_SM_PRIVATE_DATA(na_class)->copy_buf_lock);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->copy_buf_lock);
 }
 
 /*---------------------------------------------------------------------------*/
@@ -1709,7 +1716,7 @@
     }
 
     /* Notify remote */
+    if (!NA_SM_PRIVATE_DATA(na_class)->no_wait) {
-    if (!NA_SM_CLASS(na_class)->no_wait) {
 #ifdef HG_UTIL_HAS_SYSEVENTFD_H
         if (hg_event_set(na_sm_addr->remote_notify) != HG_UTIL_SUCCESS) {
             NA_LOG_ERROR("Could not send completion notification");
@@ -1726,8 +1733,8 @@
     }
 
     /* Notify local completion */
+    if (!NA_SM_PRIVATE_DATA(na_class)->no_wait
+        && (hg_event_set(NA_SM_PRIVATE_DATA(na_class)->self_addr->local_notify)
-    if (!NA_SM_CLASS(na_class)->no_wait
-        && (hg_event_set(NA_SM_CLASS(na_class)->self_addr->local_notify)
         != HG_UTIL_SUCCESS)) {
         NA_LOG_ERROR("Could not signal local completion");
         ret = NA_PROTOCOL_ERROR;
@@ -1841,7 +1848,7 @@
 {
     na_return_t ret = NA_SUCCESS;
 
+    if (poll_addr == NA_SM_PRIVATE_DATA(na_class)->self_addr) {
-    if (poll_addr == NA_SM_CLASS(na_class)->self_addr) {
         NA_LOG_ERROR("Unsupported error occurred");
         ret = NA_PROTOCOL_ERROR;
         goto done;
@@ -1869,7 +1876,7 @@
     double elapsed_ms;
     na_return_t ret = NA_SUCCESS;
 
+    if (poll_addr != NA_SM_PRIVATE_DATA(na_class)->self_addr) {
-    if (poll_addr != NA_SM_CLASS(na_class)->self_addr) {
         NA_LOG_ERROR("Unrecognized poll addr");
         ret = NA_PROTOCOL_ERROR;
         goto done;
@@ -1878,12 +1885,12 @@
     /* Prevent from entering accept too often */
     hg_time_get_current(&now);
     elapsed_ms = hg_time_to_double(hg_time_subtract(now,
+        NA_SM_PRIVATE_DATA(na_class)->last_accept_time)) * 1000.0;
-        NA_SM_CLASS(na_class)->last_accept_time)) * 1000.0;
     if (elapsed_ms < NA_SM_ACCEPT_INTERVAL) {
         *progressed = NA_FALSE;
         goto done;
     }
+    NA_SM_PRIVATE_DATA(na_class)->last_accept_time = now;
-    NA_SM_CLASS(na_class)->last_accept_time = now;
 
 #ifdef SOCK_NONBLOCK
     conn_sock = accept4(poll_addr->sock, NULL, NULL, SOCK_NONBLOCK);
@@ -1930,9 +1937,9 @@
     }
 
     /* Set up ring buffer pair (send/recv) for connection IDs */
+    na_sm_addr->conn_id = NA_SM_PRIVATE_DATA(na_class)->self_addr->conn_id;
-    na_sm_addr->conn_id = NA_SM_CLASS(na_class)->self_addr->conn_id;
     NA_SM_GEN_RING_NAME(filename, NA_SM_SEND_NAME,
+        NA_SM_PRIVATE_DATA(na_class)->self_addr);
-        NA_SM_CLASS(na_class)->self_addr);
     na_sm_ring_buf = (struct na_sm_ring_buf *) na_sm_open_shared_buf(filename,
         NA_SM_RING_BUF_SIZE, NA_TRUE);
     if (!na_sm_ring_buf) {
@@ -1945,7 +1952,7 @@
     na_sm_addr->na_sm_send_ring_buf = na_sm_ring_buf;
 
     NA_SM_GEN_RING_NAME(filename, NA_SM_RECV_NAME,
+        NA_SM_PRIVATE_DATA(na_class)->self_addr);
-        NA_SM_CLASS(na_class)->self_addr);
     na_sm_ring_buf = (struct na_sm_ring_buf *) na_sm_open_shared_buf(filename,
         NA_SM_RING_BUF_SIZE, NA_TRUE);
     if (!na_sm_ring_buf) {
@@ -1972,7 +1979,7 @@
      * ancillary data
      */
     NA_SM_GEN_FIFO_NAME(filename, NA_SM_RECV_NAME,
+        NA_SM_PRIVATE_DATA(na_class)->self_addr);
-        NA_SM_CLASS(na_class)->self_addr);
     local_notify = na_sm_event_create(filename);
     if (local_notify == -1) {
         NA_LOG_ERROR("na_sm_event_create() failed");
@@ -1997,7 +2004,7 @@
      * ancillary data
      */
     NA_SM_GEN_FIFO_NAME(filename, NA_SM_SEND_NAME,
+        NA_SM_PRIVATE_DATA(na_class)->self_addr);
-        NA_SM_CLASS(na_class)->self_addr);
     remote_notify = na_sm_event_create(filename);
     if (remote_notify == -1) {
         NA_LOG_ERROR("na_sm_event_create() failed");
@@ -2022,13 +2029,15 @@
     }
 
     /* Increment connection ID */
+    NA_SM_PRIVATE_DATA(na_class)->self_addr->conn_id++;
-    NA_SM_CLASS(na_class)->self_addr->conn_id++;
 
     /* Push the addr to accepted addr queue so that we can free it later */
+    hg_thread_spin_lock(
+        &NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue_lock);
+    HG_QUEUE_PUSH_TAIL(&NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue,
+        na_sm_addr, entry);
+    hg_thread_spin_unlock(
+        &NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue_lock);
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->accepted_addr_queue_lock);
-    HG_QUEUE_PUSH_TAIL(&NA_SM_CLASS(na_class)->accepted_addr_queue, na_sm_addr,
-        entry);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->accepted_addr_queue_lock);
 
     *progressed = NA_TRUE;
 
@@ -2043,7 +2052,7 @@
 {
     na_return_t ret = NA_SUCCESS;
 
+    if (poll_addr == NA_SM_PRIVATE_DATA(na_class)->self_addr) {
-    if (poll_addr == NA_SM_CLASS(na_class)->self_addr) {
         *progressed = NA_FALSE;
         goto done;
     }
@@ -2067,10 +2076,12 @@
             poll_addr->sock_progress = NA_SM_SOCK_DONE;
 
             /* Add addr to poll addr queue */
+            hg_thread_spin_lock(
+                &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
+            HG_QUEUE_PUSH_TAIL(&NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue,
-            hg_thread_spin_lock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
-            HG_QUEUE_PUSH_TAIL(&NA_SM_CLASS(na_class)->poll_addr_queue,
                 poll_addr, poll_entry);
+            hg_thread_spin_unlock(
+                &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
-            hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
 
             /* Progressed */
             *progressed = NA_TRUE;
@@ -2096,16 +2107,19 @@
             poll_addr->sock_progress = NA_SM_SOCK_DONE;
 
             /* Find op ID that corresponds to addr */
+            hg_thread_spin_lock(
+                &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue_lock);
-            hg_thread_spin_lock(&NA_SM_CLASS(na_class)->lookup_op_queue_lock);
             HG_QUEUE_FOREACH(na_sm_op_id,
+                &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue, entry) {
-                &NA_SM_CLASS(na_class)->lookup_op_queue, entry) {
                 if (na_sm_op_id->info.lookup.na_sm_addr == poll_addr) {
+                    HG_QUEUE_REMOVE(
+                        &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue,
-                    HG_QUEUE_REMOVE(&NA_SM_CLASS(na_class)->lookup_op_queue,
                         na_sm_op_id, na_sm_op_id, entry);
                     break;
                 }
             }
+            hg_thread_spin_unlock(
+                &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue_lock);
-            hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->lookup_op_queue_lock);
 
             if (!na_sm_op_id) {
                 NA_LOG_ERROR("Could not find lookup op ID, conn ID=%u, PID=%u",
@@ -2144,10 +2158,12 @@
             }
 
             /* Add addr to poll addr queue */
+            hg_thread_spin_lock(
+                &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
+            HG_QUEUE_PUSH_TAIL(&NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue,
-            hg_thread_spin_lock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
-            HG_QUEUE_PUSH_TAIL(&NA_SM_CLASS(na_class)->poll_addr_queue,
                 poll_addr, poll_entry);
+            hg_thread_spin_unlock(
+                &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
-            hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
 
             /* Completion */
             ret = na_sm_complete(na_sm_op_id);
@@ -2179,9 +2195,9 @@
     na_bool_t notified = NA_FALSE;
     na_return_t ret = NA_SUCCESS;
 
+    if (poll_addr == NA_SM_PRIVATE_DATA(na_class)->self_addr) {
-    if (poll_addr == NA_SM_CLASS(na_class)->self_addr) {
         /* Local notification */
+        if (!NA_SM_PRIVATE_DATA(na_class)->no_wait
-        if (!NA_SM_CLASS(na_class)->no_wait
             && (hg_event_get(poll_addr->local_notify, (hg_util_bool_t *) &notified)
             != HG_UTIL_SUCCESS)) {
             NA_LOG_ERROR("Could not get completion notification");
@@ -2198,7 +2214,7 @@
     }
 
     /* Remote notification */
+    if (!NA_SM_PRIVATE_DATA(na_class)->no_wait) {
-    if (!NA_SM_CLASS(na_class)->no_wait) {
 #ifdef HG_UTIL_HAS_SYSEVENTFD_H
         if (hg_event_get(poll_addr->local_notify, (hg_util_bool_t *) &notified)
             != HG_UTIL_SUCCESS) {
@@ -2258,10 +2274,14 @@
     na_return_t ret = NA_SUCCESS;
 
     /* Pop op ID from queue */
+    hg_thread_spin_lock(
+        &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
+    na_sm_op_id = HG_QUEUE_FIRST(
+        &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue);
+    HG_QUEUE_POP_HEAD(&NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue,
+        entry);
+    hg_thread_spin_unlock(
+        &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
-    na_sm_op_id = HG_QUEUE_FIRST(&NA_SM_CLASS(na_class)->unexpected_op_queue);
-    HG_QUEUE_POP_HEAD(&NA_SM_CLASS(na_class)->unexpected_op_queue, entry);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
 
     if (na_sm_op_id) {
         /* If an op id was pushed, associate unexpected info to this
@@ -2289,11 +2309,12 @@
 
         /* Otherwise push the unexpected message into our unexpected queue so
          * that we can treat it later when a recv_unexpected is posted */
+        hg_thread_spin_lock(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue_lock);
+        HG_QUEUE_PUSH_TAIL(&NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue,
-        hg_thread_spin_lock(&NA_SM_CLASS(na_class)->unexpected_msg_queue_lock);
-        HG_QUEUE_PUSH_TAIL(&NA_SM_CLASS(na_class)->unexpected_msg_queue,
             na_sm_unexpected_info, entry);
         hg_thread_spin_unlock(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue_lock);
-            &NA_SM_CLASS(na_class)->unexpected_msg_queue_lock);
     }
 
 done:
@@ -2309,18 +2330,18 @@
     na_return_t ret = NA_SUCCESS;
 
     hg_thread_spin_lock(
+        &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
-        &NA_SM_CLASS(na_class)->expected_op_queue_lock);
     HG_QUEUE_FOREACH(na_sm_op_id,
+        &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue, entry) {
-        &NA_SM_CLASS(na_class)->expected_op_queue, entry) {
         if (na_sm_op_id->info.recv_expected.na_sm_addr == poll_addr &&
             na_sm_op_id->info.recv_expected.tag == na_sm_hdr.hdr.tag) {
+            HG_QUEUE_REMOVE(&NA_SM_PRIVATE_DATA(na_class)->expected_op_queue,
-            HG_QUEUE_REMOVE(&NA_SM_CLASS(na_class)->expected_op_queue,
                 na_sm_op_id, na_sm_op_id, entry);
             break;
         }
     }
     hg_thread_spin_unlock(
+        &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
-        &NA_SM_CLASS(na_class)->expected_op_queue_lock);
 
     if (!na_sm_op_id) {
         /* No match if either the message was not pre-posted or it was canceled */
@@ -2425,7 +2446,7 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static void
-static NA_INLINE void
 na_sm_release(void *arg)
 {
     struct na_sm_op_id *na_sm_op_id = (struct na_sm_op_id *) arg;
@@ -2477,14 +2498,14 @@
     errno = 0;
 
     /* Initialize private data */
+    na_class->private_data = malloc(sizeof(struct na_sm_private_data));
+    if (!na_class->private_data) {
-    na_class->plugin_class = malloc(sizeof(struct na_sm_class));
-    if (!na_class->plugin_class) {
         NA_LOG_ERROR("Could not allocate NA private data class");
         ret = NA_NOMEM_ERROR;
         goto done;
     }
+    memset(na_class->private_data, 0, sizeof(struct na_sm_private_data));
+    NA_SM_PRIVATE_DATA(na_class)->no_wait = no_wait;
-    memset(na_class->plugin_class, 0, sizeof(struct na_sm_class));
-    NA_SM_CLASS(na_class)->no_wait = no_wait;
 
     /* Create poll set to wait for events */
     poll_set = hg_poll_create();
@@ -2493,7 +2514,7 @@
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
+    NA_SM_PRIVATE_DATA(na_class)->poll_set = poll_set;
-    NA_SM_CLASS(na_class)->poll_set = poll_set;
 
     /* Create self addr */
     na_sm_addr = (struct na_sm_addr *) malloc(sizeof(struct na_sm_addr));
@@ -2530,24 +2551,31 @@
         NA_LOG_ERROR("Could not add notify to poll set");
         goto done;
     }
+    NA_SM_PRIVATE_DATA(na_class)->self_addr = na_sm_addr;
-    NA_SM_CLASS(na_class)->self_addr = na_sm_addr;
 
     /* Initialize queues */
+    HG_QUEUE_INIT(&NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue);
+    HG_QUEUE_INIT(&NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue);
+    HG_QUEUE_INIT(&NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue);
+    HG_QUEUE_INIT(&NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue);
+    HG_QUEUE_INIT(&NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue);
+    HG_QUEUE_INIT(&NA_SM_PRIVATE_DATA(na_class)->expected_op_queue);
-    HG_QUEUE_INIT(&NA_SM_CLASS(na_class)->accepted_addr_queue);
-    HG_QUEUE_INIT(&NA_SM_CLASS(na_class)->poll_addr_queue);
-    HG_QUEUE_INIT(&NA_SM_CLASS(na_class)->unexpected_msg_queue);
-    HG_QUEUE_INIT(&NA_SM_CLASS(na_class)->lookup_op_queue);
-    HG_QUEUE_INIT(&NA_SM_CLASS(na_class)->unexpected_op_queue);
-    HG_QUEUE_INIT(&NA_SM_CLASS(na_class)->expected_op_queue);
 
     /* Initialize mutexes */
+    hg_thread_spin_init(
+            &NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue_lock);
+    hg_thread_spin_init(
+                &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
+    hg_thread_spin_init(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue_lock);
+    hg_thread_spin_init(
+            &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue_lock);
+    hg_thread_spin_init(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
+    hg_thread_spin_init(
+            &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
+    hg_thread_spin_init(
+             &NA_SM_PRIVATE_DATA(na_class)->copy_buf_lock);
-    hg_thread_spin_init(&NA_SM_CLASS(na_class)->accepted_addr_queue_lock);
-    hg_thread_spin_init(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
-    hg_thread_spin_init(&NA_SM_CLASS(na_class)->unexpected_msg_queue_lock);
-    hg_thread_spin_init(&NA_SM_CLASS(na_class)->lookup_op_queue_lock);
-    hg_thread_spin_init(&NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
-    hg_thread_spin_init(&NA_SM_CLASS(na_class)->expected_op_queue_lock);
-    hg_thread_spin_init(&NA_SM_CLASS(na_class)->copy_buf_lock);
 
 done:
     return ret;
@@ -2559,42 +2587,42 @@
 {
     na_return_t ret = NA_SUCCESS;
 
+    if (!na_class->private_data) {
-    if (!na_class->plugin_class) {
         goto done;
     }
 
     /* Check that lookup op queue is empty */
+    if (!HG_QUEUE_IS_EMPTY(&NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue)) {
-    if (!HG_QUEUE_IS_EMPTY(&NA_SM_CLASS(na_class)->lookup_op_queue)) {
         NA_LOG_ERROR("Lookup op queue should be empty");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Check that unexpected op queue is empty */
+    if (!HG_QUEUE_IS_EMPTY(&NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue)) {
-    if (!HG_QUEUE_IS_EMPTY(&NA_SM_CLASS(na_class)->unexpected_op_queue)) {
         NA_LOG_ERROR("Unexpected op queue should be empty");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Check that unexpected message queue is empty */
+    if (!HG_QUEUE_IS_EMPTY(&NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue)) {
-    if (!HG_QUEUE_IS_EMPTY(&NA_SM_CLASS(na_class)->unexpected_msg_queue)) {
         NA_LOG_ERROR("Unexpected msg queue should be empty");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Check that expected op queue is empty */
+    if (!HG_QUEUE_IS_EMPTY(&NA_SM_PRIVATE_DATA(na_class)->expected_op_queue)) {
-    if (!HG_QUEUE_IS_EMPTY(&NA_SM_CLASS(na_class)->expected_op_queue)) {
         NA_LOG_ERROR("Expected op queue should be empty");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Check that accepted addr queue is empty */
+    while (!HG_QUEUE_IS_EMPTY(&NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue)) {
-    while (!HG_QUEUE_IS_EMPTY(&NA_SM_CLASS(na_class)->accepted_addr_queue)) {
         struct na_sm_addr *na_sm_addr = HG_QUEUE_FIRST(
+            &NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue);
-            &NA_SM_CLASS(na_class)->accepted_addr_queue);
         ret = na_sm_addr_free(na_class, na_sm_addr);
         if (ret != NA_SUCCESS) {
             NA_LOG_ERROR("Could not free accepted addr");
@@ -2603,29 +2631,36 @@
     }
 
     /* Free self addr */
+    ret = na_sm_addr_free(na_class, NA_SM_PRIVATE_DATA(na_class)->self_addr);
-    ret = na_sm_addr_free(na_class, NA_SM_CLASS(na_class)->self_addr);
     if (ret != NA_SUCCESS) {
         NA_LOG_ERROR("Could not free self addr");
         goto done;
     }
 
     /* Close poll set */
+    if (hg_poll_destroy(NA_SM_PRIVATE_DATA(na_class)->poll_set) != HG_UTIL_SUCCESS) {
-    if (hg_poll_destroy(NA_SM_CLASS(na_class)->poll_set) != HG_UTIL_SUCCESS) {
         NA_LOG_ERROR("hg_poll_destroy() failed");
         ret = NA_PROTOCOL_ERROR;
         goto done;
     }
 
     /* Destroy mutexes */
+    hg_thread_spin_destroy(
+            &NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue_lock);
+    hg_thread_spin_destroy(
+            &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
+    hg_thread_spin_destroy(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue_lock);
+    hg_thread_spin_destroy(
+            &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue_lock);
+    hg_thread_spin_destroy(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
+    hg_thread_spin_destroy(
+            &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
+    hg_thread_spin_destroy(
+             &NA_SM_PRIVATE_DATA(na_class)->copy_buf_lock);
+
+    free(na_class->private_data);
-    hg_thread_spin_destroy(&NA_SM_CLASS(na_class)->accepted_addr_queue_lock);
-    hg_thread_spin_destroy(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
-    hg_thread_spin_destroy(&NA_SM_CLASS(na_class)->unexpected_msg_queue_lock);
-    hg_thread_spin_destroy(&NA_SM_CLASS(na_class)->lookup_op_queue_lock);
-    hg_thread_spin_destroy(&NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
-    hg_thread_spin_destroy(&NA_SM_CLASS(na_class)->expected_op_queue_lock);
-    hg_thread_spin_destroy(&NA_SM_CLASS(na_class)->copy_buf_lock);
-
-    free(na_class->plugin_class);
 
 done:
     return ret;
@@ -2781,10 +2816,12 @@
     na_sm_addr->sock_progress = NA_SM_CONN_ID;
 
     /* Push op ID to lookup op queue */
+    hg_thread_spin_lock(
+        &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue_lock);
+    HG_QUEUE_PUSH_TAIL(&NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue,
+        na_sm_op_id, entry);
+    hg_thread_spin_unlock(
+        &NA_SM_PRIVATE_DATA(na_class)->lookup_op_queue_lock);
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->lookup_op_queue_lock);
-    HG_QUEUE_PUSH_TAIL(&NA_SM_CLASS(na_class)->lookup_op_queue, na_sm_op_id,
-        entry);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->lookup_op_queue_lock);
 
     /* Assign op_id */
     if (op_id && op_id != NA_OP_ID_IGNORE && *op_id == NA_OP_ID_NULL)
@@ -2838,11 +2875,13 @@
     }
 
     if (na_sm_addr->accepted) { /* Created by accept */
+        hg_thread_spin_lock(
+            &NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue_lock);
-        hg_thread_spin_lock(&NA_SM_CLASS(na_class)->accepted_addr_queue_lock);
         /* Remove the addr from accepted addr queue */
+        HG_QUEUE_REMOVE(&NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue,
+            na_sm_addr, na_sm_addr, entry);
+        hg_thread_spin_unlock(
+            &NA_SM_PRIVATE_DATA(na_class)->accepted_addr_queue_lock);
-        HG_QUEUE_REMOVE(&NA_SM_CLASS(na_class)->accepted_addr_queue, na_sm_addr,
-            na_sm_addr, entry);
-        hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->accepted_addr_queue_lock);
     }
 
     /* Deregister event file descriptors from poll set */
@@ -2876,20 +2915,22 @@
         }
 
         /* Remove addr from poll addr queue */
+        hg_thread_spin_lock(
+            &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
+        HG_QUEUE_REMOVE(&NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue,
+            na_sm_addr, na_sm_addr, poll_entry);
+        hg_thread_spin_unlock(
+            &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
-        hg_thread_spin_lock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
-        HG_QUEUE_REMOVE(&NA_SM_CLASS(na_class)->poll_addr_queue, na_sm_addr,
-            na_sm_addr, poll_entry);
-        hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
 
         if (na_sm_addr->accepted) { /* Created by accept */
             /* Get file names from ring bufs / events to delete files */
             sprintf(na_sm_send_ring_buf_name, "%s-%d-%d-%d-%s",
+                NA_SM_SHM_PREFIX, NA_SM_PRIVATE_DATA(na_class)->self_addr->pid,
+                NA_SM_PRIVATE_DATA(na_class)->self_addr->id,
-                NA_SM_SHM_PREFIX, NA_SM_CLASS(na_class)->self_addr->pid,
-                NA_SM_CLASS(na_class)->self_addr->id,
                 na_sm_addr->conn_id, NA_SM_SEND_NAME);
             sprintf(na_sm_recv_ring_buf_name, "%s-%d-%d-%d-%s",
+                NA_SM_SHM_PREFIX, NA_SM_PRIVATE_DATA(na_class)->self_addr->pid,
+                NA_SM_PRIVATE_DATA(na_class)->self_addr->id,
-                NA_SM_SHM_PREFIX, NA_SM_CLASS(na_class)->self_addr->pid,
-                NA_SM_CLASS(na_class)->self_addr->id,
                 na_sm_addr->conn_id, NA_SM_RECV_NAME);
             send_ring_buf_name = na_sm_send_ring_buf_name;
             recv_ring_buf_name = na_sm_recv_ring_buf_name;
@@ -2897,13 +2938,13 @@
 #ifndef HG_UTIL_HAS_SYSEVENTFD_H
             sprintf(na_sm_local_event_name, "%s/%s/%d/%u/fifo-%u-%s",
                 NA_SM_TMP_DIRECTORY, NA_SM_SHM_PREFIX,
+                NA_SM_PRIVATE_DATA(na_class)->self_addr->pid,
+                NA_SM_PRIVATE_DATA(na_class)->self_addr->id,
-                NA_SM_CLASS(na_class)->self_addr->pid,
-                NA_SM_CLASS(na_class)->self_addr->id,
                 na_sm_addr->conn_id, NA_SM_RECV_NAME);
             sprintf(na_sm_remote_event_name, "%s/%s/%d/%u/fifo-%u-%s",
                 NA_SM_TMP_DIRECTORY, NA_SM_SHM_PREFIX,
+                NA_SM_PRIVATE_DATA(na_class)->self_addr->pid,
+                NA_SM_PRIVATE_DATA(na_class)->self_addr->id,
-                NA_SM_CLASS(na_class)->self_addr->pid,
-                NA_SM_CLASS(na_class)->self_addr->id,
                 na_sm_addr->conn_id, NA_SM_SEND_NAME);
             local_event_name = na_sm_local_event_name;
             remote_event_name = na_sm_remote_event_name;
@@ -2998,7 +3039,7 @@
 static na_return_t
 na_sm_addr_self(na_class_t *na_class, na_addr_t *addr)
 {
+    struct na_sm_addr *na_sm_addr = NA_SM_PRIVATE_DATA(na_class)->self_addr;
-    struct na_sm_addr *na_sm_addr = NA_SM_CLASS(na_class)->self_addr;
     na_return_t ret = NA_SUCCESS;
 
     /* Increment refcount */
@@ -3026,7 +3067,7 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static na_bool_t
-static NA_INLINE na_bool_t
 na_sm_addr_is_self(na_class_t NA_UNUSED *na_class, na_addr_t addr)
 {
     struct na_sm_addr *na_sm_addr = (struct na_sm_addr *) addr;
@@ -3063,21 +3104,21 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static na_size_t
-static NA_INLINE na_size_t
 na_sm_msg_get_max_unexpected_size(const na_class_t NA_UNUSED *na_class)
 {
     return NA_SM_UNEXPECTED_SIZE;
 }
 
 /*---------------------------------------------------------------------------*/
+static na_size_t
-static NA_INLINE na_size_t
 na_sm_msg_get_max_expected_size(const na_class_t NA_UNUSED *na_class)
 {
     return NA_SM_EXPECTED_SIZE;
 }
 
 /*---------------------------------------------------------------------------*/
+static na_tag_t
-static NA_INLINE na_tag_t
 na_sm_msg_get_max_tag(const na_class_t NA_UNUSED *na_class)
 {
     return NA_SM_MAX_TAG;
@@ -3204,11 +3245,14 @@
         *op_id = na_sm_op_id;
 
     /* Look for an unexpected message already received */
+    hg_thread_spin_lock(
+        &NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue_lock);
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->unexpected_msg_queue_lock);
     na_sm_unexpected_info = HG_QUEUE_FIRST(
+        &NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue);
+    HG_QUEUE_POP_HEAD(&NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue,
+        entry);
+    hg_thread_spin_unlock(
+        &NA_SM_PRIVATE_DATA(na_class)->unexpected_msg_queue_lock);
-        &NA_SM_CLASS(na_class)->unexpected_msg_queue);
-    HG_QUEUE_POP_HEAD(&NA_SM_CLASS(na_class)->unexpected_msg_queue, entry);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->unexpected_msg_queue_lock);
     if (na_sm_unexpected_info) {
         na_sm_op_id->info.recv_unexpected.unexpected_info =
             *na_sm_unexpected_info;
@@ -3221,10 +3265,12 @@
         }
     } else {
         /* Nothing has been received yet so add op_id to progress queue */
+        hg_thread_spin_lock(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
+        HG_QUEUE_PUSH_TAIL(&NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue,
-        hg_thread_spin_lock(&NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
-        HG_QUEUE_PUSH_TAIL(&NA_SM_CLASS(na_class)->unexpected_op_queue,
             na_sm_op_id, entry);
+        hg_thread_spin_unlock(
+            &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
-        hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
     }
 
 done:
@@ -3357,10 +3403,12 @@
     /* Expected messages must always be pre-posted, therefore a message should
      * never arrive before that call returns (not completes), simply add
      * op_id to queue */
+    hg_thread_spin_lock(
+        &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
+    HG_QUEUE_PUSH_TAIL(&NA_SM_PRIVATE_DATA(na_class)->expected_op_queue,
+        na_sm_op_id, entry);
+    hg_thread_spin_unlock(
+        &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->expected_op_queue_lock);
-    HG_QUEUE_PUSH_TAIL(&NA_SM_CLASS(na_class)->expected_op_queue, na_sm_op_id,
-        entry);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->expected_op_queue_lock);
 
 done:
     if (ret != NA_SUCCESS) {
@@ -3468,7 +3516,7 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static na_size_t
-static NA_INLINE na_size_t
 na_sm_mem_handle_get_serialize_size(na_class_t NA_UNUSED *na_class,
     na_mem_handle_t mem_handle)
 {
@@ -3717,8 +3765,8 @@
     }
 
     /* Notify local completion */
+    if (!NA_SM_PRIVATE_DATA(na_class)->no_wait
+        && (hg_event_set(NA_SM_PRIVATE_DATA(na_class)->self_addr->local_notify)
-    if (!NA_SM_CLASS(na_class)->no_wait
-        && (hg_event_set(NA_SM_CLASS(na_class)->self_addr->local_notify)
         != HG_UTIL_SUCCESS)) {
         NA_LOG_ERROR("Could not signal local completion");
         ret = NA_PROTOCOL_ERROR;
@@ -3875,8 +3923,8 @@
     }
 
     /* Notify local completion */
+    if (!NA_SM_PRIVATE_DATA(na_class)->no_wait
+        && (hg_event_set(NA_SM_PRIVATE_DATA(na_class)->self_addr->local_notify)
-    if (!NA_SM_CLASS(na_class)->no_wait
-        && (hg_event_set(NA_SM_CLASS(na_class)->self_addr->local_notify)
         != HG_UTIL_SUCCESS)) {
         NA_LOG_ERROR("Could not signal local completion");
         ret = NA_PROTOCOL_ERROR;
@@ -3891,12 +3939,12 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static int
-static NA_INLINE int
 na_sm_poll_get_fd(na_class_t *na_class, na_context_t NA_UNUSED *context)
 {
     int fd;
 
+    fd = hg_poll_get_fd(NA_SM_PRIVATE_DATA(na_class)->poll_set);
-    fd = hg_poll_get_fd(NA_SM_CLASS(na_class)->poll_set);
     if (fd == HG_UTIL_FAIL) {
         NA_LOG_ERROR("Could not get poll fd from poll set");
     }
@@ -3905,22 +3953,22 @@
 }
 
 /*---------------------------------------------------------------------------*/
+static na_bool_t
-static NA_INLINE na_bool_t
 na_sm_poll_try_wait(na_class_t *na_class, na_context_t NA_UNUSED *context)
 {
     struct na_sm_addr *na_sm_addr;
     na_bool_t ret = NA_TRUE;
 
     /* Check whether something is in one of the ring buffers */
+    hg_thread_spin_lock(&NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
+    HG_QUEUE_FOREACH(na_sm_addr, &NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue,
-    hg_thread_spin_lock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
-    HG_QUEUE_FOREACH(na_sm_addr, &NA_SM_CLASS(na_class)->poll_addr_queue,
         poll_entry) {
         if (!na_sm_ring_buf_is_empty(na_sm_addr->na_sm_recv_ring_buf)) {
             ret = NA_FALSE;
             break;
         }
     }
+    hg_thread_spin_unlock(&NA_SM_PRIVATE_DATA(na_class)->poll_addr_queue_lock);
-    hg_thread_spin_unlock(&NA_SM_CLASS(na_class)->poll_addr_queue_lock);
 
     return ret;
 }
@@ -3940,7 +3988,7 @@
         if (timeout)
             hg_time_get_current(&t1);
 
+        if (hg_poll_wait(NA_SM_PRIVATE_DATA(na_class)->poll_set,
-        if (hg_poll_wait(NA_SM_CLASS(na_class)->poll_set,
             (unsigned int) (remaining * 1000.0), &progressed) != HG_UTIL_SUCCESS) {
             NA_LOG_ERROR("hg_poll_wait() failed");
             ret = NA_PROTOCOL_ERROR;
@@ -3986,17 +4034,17 @@
 
             /* Must remove op_id from unexpected op_id queue */
             hg_thread_spin_lock(
+                &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
-                &NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
             HG_QUEUE_FOREACH(na_sm_var_op_id,
+                &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue, entry) {
-                &NA_SM_CLASS(na_class)->unexpected_op_queue, entry) {
                 if (na_sm_var_op_id == na_sm_op_id) {
+                    HG_QUEUE_REMOVE(&NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue,
-                    HG_QUEUE_REMOVE(&NA_SM_CLASS(na_class)->unexpected_op_queue,
                         na_sm_var_op_id, na_sm_op_id, entry);
                     break;
                 }
             }
             hg_thread_spin_unlock(
+                &NA_SM_PRIVATE_DATA(na_class)->unexpected_op_queue_lock);
-                &NA_SM_CLASS(na_class)->unexpected_op_queue_lock);
 
             /* Cancel op id */
             if (na_sm_var_op_id == na_sm_op_id) {
@@ -4016,17 +4064,18 @@
             struct na_sm_op_id *na_sm_var_op_id = NULL;
 
             /* Must remove op_id from unexpected op_id queue */
+            hg_thread_spin_lock(
+                &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
-            hg_thread_spin_lock(&NA_SM_CLASS(na_class)->expected_op_queue_lock);
             HG_QUEUE_FOREACH(na_sm_var_op_id,
+                &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue, entry) {
-                &NA_SM_CLASS(na_class)->expected_op_queue, entry) {
                 if (na_sm_var_op_id == na_sm_op_id) {
+                    HG_QUEUE_REMOVE(&NA_SM_PRIVATE_DATA(na_class)->expected_op_queue,
-                    HG_QUEUE_REMOVE(&NA_SM_CLASS(na_class)->expected_op_queue,
                         na_sm_var_op_id, na_sm_op_id, entry);
                     break;
                 }
             }
             hg_thread_spin_unlock(
+                &NA_SM_PRIVATE_DATA(na_class)->expected_op_queue_lock);
-                &NA_SM_CLASS(na_class)->expected_op_queue_lock);
 
             /* Cancel op id */
             if (na_sm_var_op_id == na_sm_op_id) {
--- b/src/na/na_types.h
+++ /dev/null
@@ -1,125 +0,0 @@
-/*
- * Copyright (C) 2013-2018 Argonne National Laboratory, Department of Energy,
- *                    UChicago Argonne, LLC and The HDF Group.
- * All rights reserved.
- *
- * The full copyright notice, including terms governing use, modification,
- * and redistribution, is contained in the COPYING file that can be
- * found at the root of the source code distribution tree.
- */
-
-#ifndef NA_TYPES_H
-#define NA_TYPES_H
-
-#include "na_config.h"
-
-#include <limits.h>
-
-/*************************************/
-/* Public Type and Struct Definition */
-/*************************************/
-
-typedef struct na_class na_class_t;     /* Opaque NA class */
-typedef struct na_context na_context_t; /* Opaque NA execution context */
-typedef void *na_addr_t;                /* Abstract NA address */
-typedef na_uint64_t na_size_t;          /* Size */
-typedef na_uint32_t na_tag_t;           /* Tag */
-typedef void *na_op_id_t;               /* Abstract operation id */
-
-typedef void *na_mem_handle_t;          /* Abstract memory handle */
-typedef na_uint64_t na_offset_t;        /* Offset */
-
-/* Progress mode */
-typedef enum na_progress_mode {
-    NA_DEFAULT,     /*!< blocking progress, depending on timeout value */
-    NA_NO_BLOCK     /*!< no blocking progress, independent of timeout value */
-} na_progress_mode_t;
-
-/* Init info */
-struct na_init_info {
-    na_progress_mode_t progress_mode;   /* Progress mode */
-    na_uint8_t max_contexts;            /* Max contexts */
-    const char *auth_key;               /* Authorization key */
-};
-
-/* Segment */
-struct na_segment {
-    na_ptr_t address;   /* Address of the segment */
-    na_size_t size;     /* Size of the segment in bytes */
-};
-
-/* Error return codes:
- * Functions return 0 for success or NA_XXX_ERROR for failure */
-typedef enum na_return {
-    NA_SUCCESS,             /*!< operation succeeded */
-    NA_TIMEOUT,             /*!< reached timeout */
-    NA_INVALID_PARAM,       /*!< invalid parameter */
-    NA_SIZE_ERROR,          /*!< message size error */
-    NA_ALIGNMENT_ERROR,     /*!< alignment error */
-    NA_PERMISSION_ERROR,    /*!< read/write permission error */
-    NA_NOMEM_ERROR,         /*!< no memory error */
-    NA_PROTOCOL_ERROR,      /*!< unknown error reported from the protocol layer */
-    NA_CANCELED,            /*!< operation was canceled */
-    NA_ADDRINUSE_ERROR      /*!< address already in use */
-} na_return_t;
-
-/* Callback operation type */
-typedef enum na_cb_type {
-    NA_CB_LOOKUP,           /*!< lookup callback */
-    NA_CB_SEND_UNEXPECTED,  /*!< unexpected send callback */
-    NA_CB_RECV_UNEXPECTED,  /*!< unexpected recv callback */
-    NA_CB_SEND_EXPECTED,    /*!< expected send callback */
-    NA_CB_RECV_EXPECTED,    /*!< expected recv callback */
-    NA_CB_PUT,              /*!< put callback */
-    NA_CB_GET               /*!< get callback */
-} na_cb_type_t;
-
-/* Callback info structs */
-struct na_cb_info_lookup {
-    na_addr_t addr;
-};
-
-struct na_cb_info_recv_unexpected {
-    na_size_t actual_buf_size;
-    na_addr_t source;
-    na_tag_t  tag;
-};
-
-/* Callback info struct */
-struct na_cb_info {
-    void *arg;          /* User data */
-    na_return_t ret;    /* Return value */
-    na_cb_type_t type;  /* Callback type */
-    union {             /* Union of callback info structures */
-        struct na_cb_info_lookup lookup;
-        struct na_cb_info_recv_unexpected recv_unexpected;
-    } info;
-};
-
-/* Callback type */
-typedef int (*na_cb_t)(const struct na_cb_info *callback_info);
-
-/*****************/
-/* Public Macros */
-/*****************/
-
-/* Constant values */
-#define NA_ADDR_NULL        ((na_addr_t)0)
-#define NA_OP_ID_NULL       ((na_op_id_t)0)
-#define NA_OP_ID_IGNORE     ((na_op_id_t *)1)
-#define NA_MEM_HANDLE_NULL  ((na_mem_handle_t)0)
-
-/* Max timeout */
-#define NA_MAX_IDLE_TIME    (3600*1000)
-
-/* Tag upper bound
- * \remark This is not the user tag limit but only the limit imposed by the type */
-#define NA_TAG_UB           UINT_MAX
-
-/* The memory attributes associated with the memory handle
- * can be defined as read only, write only or read/write */
-#define NA_MEM_READ_ONLY    0x01
-#define NA_MEM_WRITE_ONLY   0x02
-#define NA_MEM_READWRITE    0x03
-
-#endif /* NA_TYPES_H */
--- b/src/util/CMakeLists.txt
+++ a/src/util/CMakeLists.txt
@@ -136,13 +136,9 @@
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_log.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_mem.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_poll.c
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_request.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread.c
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_condition.c
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_mutex.c
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_pool.c
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_request.c
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_rwlock.c
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_spin.c
 )
 
 #----------------------------------------------------------------------------
@@ -188,7 +184,6 @@
 # Specify project header files to be installed
 #-----------------------------------------------------------------------------
 set(MERCURY_HEADERS
-  ${CMAKE_CURRENT_BINARY_DIR}/mercury_util_config.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_atomic.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_atomic_queue.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_event.h
@@ -200,14 +195,14 @@
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_poll.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_queue.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_request.h
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_condition.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_condition.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_mutex.h
+  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_rwlock.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_pool.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_rwlock.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_thread_spin.h
   ${CMAKE_CURRENT_SOURCE_DIR}/mercury_time.h
+  ${CMAKE_CURRENT_BINARY_DIR}/mercury_util_config.h
-  ${CMAKE_CURRENT_SOURCE_DIR}/mercury_util_error.h
 )
 
 #-----------------------------------------------------------------------------
--- b/src/util/mercury_atomic.h
+++ a/src/util/mercury_atomic.h
@@ -14,32 +14,32 @@
 #include "mercury_util_config.h"
 
 #if defined(_WIN32)
+  #include <windows.h>
+  typedef struct { volatile LONG value; } hg_atomic_int32_t;
+  typedef struct { volatile LONGLONG value; } hg_atomic_int64_t;
+  #define HG_ATOMIC_VAR_INIT(x) { (x) }
-# include <windows.h>
-typedef struct { volatile LONG value; } hg_atomic_int32_t;
-typedef struct { volatile LONGLONG value; } hg_atomic_int64_t;
-# define HG_ATOMIC_VAR_INIT(x) { (x) }
 #elif defined(HG_UTIL_HAS_OPA_PRIMITIVES_H)
+  #include <opa_primitives.h>
+  typedef OPA_int_t hg_atomic_int32_t;
+  typedef OPA_ptr_t hg_atomic_int64_t; /* OPA has only limited 64-bit support */
+  #define HG_ATOMIC_VAR_INIT(x) OPA_PTR_T_INITIALIZER(x)
-# include <opa_primitives.h>
-typedef OPA_int_t hg_atomic_int32_t;
-typedef OPA_ptr_t hg_atomic_int64_t; /* OPA has only limited 64-bit support */
-# define HG_ATOMIC_VAR_INIT(x) OPA_PTR_T_INITIALIZER(x)
 #elif defined(HG_UTIL_HAS_STDATOMIC_H)
+  #include <stdatomic.h>
+#ifdef __INTEL_COMPILER
+  typedef atomic_int hg_atomic_int32_t;
+  typedef atomic_llong hg_atomic_int64_t;
+#else
+  typedef _Atomic hg_util_int32_t hg_atomic_int32_t;
+  typedef _Atomic hg_util_int64_t hg_atomic_int64_t;
+#endif
+  #define HG_ATOMIC_VAR_INIT(x) ATOMIC_VAR_INIT(x)
-# include <stdatomic.h>
-# ifdef __INTEL_COMPILER
-typedef atomic_int hg_atomic_int32_t;
-typedef atomic_llong hg_atomic_int64_t;
-# else
-typedef _Atomic hg_util_int32_t hg_atomic_int32_t;
-typedef _Atomic hg_util_int64_t hg_atomic_int64_t;
-# endif
-# define HG_ATOMIC_VAR_INIT(x) ATOMIC_VAR_INIT(x)
 #elif defined(__APPLE__)
+  #include <libkern/OSAtomic.h>
+  typedef struct { volatile hg_util_int32_t value; } hg_atomic_int32_t;
+  typedef struct { volatile hg_util_int64_t value; } hg_atomic_int64_t;
+  #define HG_ATOMIC_VAR_INIT(x) { (x) }
-# include <libkern/OSAtomic.h>
-typedef struct { volatile hg_util_int32_t value; } hg_atomic_int32_t;
-typedef struct { volatile hg_util_int64_t value; } hg_atomic_int64_t;
-# define HG_ATOMIC_VAR_INIT(x) { (x) }
 #else
+  #error "Not supported on this platform."
-# error "Not supported on this platform."
 #endif
 
 #ifdef __cplusplus
--- b/src/util/mercury_atomic_queue.h
+++ a/src/util/mercury_atomic_queue.h
@@ -69,11 +69,11 @@
 #define HG_ATOMIC_QUEUE_ELT_SIZE sizeof(hg_atomic_int64_t)
 
 #ifndef cpu_spinwait
+#if defined(__x86_64__) || defined(__amd64__)
+#define cpu_spinwait() asm volatile("pause\n": : :"memory");
+#else
+#define cpu_spinwait();
+#endif
-# if defined(__x86_64__) || defined(__amd64__)
-#  define cpu_spinwait() asm volatile("pause\n": : :"memory");
-# else
-#  define cpu_spinwait();
-# endif
 #endif
 
 /*********************/
--- b/src/util/mercury_event.c
+++ a/src/util/mercury_event.c
@@ -9,6 +9,26 @@
  */
 
 #include "mercury_event.h"
+#include "mercury_util_error.h"
+
+#ifdef _WIN32
+
+#else
+#include <errno.h>
+#include <string.h>
+#include <unistd.h>
+#if defined(HG_UTIL_HAS_SYSEVENTFD_H)
+#include <sys/eventfd.h>
+#ifndef HG_UTIL_HAS_EVENTFD_T
+typedef uint64_t eventfd_t;
+#endif
+#elif defined(HG_UTIL_HAS_SYSEVENT_H)
+#include <sys/event.h>
+/* User-defined ident */
+#define HG_EVENT_IDENT 42
+#endif
+
+#endif
 
 /*---------------------------------------------------------------------------*/
 int
@@ -69,3 +89,97 @@
 done:
     return ret;
 }
+
+/*---------------------------------------------------------------------------*/
+int
+hg_event_set(int fd)
+{
+    int ret = HG_UTIL_SUCCESS;
+#if defined(_WIN32)
+
+#elif defined(HG_UTIL_HAS_SYSEVENTFD_H)
+    eventfd_t count = 1;
+
+#ifdef HG_UTIL_HAS_EVENTFD_T
+    if (eventfd_write(fd, count) == -1) {
+#else
+    ssize_t s;
+
+    s = write(fd, &count, sizeof(eventfd_t));
+    if (s != sizeof(eventfd_t)) {
+#endif
+        if (errno == EAGAIN)
+            goto done;
+        HG_UTIL_LOG_ERROR("write() failed (%s)", strerror(errno));
+        ret = HG_UTIL_FAIL;
+        goto done;
+    }
+#elif defined(HG_UTIL_HAS_SYSEVENT_H)
+    struct kevent kev;
+    struct timespec timeout = {0, 0};
+
+    EV_SET(&kev, HG_EVENT_IDENT, EVFILT_USER, 0, NOTE_TRIGGER, 0, NULL);
+
+    /* Trigger user-defined event */
+    if (kevent(fd, &kev, 1, NULL, 0, &timeout) == -1) {
+        HG_UTIL_LOG_ERROR("kevent() failed (%s)", strerror(errno));
+        ret = HG_UTIL_FAIL;
+        goto done;
+    }
+#else
+
+#endif
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+int
+hg_event_get(int fd, hg_util_bool_t *signaled)
+{
+    int ret = HG_UTIL_SUCCESS;
+    hg_util_bool_t event_signal = HG_UTIL_FALSE;
+#if defined(_WIN32)
+
+#elif defined(HG_UTIL_HAS_SYSEVENTFD_H)
+    eventfd_t count = 0;
+
+#ifdef HG_UTIL_HAS_EVENTFD_T
+    if (eventfd_read(fd, &count) == -1) {
+#else
+    ssize_t s;
+
+    s = read(fd, &count, sizeof(eventfd_t));
+    if (s != sizeof(eventfd_t)) {
+#endif
+        if (errno == EAGAIN)
+            goto done;
+        HG_UTIL_LOG_ERROR("read() failed (%s)", strerror(errno));
+        ret = HG_UTIL_FAIL;
+        goto done;
+    }
+    event_signal = HG_UTIL_TRUE;
+#elif defined(HG_UTIL_HAS_SYSEVENT_H)
+    struct kevent kev;
+    int nfds;
+    struct timespec timeout = {0, 0};
+
+    /* Check user-defined event */
+    nfds = kevent(fd, NULL, 0, &kev, 1, &timeout);
+    if (nfds == -1) {
+        HG_UTIL_LOG_ERROR("kevent() failed (%s)", strerror(errno));
+        ret = HG_UTIL_FAIL;
+        goto done;
+    }
+    if (nfds > 0 && kev.ident == HG_EVENT_IDENT)
+        event_signal = HG_UTIL_TRUE;
+#else
+
+#endif
+
+    if (signaled) *signaled = event_signal;
+
+done:
+    return ret;
+}
--- b/src/util/mercury_event.h
+++ a/src/util/mercury_event.h
@@ -12,25 +12,6 @@
 #define MERCURY_EVENT_H
 
 #include "mercury_util_config.h"
-#include "mercury_util_error.h"
-
-#ifdef _WIN32
-
-#else
-# include <errno.h>
-# include <string.h>
-# include <unistd.h>
-# if defined(HG_UTIL_HAS_SYSEVENTFD_H)
-#  include <sys/eventfd.h>
-#  ifndef HG_UTIL_HAS_EVENTFD_T
-typedef uint64_t eventfd_t;
-#  endif
-# elif defined(HG_UTIL_HAS_SYSEVENT_H)
-# include <sys/event.h>
-/* User-defined ident */
-# define HG_EVENT_IDENT 42
-# endif
-#endif
 
 /**
  * Purpose: define an event object that can be used as an event
@@ -66,7 +47,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_event_set(int fd);
 
 /**
@@ -77,120 +58,9 @@
  *
  * \return Non-negative on success or negative on failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_event_get(int fd, hg_util_bool_t *notified);
 
-/*---------------------------------------------------------------------------*/
-#if defined(_WIN32)
-/* TODO */
-#elif defined(HG_UTIL_HAS_SYSEVENTFD_H)
-static HG_UTIL_INLINE int
-hg_event_set(int fd)
-{
-    int ret = HG_UTIL_SUCCESS;
-    eventfd_t count = 1;
-
-#ifdef HG_UTIL_HAS_EVENTFD_T
-    if (eventfd_write(fd, count) == -1) {
-#else
-    ssize_t s;
-
-    s = write(fd, &count, sizeof(eventfd_t));
-    if (s != sizeof(eventfd_t)) {
-#endif
-        if (errno == EAGAIN)
-            goto done;
-        HG_UTIL_LOG_ERROR("write() failed (%s)", strerror(errno));
-        ret = HG_UTIL_FAIL;
-        goto done;
-    }
-
-done:
-    return ret;
-}
-#elif defined(HG_UTIL_HAS_SYSEVENT_H)
-static HG_UTIL_INLINE int
-hg_event_set(int fd)
-{
-    int ret = HG_UTIL_SUCCESS;
-    struct kevent kev;
-    struct timespec timeout = {0, 0};
-
-    EV_SET(&kev, HG_EVENT_IDENT, EVFILT_USER, 0, NOTE_TRIGGER, 0, NULL);
-
-    /* Trigger user-defined event */
-    if (kevent(fd, &kev, 1, NULL, 0, &timeout) == -1) {
-        HG_UTIL_LOG_ERROR("kevent() failed (%s)", strerror(errno));
-        ret = HG_UTIL_FAIL;
-        goto done;
-    }
-
-done:
-    return ret;
-}
-#else
-# error "Not supported on this platform."
-#endif
-
-/*---------------------------------------------------------------------------*/
-#if defined(_WIN32)
-#elif defined(HG_UTIL_HAS_SYSEVENTFD_H)
-static HG_UTIL_INLINE int
-hg_event_get(int fd, hg_util_bool_t *signaled)
-{
-    int ret = HG_UTIL_SUCCESS;
-    hg_util_bool_t event_signal = HG_UTIL_FALSE;
-    eventfd_t count = 0;
-
-#ifdef HG_UTIL_HAS_EVENTFD_T
-    if (eventfd_read(fd, &count) == -1) {
-#else
-    ssize_t s;
-
-    s = read(fd, &count, sizeof(eventfd_t));
-    if (s != sizeof(eventfd_t)) {
-#endif
-        if (errno == EAGAIN)
-            goto done;
-        HG_UTIL_LOG_ERROR("read() failed (%s)", strerror(errno));
-        ret = HG_UTIL_FAIL;
-        goto done;
-    }
-    event_signal = HG_UTIL_TRUE;
-
-done:
-    if (signaled && ret != HG_UTIL_FAIL)
-        *signaled = event_signal;
-    return ret;
-}
-#elif defined(HG_UTIL_HAS_SYSEVENT_H)
-static HG_UTIL_INLINE int
-hg_event_get(int fd, hg_util_bool_t *signaled)
-{
-    int ret = HG_UTIL_SUCCESS;
-    hg_util_bool_t event_signal = HG_UTIL_FALSE;
-    struct kevent kev;
-    int nfds;
-    struct timespec timeout = {0, 0};
-
-    /* Check user-defined event */
-    nfds = kevent(fd, NULL, 0, &kev, 1, &timeout);
-    if (nfds == -1) {
-        HG_UTIL_LOG_ERROR("kevent() failed (%s)", strerror(errno));
-        ret = HG_UTIL_FAIL;
-        goto done;
-    }
-    if (nfds > 0 && kev.ident == HG_EVENT_IDENT)
-        event_signal = HG_UTIL_TRUE;
-
-    if (signaled) *signaled = event_signal;
-
-done:
-    return ret;
-}
-#else
-#endif
-
 #ifdef __cplusplus
 }
 #endif
--- b/src/util/mercury_mem.c
+++ a/src/util/mercury_mem.c
@@ -12,15 +12,15 @@
 #include "mercury_util_error.h"
 
 #ifdef _WIN32
+  #include <windows.h>
-# include <windows.h>
 #else
+  #include <sys/mman.h>
+  #include <unistd.h>
+  #include <sys/types.h>
+  #include <sys/stat.h>        /* For mode constants */
+  #include <fcntl.h>           /* For O_* constants */
+  #include <string.h>
+  #include <errno.h>
-# include <sys/mman.h>
-# include <unistd.h>
-# include <sys/types.h>
-# include <sys/stat.h>        /* For mode constants */
-# include <fcntl.h>           /* For O_* constants */
-# include <string.h>
-# include <errno.h>
 #endif
 #include <stdlib.h>
 
--- b/src/util/mercury_mem.h
+++ a/src/util/mercury_mem.h
@@ -59,7 +59,7 @@
  *
  * \return a pointer to the mapped memory region, or NULL in case of failure
  */
+void *
-HG_UTIL_EXPORT void *
 hg_mem_shm_map(const char *name, size_t size, hg_util_bool_t create);
 
 /**
@@ -71,7 +71,7 @@
  *
  * \return non-negative on success, or negative in case of failure
  */
+int
-HG_UTIL_EXPORT int
 hg_mem_shm_unmap(const char *name, void *mem_ptr, size_t size);
 
 #ifdef __cplusplus
--- b/src/util/mercury_request.c
+++ a/src/util/mercury_request.c
@@ -14,6 +14,8 @@
 #include "mercury_time.h"
 #include "mercury_util_error.h"
 
+#include "mercury_atomic.h"
+
 #include <stdlib.h>
 
 struct hg_request_class {
@@ -25,6 +27,12 @@
     hg_thread_cond_t progress_cond;
 };
 
+struct hg_request {
+    void *data;
+    hg_atomic_int32_t completed;
+    hg_request_class_t *request_class;
+};
+
 /*---------------------------------------------------------------------------*/
 static HG_UTIL_INLINE hg_util_bool_t
 hg_request_check(hg_request_t *request)
@@ -119,6 +127,28 @@
 }
 
 /*---------------------------------------------------------------------------*/
+int
+hg_request_reset(hg_request_t *request)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+    hg_atomic_set32(&request->completed, HG_UTIL_FALSE);
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+int
+hg_request_complete(hg_request_t *request)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+    hg_atomic_incr32(&request->completed);
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
 /*
  * lock(progress_mutex)
  * while (!completed) {
@@ -209,3 +239,45 @@
 
     return ret;
 }
+
+/*---------------------------------------------------------------------------*/
+int
+hg_request_waitall(int count, hg_request_t *request[], unsigned int timeout,
+        unsigned int *flag)
+{
+    /* TODO */
+    int i;
+    for (i = 0; i < count; i++)
+        hg_request_wait(request[i], timeout, flag);
+    return HG_UTIL_SUCCESS;
+}
+
+/*---------------------------------------------------------------------------*/
+//hg_return_t
+//hg_request_complete_cb(const struct hg_cb_info *cb_info)
+//{
+//    int ret = hg_request_complete(cb_info->arg);
+//    return ret == HG_UTIL_SUCCESS ? HG_SUCCESS : HG_OTHER_ERROR;
+//}
+
+/*---------------------------------------------------------------------------*/
+int
+hg_request_set_data(hg_request_t *request, void *data)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+    request->data = data;
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+void *
+hg_request_get_data(hg_request_t *request)
+{
+    void *ret = NULL;
+
+    ret = request->data;
+
+    return ret;
+}
--- b/src/util/mercury_request.h
+++ a/src/util/mercury_request.h
@@ -12,7 +12,6 @@
 #define MERCURY_REQUEST_H
 
 #include "mercury_util_config.h"
-#include "mercury_atomic.h"
 
 /**
  * Purpose: define a request emulation library on top of the callback model
@@ -25,12 +24,6 @@
 typedef struct hg_request_class  hg_request_class_t;  /* Opaque request class */
 typedef struct hg_request hg_request_t; /* Opaque request object */
 
-struct hg_request {
-    void *data;
-    hg_atomic_int32_t completed;
-    hg_request_class_t *request_class;
-};
-
 /**
  * Progress callback, arg can be used to pass extra parameters required by
  * underlying API.
@@ -114,7 +107,7 @@
  *
  * \return Pointer to request or NULL in case of failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_request_reset(hg_request_t *request);
 
 /**
@@ -125,7 +118,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_request_complete(hg_request_t *request);
 
 /**
@@ -151,7 +144,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_request_waitall(int count, hg_request_t *request[],  unsigned int timeout,
         unsigned int *flag);
 
@@ -174,7 +167,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_request_set_data(hg_request_t *request, void *data);
 
 /**
@@ -184,7 +177,7 @@
  *
  * \return Pointer to data or NULL if nothing was attached by user
  */
+HG_UTIL_EXPORT void *
-static HG_UTIL_INLINE void *
 hg_request_get_data(hg_request_t *request);
 
 /**
@@ -198,70 +191,6 @@
 hg_request_cancel(hg_request_t *request);
  */
 
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE int
-hg_request_reset(hg_request_t *request)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-    hg_atomic_set32(&request->completed, HG_UTIL_FALSE);
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE int
-hg_request_complete(hg_request_t *request)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-    hg_atomic_incr32(&request->completed);
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE int
-hg_request_waitall(int count, hg_request_t *request[], unsigned int timeout,
-        unsigned int *flag)
-{
-    /* TODO */
-    int i;
-    for (i = 0; i < count; i++)
-        hg_request_wait(request[i], timeout, flag);
-    return HG_UTIL_SUCCESS;
-}
-
-/*---------------------------------------------------------------------------*/
-//hg_return_t
-//hg_request_complete_cb(const struct hg_cb_info *cb_info)
-//{
-//    int ret = hg_request_complete(cb_info->arg);
-//    return ret == HG_UTIL_SUCCESS ? HG_SUCCESS : HG_OTHER_ERROR;
-//}
-
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE int
-hg_request_set_data(hg_request_t *request, void *data)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-    request->data = data;
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE void *
-hg_request_get_data(hg_request_t *request)
-{
-    void *ret = NULL;
-
-    ret = request->data;
-
-    return ret;
-}
-
 #ifdef __cplusplus
 }
 #endif
--- b/src/util/mercury_thread.c
+++ a/src/util/mercury_thread.c
@@ -9,6 +9,7 @@
  */
 
 #include "mercury_thread.h"
+#include "mercury_util_error.h"
 
 /*---------------------------------------------------------------------------*/
 void
@@ -155,6 +156,42 @@
 }
 
 /*---------------------------------------------------------------------------*/
+void *
+hg_thread_getspecific(hg_thread_key_t key)
+{
+    void *ret;
+
+#ifdef _WIN32
+    ret = TlsGetValue(key);
+#else
+    ret = pthread_getspecific(key);
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+int
+hg_thread_setspecific(hg_thread_key_t key, const void *value)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#ifdef _WIN32
+    if (!TlsSetValue(key, (LPVOID) value)) {
+        HG_UTIL_LOG_ERROR("TlsSetValue() failed");
+        ret = HG_UTIL_FAIL;
+    }
+#else
+    if (pthread_setspecific(key, value)) {
+        HG_UTIL_LOG_ERROR("pthread_setspecific() failed");
+        ret = HG_UTIL_FAIL;
+    }
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
 int
 hg_thread_getaffinity(hg_thread_t thread, hg_cpu_set_t *cpu_mask)
 {
--- b/src/util/mercury_thread.h
+++ a/src/util/mercury_thread.h
@@ -12,38 +12,37 @@
 #define MERCURY_THREAD_H
 
 #if !defined(_WIN32) && !defined(_GNU_SOURCE)
+  #define _GNU_SOURCE
-# define _GNU_SOURCE
 #endif
 #include "mercury_util_config.h"
-#include "mercury_util_error.h"
 
 #ifdef _WIN32
+  #include <windows.h>
+  typedef HANDLE hg_thread_t;
+  typedef LPTHREAD_START_ROUTINE hg_thread_func_t;
+  typedef DWORD hg_thread_ret_t;
+  #define HG_THREAD_RETURN_TYPE hg_thread_ret_t WINAPI
+  typedef DWORD hg_thread_key_t;
+  typedef DWORD_PTR hg_cpu_set_t;
-# include <windows.h>
-typedef HANDLE hg_thread_t;
-typedef LPTHREAD_START_ROUTINE hg_thread_func_t;
-typedef DWORD hg_thread_ret_t;
-# define HG_THREAD_RETURN_TYPE hg_thread_ret_t WINAPI
-typedef DWORD hg_thread_key_t;
-typedef DWORD_PTR hg_cpu_set_t;
 #else
+  #include <pthread.h>
+  typedef pthread_t hg_thread_t;
+  typedef void *(*hg_thread_func_t)(void *);
+  typedef void *hg_thread_ret_t;
+  #define HG_THREAD_RETURN_TYPE hg_thread_ret_t
+  typedef pthread_key_t hg_thread_key_t;
+#ifdef __APPLE__
+  /* Size definition for CPU sets.  */
+  # define HG_CPU_SETSIZE  1024
+  # define HG_NCPUBITS     (8 * sizeof (hg_cpu_mask_t))
+  /* Type for array elements in 'cpu_set_t'.  */
+  typedef hg_util_uint64_t hg_cpu_mask_t;
+  typedef struct {
+      hg_cpu_mask_t bits[HG_CPU_SETSIZE / HG_NCPUBITS];
+  } hg_cpu_set_t;
+#else
+  typedef cpu_set_t hg_cpu_set_t;
+#endif
-# include <pthread.h>
-typedef pthread_t hg_thread_t;
-typedef void *(*hg_thread_func_t)(void *);
-typedef void *hg_thread_ret_t;
-# define HG_THREAD_RETURN_TYPE hg_thread_ret_t
-typedef pthread_key_t hg_thread_key_t;
-# ifdef __APPLE__
-/* Size definition for CPU sets.  */
-#  define HG_CPU_SETSIZE  1024
-#  define HG_NCPUBITS     (8 * sizeof (hg_cpu_mask_t))
-/* Type for array elements in 'cpu_set_t'.  */
-typedef hg_util_uint64_t hg_cpu_mask_t;
-typedef struct {
-    hg_cpu_mask_t bits[HG_CPU_SETSIZE / HG_NCPUBITS];
-} hg_cpu_set_t;
-# else
-typedef cpu_set_t hg_cpu_set_t;
-# endif
 #endif
 
 #ifdef __cplusplus
@@ -136,7 +135,7 @@
  *
  * \return Pointer to data associated to the key
  */
+HG_UTIL_EXPORT void *
-static HG_UTIL_INLINE void *
 hg_thread_getspecific(hg_thread_key_t key);
 
 /**
@@ -147,7 +146,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_thread_setspecific(hg_thread_key_t key, const void *value);
 
 /**
@@ -172,42 +171,6 @@
 HG_UTIL_EXPORT int
 hg_thread_setaffinity(hg_thread_t thread, const hg_cpu_set_t *cpu_mask);
 
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE void *
-hg_thread_getspecific(hg_thread_key_t key)
-{
-    void *ret;
-
-#ifdef _WIN32
-    ret = TlsGetValue(key);
-#else
-    ret = pthread_getspecific(key);
-#endif
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE int
-hg_thread_setspecific(hg_thread_key_t key, const void *value)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#ifdef _WIN32
-    if (!TlsSetValue(key, (LPVOID) value)) {
-        HG_UTIL_LOG_ERROR("TlsSetValue() failed");
-        ret = HG_UTIL_FAIL;
-    }
-#else
-    if (pthread_setspecific(key, value)) {
-        HG_UTIL_LOG_ERROR("pthread_setspecific() failed");
-        ret = HG_UTIL_FAIL;
-    }
-#endif
-
-    return ret;
-}
-
 #ifdef __cplusplus
 }
 #endif
--- b/src/util/mercury_thread_condition.c
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Copyright (C) 2013-2018 Argonne National Laboratory, Department of Energy,
- *                    UChicago Argonne, LLC and The HDF Group.
- * All rights reserved.
- *
- * The full copyright notice, including terms governing use, modification,
- * and redistribution, is contained in the COPYING file that can be
- * found at the root of the source code distribution tree.
- */
-
-#include "mercury_thread_condition.h"
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_cond_init(hg_thread_cond_t *cond)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#ifdef _WIN32
-    InitializeConditionVariable(cond);
-#else
-    pthread_condattr_t attr;
-
-    pthread_condattr_init(&attr);
-# if defined(HG_UTIL_HAS_PTHREAD_CONDATTR_SETCLOCK) && defined(HG_UTIL_HAS_CLOCK_MONOTONIC)
-    /* Must set clock ID if using different clock */
-    pthread_condattr_setclock(&attr, CLOCK_MONOTONIC);
-# endif
-    if (pthread_cond_init(cond, &attr)) ret = HG_UTIL_FAIL;
-    pthread_condattr_destroy(&attr);
-#endif
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_cond_destroy(hg_thread_cond_t *cond)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#ifndef _WIN32
-    if (pthread_cond_destroy(cond)) ret = HG_UTIL_FAIL;
-#endif
-
-    return ret;
-}
--- b/src/util/mercury_thread_condition.h
+++ a/src/util/mercury_thread_condition.h
@@ -36,7 +36,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_cond_init(hg_thread_cond_t *cond);
 
 /**
@@ -46,7 +46,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_cond_destroy(hg_thread_cond_t *cond);
 
 /**
@@ -95,6 +95,42 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_UTIL_INLINE int
+hg_thread_cond_init(hg_thread_cond_t *cond)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#ifdef _WIN32
+    InitializeConditionVariable(cond);
+#else
+    pthread_condattr_t attr;
+
+    pthread_condattr_init(&attr);
+# if defined(HG_UTIL_HAS_PTHREAD_CONDATTR_SETCLOCK) && defined(HG_UTIL_HAS_CLOCK_MONOTONIC)
+    /* Must set clock ID if using different clock */
+    pthread_condattr_setclock(&attr, CLOCK_MONOTONIC);
+# endif
+    if (pthread_cond_init(cond, &attr)) ret = HG_UTIL_FAIL;
+    pthread_condattr_destroy(&attr);
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
+hg_thread_cond_destroy(hg_thread_cond_t *cond)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#ifndef _WIN32
+    if (pthread_cond_destroy(cond)) ret = HG_UTIL_FAIL;
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
 hg_thread_cond_signal(hg_thread_cond_t *cond)
 {
     int ret = HG_UTIL_SUCCESS;
--- b/src/util/mercury_thread_mutex.c
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Copyright (C) 2013-2018 Argonne National Laboratory, Department of Energy,
- *                    UChicago Argonne, LLC and The HDF Group.
- * All rights reserved.
- *
- * The full copyright notice, including terms governing use, modification,
- * and redistribution, is contained in the COPYING file that can be
- * found at the root of the source code distribution tree.
- */
-
-#include "mercury_thread_mutex.h"
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_mutex_init(hg_thread_mutex_t *mutex)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#ifdef _WIN32
-    InitializeCriticalSection(mutex);
-#else
-    pthread_mutexattr_t mutex_attr;
-
-    pthread_mutexattr_init(&mutex_attr);
-#ifdef HG_UTIL_HAS_PTHREAD_MUTEX_ADAPTIVE_NP
-    /* Set type to PTHREAD_MUTEX_ADAPTIVE_NP to improve performance */
-    pthread_mutexattr_settype(&mutex_attr, PTHREAD_MUTEX_ADAPTIVE_NP);
-#else
-    pthread_mutexattr_settype(&mutex_attr, PTHREAD_MUTEX_DEFAULT);
-#endif
-    if (pthread_mutex_init(mutex, &mutex_attr)) ret = HG_UTIL_FAIL;
-
-    pthread_mutexattr_destroy(&mutex_attr);
-#endif
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_mutex_destroy(hg_thread_mutex_t *mutex)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#ifdef _WIN32
-    DeleteCriticalSection(mutex);
-#else
-    if (pthread_mutex_destroy(mutex)) ret = HG_UTIL_FAIL;
-#endif
-
-    return ret;
-}
--- b/src/util/mercury_thread_mutex.h
+++ a/src/util/mercury_thread_mutex.h
@@ -34,7 +34,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_mutex_init(hg_thread_mutex_t *mutex);
 
 /**
@@ -44,7 +44,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_mutex_destroy(hg_thread_mutex_t *mutex);
 
 /**
@@ -79,6 +79,47 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_UTIL_INLINE int
+hg_thread_mutex_init(hg_thread_mutex_t *mutex)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#ifdef _WIN32
+    InitializeCriticalSection(mutex);
+#else
+    pthread_mutexattr_t mutex_attr;
+
+    pthread_mutexattr_init(&mutex_attr);
+#ifdef HG_UTIL_HAS_PTHREAD_MUTEX_ADAPTIVE_NP
+    /* Set type to PTHREAD_MUTEX_ADAPTIVE_NP to improve performance */
+    pthread_mutexattr_settype(&mutex_attr, PTHREAD_MUTEX_ADAPTIVE_NP);
+#else
+    pthread_mutexattr_settype(&mutex_attr, PTHREAD_MUTEX_DEFAULT);
+#endif
+    if (pthread_mutex_init(mutex, &mutex_attr)) ret = HG_UTIL_FAIL;
+
+    pthread_mutexattr_destroy(&mutex_attr);
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
+hg_thread_mutex_destroy(hg_thread_mutex_t *mutex)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#ifdef _WIN32
+    DeleteCriticalSection(mutex);
+#else
+    if (pthread_mutex_destroy(mutex)) ret = HG_UTIL_FAIL;
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
 hg_thread_mutex_lock(hg_thread_mutex_t *mutex)
 {
     int ret = HG_UTIL_SUCCESS;
--- b/src/util/mercury_thread_pool.c
+++ a/src/util/mercury_thread_pool.c
@@ -9,13 +9,19 @@
  */
 
 #include "mercury_thread_pool.h"
+#include "mercury_thread_condition.h"
+#include "mercury_util_error.h"
 
 #include <stdlib.h>
 
+struct hg_thread_pool {
+    unsigned int sleeping_worker_count;
-struct hg_thread_pool_private {
-    struct hg_thread_pool pool;
     unsigned int thread_count;
     hg_thread_t *threads;
+    HG_QUEUE_HEAD(hg_thread_work) queue;
+    int shutdown;
+    hg_thread_mutex_t mutex;
+    hg_thread_cond_t cond;
 };
 
 /**
@@ -64,37 +70,36 @@
 
 /*---------------------------------------------------------------------------*/
 int
+hg_thread_pool_init(unsigned int thread_count, hg_thread_pool_t **pool)
-hg_thread_pool_init(unsigned int thread_count, hg_thread_pool_t **pool_ptr)
 {
     int ret = HG_UTIL_SUCCESS;
+    hg_thread_pool_t *priv_pool = NULL;
-    struct hg_thread_pool_private *priv_pool = NULL;
     unsigned int i;
 
+    if (!pool) {
-    if (!pool_ptr) {
         HG_UTIL_LOG_ERROR("Cannot pass NULL pointer");
         ret = HG_UTIL_FAIL;
         goto done;
     }
 
+    priv_pool = (hg_thread_pool_t*) malloc(sizeof(hg_thread_pool_t));
-    priv_pool = (struct hg_thread_pool_private *) malloc(
-        sizeof(struct hg_thread_pool_private));
     if (!priv_pool) {
         HG_UTIL_LOG_ERROR("Could not allocate thread pool");
         ret = HG_UTIL_FAIL;
         goto done;
     }
+    priv_pool->sleeping_worker_count = 0;
-    priv_pool->pool.sleeping_worker_count = 0;
     priv_pool->thread_count = thread_count;
     priv_pool->threads = NULL;
+    HG_QUEUE_INIT(&priv_pool->queue);
+    priv_pool->shutdown = 0;
-    HG_QUEUE_INIT(&priv_pool->pool.queue);
-    priv_pool->pool.shutdown = 0;
 
+    if (hg_thread_mutex_init(&priv_pool->mutex) != HG_UTIL_SUCCESS) {
-    if (hg_thread_mutex_init(&priv_pool->pool.mutex) != HG_UTIL_SUCCESS) {
         HG_UTIL_LOG_ERROR("Could not initialize mutex");
         ret = HG_UTIL_FAIL;
         goto done;
     }
+    if (hg_thread_cond_init(&priv_pool->cond) != HG_UTIL_SUCCESS) {
-    if (hg_thread_cond_init(&priv_pool->pool.cond) != HG_UTIL_SUCCESS) {
         HG_UTIL_LOG_ERROR("Could not initialize thread condition");
         ret = HG_UTIL_FAIL;
         goto done;
@@ -117,12 +122,12 @@
         }
     }
 
+    *pool = priv_pool;
-    *pool_ptr = (struct hg_thread_pool *) priv_pool;
 
 done:
     if (ret != HG_UTIL_SUCCESS) {
         if (priv_pool) {
+            hg_thread_pool_destroy(priv_pool);
-            hg_thread_pool_destroy((struct hg_thread_pool *) priv_pool);
         }
         priv_pool = NULL;
     }
@@ -133,29 +138,27 @@
 int
 hg_thread_pool_destroy(hg_thread_pool_t *pool)
 {
-    struct hg_thread_pool_private *priv_pool =
-        (struct hg_thread_pool_private *) pool;
     int ret = HG_UTIL_SUCCESS;
     unsigned int i;
 
+    if (!pool) goto done;
-    if (!priv_pool) goto done;
 
+    if (pool->threads) {
+        hg_thread_mutex_lock(&pool->mutex);
-    if (priv_pool->threads) {
-        hg_thread_mutex_lock(&priv_pool->pool.mutex);
 
+        pool->shutdown = 1;
-        priv_pool->pool.shutdown = 1;
 
+        if (hg_thread_cond_broadcast(&pool->cond) != HG_UTIL_SUCCESS) {
-        if (hg_thread_cond_broadcast(&priv_pool->pool.cond) != HG_UTIL_SUCCESS) {
             HG_UTIL_LOG_ERROR("Could not broadcast condition signal");
             ret = HG_UTIL_FAIL;
         }
 
+        hg_thread_mutex_unlock(&pool->mutex);
-        hg_thread_mutex_unlock(&priv_pool->pool.mutex);
 
         if (ret != HG_UTIL_SUCCESS) goto done;
 
+        for(i = 0; i < pool->thread_count; i++) {
+            if (hg_thread_join(pool->threads[i]) != HG_UTIL_SUCCESS) {
-        for(i = 0; i < priv_pool->thread_count; i++) {
-            if (hg_thread_join(priv_pool->threads[i]) != HG_UTIL_SUCCESS) {
                 HG_UTIL_LOG_ERROR("Could not join thread");
                 ret = HG_UTIL_FAIL;
                 goto done;
@@ -163,21 +166,72 @@
         }
     }
 
+    free(pool->threads);
+    pool->threads = NULL;
-    free(priv_pool->threads);
-    priv_pool->threads = NULL;
 
+    if (hg_thread_mutex_destroy(&pool->mutex) != HG_UTIL_SUCCESS) {
-    if (hg_thread_mutex_destroy(&priv_pool->pool.mutex) != HG_UTIL_SUCCESS) {
         HG_UTIL_LOG_ERROR("Could not destroy mutex");
         ret = HG_UTIL_FAIL;
         goto done;
     }
+    if (hg_thread_cond_destroy(&pool->cond) != HG_UTIL_SUCCESS){
-    if (hg_thread_cond_destroy(&priv_pool->pool.cond) != HG_UTIL_SUCCESS){
         HG_UTIL_LOG_ERROR("Could not destroy thread condition");
         ret = HG_UTIL_FAIL;
         goto done;
     }
 
+    free(pool);
+
+done:
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+int
+hg_thread_pool_post(hg_thread_pool_t *pool, struct hg_thread_work *work)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+    if (!pool) {
+        HG_UTIL_LOG_ERROR("Thread pool not initialized");
+        ret = HG_UTIL_FAIL;
+        goto done;
+    }
+
+    if (!work) {
+        HG_UTIL_LOG_ERROR("Thread work cannot be NULL");
+        ret = HG_UTIL_FAIL;
+        goto done;
+    }
+
+    if (!work->func) {
+        HG_UTIL_LOG_ERROR("Function pointer cannot be NULL");
+        ret = HG_UTIL_FAIL;
+        goto done;
+    }
+
+    hg_thread_mutex_lock(&pool->mutex);
+
+    /* Are we shutting down ? */
+    if (pool->shutdown) {
+        HG_UTIL_LOG_ERROR("Pool is shutting down");
+        ret = HG_UTIL_FAIL;
+        goto unlock;
+    }
+
+    /* Add task to task queue */
+    HG_QUEUE_PUSH_TAIL(&pool->queue, work, entry);
+
+    /* Wake up sleeping worker */
+    if (pool->sleeping_worker_count) {
+        if (hg_thread_cond_signal(&pool->cond) != HG_UTIL_SUCCESS) {
+            HG_UTIL_LOG_ERROR("Cannot signal pool condition");
+            ret = HG_UTIL_FAIL;
+        }
+    }
+
+unlock:
+    hg_thread_mutex_unlock(&pool->mutex);
-    free(priv_pool);
 
 done:
     return ret;
--- b/src/util/mercury_thread_pool.h
+++ a/src/util/mercury_thread_pool.h
@@ -13,19 +13,9 @@
 
 #include "mercury_thread.h"
 #include "mercury_queue.h"
-#include "mercury_thread_condition.h"
-#include "mercury_util_error.h"
 
 typedef struct hg_thread_pool hg_thread_pool_t;
 
-struct hg_thread_pool {
-    unsigned int sleeping_worker_count;
-    HG_QUEUE_HEAD(hg_thread_work) queue;
-    int shutdown;
-    hg_thread_mutex_t mutex;
-    hg_thread_cond_t cond;
-};
-
 struct hg_thread_work {
     hg_thread_func_t func;
     void *args;
@@ -67,60 +57,9 @@
  *
  * \return Non-negative on success or negative on failure
  */
+HG_UTIL_EXPORT int
-static HG_UTIL_INLINE int
 hg_thread_pool_post(hg_thread_pool_t *pool, struct hg_thread_work *work);
 
-/*---------------------------------------------------------------------------*/
-static HG_UTIL_INLINE int
-hg_thread_pool_post(hg_thread_pool_t *pool, struct hg_thread_work *work)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-    if (!pool) {
-        HG_UTIL_LOG_ERROR("Thread pool not initialized");
-        ret = HG_UTIL_FAIL;
-        goto done;
-    }
-
-    if (!work) {
-        HG_UTIL_LOG_ERROR("Thread work cannot be NULL");
-        ret = HG_UTIL_FAIL;
-        goto done;
-    }
-
-    if (!work->func) {
-        HG_UTIL_LOG_ERROR("Function pointer cannot be NULL");
-        ret = HG_UTIL_FAIL;
-        goto done;
-    }
-
-    hg_thread_mutex_lock(&pool->mutex);
-
-    /* Are we shutting down ? */
-    if (pool->shutdown) {
-        HG_UTIL_LOG_ERROR("Pool is shutting down");
-        ret = HG_UTIL_FAIL;
-        goto unlock;
-    }
-
-    /* Add task to task queue */
-    HG_QUEUE_PUSH_TAIL(&pool->queue, work, entry);
-
-    /* Wake up sleeping worker */
-    if (pool->sleeping_worker_count) {
-        if (hg_thread_cond_signal(&pool->cond) != HG_UTIL_SUCCESS) {
-            HG_UTIL_LOG_ERROR("Cannot signal pool condition");
-            ret = HG_UTIL_FAIL;
-        }
-    }
-
-unlock:
-    hg_thread_mutex_unlock(&pool->mutex);
-
-done:
-    return ret;
-}
-
 #ifdef __cplusplus
 }
 #endif
--- b/src/util/mercury_thread_rwlock.c
+++ /dev/null
@@ -1,79 +0,0 @@
-/*
- * Copyright (C) 2013-2018 Argonne National Laboratory, Department of Energy,
- *                    UChicago Argonne, LLC and The HDF Group.
- * All rights reserved.
- *
- * The full copyright notice, including terms governing use, modification,
- * and redistribution, is contained in the COPYING file that can be
- * found at the root of the source code distribution tree.
- */
-
-/* Copyright (C) 2017 Intel Corporation
- * All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted for any purpose (including commercial purposes)
- * provided that the following conditions are met:
- *
- * 1. Redistributions of source code must retain the above copyright notice,
- *    this list of conditions, and the following disclaimer.
- *
- * 2. Redistributions in binary form must reproduce the above copyright notice,
- *    this list of conditions, and the following disclaimer in the
- *    documentation and/or materials provided with the distribution.
- *
- * 3. In addition, redistributions of modified forms of the source or binary
- *    code must carry prominent notices stating that the original code was
- *    changed and the date of the change.
- *
- *  4. All publications or advertising materials mentioning features or use of
- *     this software are asked, but not required, to acknowledge that it was
- *     developed by Intel Corporation and credit the contributors.
- *
- * 5. Neither the name of Intel Corporation, nor the name of any Contributor
- *    may be used to endorse or promote products derived from this software
- *    without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
- * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY
- * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
- * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
- * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
- * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "mercury_thread_rwlock.h"
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_rwlock_init(hg_thread_rwlock_t *rwlock)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#ifdef _WIN32
-    InitializeSRWLock(rwlock);
-#else
-    if (pthread_rwlock_init(rwlock, NULL)) ret = HG_UTIL_FAIL;
-#endif
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_rwlock_destroy(hg_thread_rwlock_t *rwlock)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#ifdef _WIN32
-    /* nothing to do */
-#else
-    if (pthread_rwlock_destroy(rwlock)) ret = HG_UTIL_FAIL;
-#endif
-
-    return ret;
-}
--- b/src/util/mercury_thread_rwlock.h
+++ a/src/util/mercury_thread_rwlock.h
@@ -70,7 +70,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_rwlock_init(hg_thread_rwlock_t *rwlock);
 
 /**
@@ -80,7 +80,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_rwlock_destroy(hg_thread_rwlock_t *rwlock);
 
 /**
@@ -145,6 +145,36 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_UTIL_INLINE int
+hg_thread_rwlock_init(hg_thread_rwlock_t *rwlock)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#ifdef _WIN32
+    InitializeSRWLock(rwlock);
+#else
+    if (pthread_rwlock_init(rwlock, NULL)) ret = HG_UTIL_FAIL;
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
+hg_thread_rwlock_destroy(hg_thread_rwlock_t *rwlock)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#ifdef _WIN32
+    /* nothing to do */
+#else
+    if (pthread_rwlock_destroy(rwlock)) ret = HG_UTIL_FAIL;
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
 hg_thread_rwlock_rdlock(hg_thread_rwlock_t *rwlock)
 {
     int ret = HG_UTIL_SUCCESS;
--- b/src/util/mercury_thread_spin.c
+++ /dev/null
@@ -1,45 +0,0 @@
-/*
- * Copyright (C) 2013-2018 Argonne National Laboratory, Department of Energy,
- *                    UChicago Argonne, LLC and The HDF Group.
- * All rights reserved.
- *
- * The full copyright notice, including terms governing use, modification,
- * and redistribution, is contained in the COPYING file that can be
- * found at the root of the source code distribution tree.
- */
-
-#include "mercury_thread_spin.h"
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_spin_init(hg_thread_spin_t *lock)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#if defined(_WIN32)
-    *lock = 0;
-#elif defined(HG_UTIL_HAS_PTHREAD_SPINLOCK_T)
-    if (pthread_spin_init(lock, 0)) ret = HG_UTIL_FAIL;
-#else
-    ret = hg_thread_mutex_init(lock);
-#endif
-
-    return ret;
-}
-
-/*---------------------------------------------------------------------------*/
-int
-hg_thread_spin_destroy(hg_thread_spin_t *lock)
-{
-    int ret = HG_UTIL_SUCCESS;
-
-#if defined(_WIN32)
-    (void) lock;
-#elif defined(HG_UTIL_HAS_PTHREAD_SPINLOCK_T)
-    if (pthread_spin_destroy(lock)) ret = HG_UTIL_FAIL;
-#else
-    ret = hg_thread_mutex_destroy(lock);
-#endif
-
-    return ret;
-}
--- b/src/util/mercury_thread_spin.h
+++ a/src/util/mercury_thread_spin.h
@@ -36,7 +36,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_spin_init(hg_thread_spin_t *lock);
 
 /**
@@ -46,7 +46,7 @@
  *
  * \return Non-negative on success or negative on failure
  */
+static HG_UTIL_INLINE int
-HG_UTIL_EXPORT int
 hg_thread_spin_destroy(hg_thread_spin_t *lock);
 
 /**
@@ -81,6 +81,40 @@
 
 /*---------------------------------------------------------------------------*/
 static HG_UTIL_INLINE int
+hg_thread_spin_init(hg_thread_spin_t *lock)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#if defined(_WIN32)
+    *lock = 0;
+#elif defined(HG_UTIL_HAS_PTHREAD_SPINLOCK_T)
+    if (pthread_spin_init(lock, 0)) ret = HG_UTIL_FAIL;
+#else
+    ret = hg_thread_mutex_init(lock);
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
+hg_thread_spin_destroy(hg_thread_spin_t *lock)
+{
+    int ret = HG_UTIL_SUCCESS;
+
+#if defined(_WIN32)
+    (void) lock;
+#elif defined(HG_UTIL_HAS_PTHREAD_SPINLOCK_T)
+    if (pthread_spin_destroy(lock)) ret = HG_UTIL_FAIL;
+#else
+    ret = hg_thread_mutex_destroy(lock);
+#endif
+
+    return ret;
+}
+
+/*---------------------------------------------------------------------------*/
+static HG_UTIL_INLINE int
 hg_thread_spin_lock(hg_thread_spin_t *lock)
 {
     int ret = HG_UTIL_SUCCESS;
